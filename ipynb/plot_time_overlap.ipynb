{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Auto-generated from `plot_time_overlap.py`\n\nGenerated on 2025-11-09T22:01:34.\n\nThis notebook was created programmatically to mirror the original Python script.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nimport sys\nproject_root = str(Path.cwd().parent.resolve())\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "#!/usr/bin/env python3\n\"\"\"\nPlot overlapping time intervals from a CSV as a time-axis strip.\n\n- X-axis: time of day\n- Each record's interval contributes to the shading\n- Darker color => more vehicles overlapping at that time\n\nHow to run:\n  python plot_time_overlap.py\nConfigure parameters in-file below (no CLI args).\n\"\"\"\nimport os\nfrom dataclasses import dataclass\nfrom typing import List, Optional, Sequence, Tuple\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom matplotlib.ticker import FuncFormatter\nfrom matplotlib import rcParams\nfrom matplotlib.lines import Line2D\n\n# Use safe Latin fonts to avoid garbled axes; switch labels to English\nrcParams[\"font.family\"] = \"sans-serif\"\nrcParams[\"font.sans-serif\"] = [\n\t\"DejaVu Sans\",\n\t\"Arial\",\n\t\"Liberation Sans\",\n\t\"Nimbus Sans L\",\n]\nrcParams[\"axes.unicode_minus\"] = True\n\n# =========================\n# Configuration (edit here)\n# =========================\nCSV_PATH = \"/home/mw/project/cross_over_time_A.csv\"\nOUTPUT_PATH = \"/home/mw/project/cross_over_time_A_overlap_3.png\"\n# Real (A1) intervals and output\nREAL_CSV_PATH = \"/home/mw/project/corss_timeA_real.csv\"\nREAL_OUTPUT_PATH = \"/home/mw/project/cross_over_time_A_real_overlap.png\"\nWAIT_CSV_PATH = \"/home/mw/project/wait.csv\"\nWAIT_OUTPUT_PATH = \"/home/mw/project/wait_overlap.png\"\nCSV_PATH_ALL = \"/home/mw/project/cross_over_time.csv\"\nGROUPED_OUTPUT_PATH = \"/home/mw/project/cross_over_time_grouped_overlay.png\"\nGROUPED_TITLE = \"Overlap by direction groups (A1/B1/A2/B2)\"\nGROUP_DIR_COLORS = {\n\t\"A1\": \"#1f77b4\",\n\t\"B1\": \"#ff7f0e\",\n\t\"A2\": \"#2ca02c\",\n\t\"B2\": \"#d62728\",\n}\n# Single-group output config\nSINGLE_OUTPUT_DIR = \"/home/tzhang174/EVData_XGame/plots\"\nSINGLE_TITLE_PREFIX = \"Overlap - \"\n# Separate outputs for single-group figures\nGROUP_SINGLE_OUTPUTS = {\n\t\"A1\": \"/home/mw/project/cross_over_time_A1_overlay.png\",\n\t\"B1\": \"/home/mw/project/cross_over_time_B1_overlay.png\",\n\t\"A2\": \"/home/mw/project/cross_over_time_A2_overlay.png\",\n\t\"B2\": \"/home/mw/project/cross_over_time_B2_overlay.png\",\n}\nCOUNT_OUTPUT_PATH = \"/home/mw/project/cross_over_time_A_overlap_counts.png\"\nWAIT_COUNT_OUTPUT_PATH = \"/home/mw/project/wait_overlap_counts.png\"\nREFINED_CSV_PATH = \"/home/mw/project/A0003_refined.csv\"\nDIRECTION_CSV_PATH = \"/home/mw/project/direction.csv\"\n\n# Optional filters; set to None to include all\nROAD_ID = \"A0003\"  # e.g., \"A0003\" or None\nTARGET_DATE = None  # e.g., \"2024-06-20\" or None\nSEGMENT = None      # e.g., \"A1-1\" or None\nDIRECTION = None    # e.g., \"A1-1\" or \"A1-2\" or None\n\n# Plot mode: \"alpha\" => translucent bars overlaid; \"heat\" => binned heat strip\nMODE = \"alpha\"\nHEAT_BIN_SECONDS = 5  # used only when MODE == \"heat\"\nTITLE = \"Interval overlap\"\nSAVE_DPI = 220\nWAIT_TITLE = \"Wait time overlap\"\nCOUNT_TITLE = \"Overlap count per second\"\nWAIT_COUNT_TITLE = \"Wait count per second\"\nWAIT_COLOR = \"#7f0000\"\nCOMBINED_OUTPUT_PATH = \"/home/mw/project/overlap_combined.png\"\nCOMBINED_TITLE = \"Combined overlap (cross_over + wait)\"\nCROSS_COLOR = \"#00441b\"\nCYCLE_CSV_PATH = \"/home/mw/project/cycle_preview.csv\"\nDRAW_CYCLE_MARKERS = True\nCYCLE_START_COLOR = \"#9467bd\"  # purple\nGREEN_START_COLOR = \"#ffbf00\"  # gold\nCYCLE_START_LS = \":\"\nGREEN_START_LS = \"-\"\nCYCLE_MARK_LW = 1.8\nCYCLE_ZORDER = 12\n\n# End-time markers from merged points (A1-1 & A1-2)\nDRAW_END_TIME_LINES = True\nENDLINE_DIRECTIONS = (\"A1-1\", \"A1-2\")\nENDLINE_COLORS = {\n\t\"A1-1\": \"#d62728\",  # red\n\t\"A1-2\": \"#2ca02c\",  # green\n}\nENDLINE_ALPHA = 0.9\nENDLINE_LW = 1.8\nENDLINE_LS = \"--\"\nENDLINE_ZORDER = 10\n\n\ndef parse_time_to_seconds(time_str: str) -> int:\n\t\"\"\"Convert 'HH:MM:SS' to seconds since 00:00:00.\"\"\"\n\th, m, s = time_str.split(\":\")\n\treturn int(h) * 3600 + int(m) * 60 + int(s)\n\n\ndef parse_time_to_seconds_any(time_str: str) -> Optional[int]:\n\t\"\"\"\n\tParse time-of-day from:\n\t- 'HH:MM' or 'HH:MM:SS'\n\t- 'YYYY-MM-DD HH:MM:SS[.ffffff]'\n\tReturns seconds since midnight or None if unparsable.\n\t\"\"\"\n\tif time_str is None:\n\t\treturn None\n\tt = str(time_str).strip()\n\tif not t or t.lower() == \"nat\":\n\t\treturn None\n\t# Fast path: HH:MM or HH:MM:SS\n\ttry:\n\t\tparts = t.split(\":\")\n\t\tif len(parts) == 2:\n\t\t\th, m = int(parts[0]), int(parts[1])\n\t\t\treturn h * 3600 + m * 60\n\t\tif len(parts) >= 3 and \" \" not in parts[0]:\n\t\t\th, m = int(parts[0]), int(parts[1])\n\t\t\tsec_part = parts[2]\n\t\t\t# Trim fractional seconds if present\n\t\t\tif \".\" in sec_part:\n\t\t\t\tsec_part = sec_part.split(\".\")[0]\n\t\t\ts = int(sec_part)\n\t\t\treturn h * 3600 + m * 60 + s\n\texcept Exception:\n\t\tpass\n\t# Fallback: use pandas to parse full timestamps\n\ttry:\n\t\tts = pd.to_datetime(t, errors=\"coerce\")\n\t\tif ts is pd.NaT:\n\t\t\treturn None\n\t\treturn int(ts.hour) * 3600 + int(ts.minute) * 60 + int(ts.second)\n\texcept Exception:\n\t\treturn None\n\n\ndef format_seconds_as_hhmm(seconds: float) -> str:\n\t\"\"\"Format seconds since midnight as 'HH:MM'.\"\"\"\n\tseconds = int(round(seconds))\n\th = seconds // 3600\n\tm = (seconds % 3600) // 60\n\treturn f\"{h:02d}:{m:02d}\"\n\n\n@dataclass\nclass Interval:\n\tstart_s: int\n\tend_s: int\n\n\t@property\n\tdef width(self) -> int:\n\t\treturn max(0, self.end_s - self.start_s)\n\n\ndef load_intervals(\n\tcsv_path: str,\n\troad_id: Optional[str] = None,\n\ttarget_date: Optional[str] = None,\n\tsegment: Optional[str] = None,\n\tdirection: Optional[str] = None,\n) -> List[Interval]:\n\t\"\"\"\n\tRead CSV and return a list of intervals [enter_time, exit_time) in seconds of day.\n\tExpected columns: road_id, date, enter_time, exit_time, seg_id, direction\n\t\"\"\"\n\tdf = pd.read_csv(csv_path, dtype=str)\n\n\t# Basic filters if provided\n\tif road_id:\n\t\tdf = df[df[\"road_id\"] == road_id]\n\tif target_date:\n\t\tdf = df[df[\"date\"] == target_date]\n\tif segment:\n\t\tdf = df[df[\"seg_id\"] == segment]\n\tif direction:\n\t\tdf = df[df[\"direction\"] == direction]\n\n\tintervals: List[Interval] = []\n\tfor _, row in df.iterrows():\n\t\ttry:\n\t\t\tstart = parse_time_to_seconds_any(row.get(\"enter_time\"))\n\t\t\tend = parse_time_to_seconds_any(row.get(\"exit_time\"))\n\t\t\tif start is None or end is None:\n\t\t\t\tcontinue\n\t\t\t# Guard against malformed rows\n\t\t\tif end < start:\n\t\t\t\t# If exit before enter (e.g., cross-midnight not expected here), skip\n\t\t\t\tcontinue\n\t\t\tif end == start:\n\t\t\t\tcontinue\n\t\t\tintervals.append(Interval(start, end))\n\t\texcept Exception:\n\t\t\t# Skip malformed time strings\n\t\t\tcontinue\n\treturn intervals\n\n\ndef load_wait_intervals(\n\tcsv_path: str,\n\troad_id: Optional[str] = None,\n\ttarget_date: Optional[str] = None,\n\tsegment: Optional[str] = None,\n\tdirection: Optional[str] = None,\n) -> List[Interval]:\n\t\"\"\"\n\tRead wait.csv and return a list of wait intervals [time_stamp, end_time) in seconds of day.\n\tExpected columns: road_id, date, time_stamp, end_time, seg_id, direction\n\t\"\"\"\n\tdf = pd.read_csv(csv_path, dtype=str)\n\n\t# Basic filters if provided\n\tif road_id:\n\t\tdf = df[df[\"road_id\"] == road_id]\n\tif target_date:\n\t\tdf = df[df[\"date\"] == target_date]\n\tif segment:\n\t\tdf = df[df[\"seg_id\"] == segment]\n\tif direction:\n\t\tdf = df[df[\"direction\"] == direction]\n\n\t# Drop rows with missing times\n\tdf = df.dropna(subset=[\"time_stamp\", \"end_time\"])\n\n\tintervals: List[Interval] = []\n\tfor _, row in df.iterrows():\n\t\ttry:\n\t\t\tstart = parse_time_to_seconds(str(row[\"time_stamp\"]))\n\t\t\tend = parse_time_to_seconds(str(row[\"end_time\"]))\n\t\t\tif end <= start:\n\t\t\t\tcontinue\n\t\t\tintervals.append(Interval(start, end))\n\t\texcept Exception:\n\t\t\tcontinue\n\treturn intervals\n\n\ndef compute_bounds(intervals: Sequence[Interval], start: Optional[str], end: Optional[str]) -> Tuple[int, int]:\n\t\"\"\"Compute plotting [min_s, max_s] bounds in seconds.\"\"\"\n\tif not intervals:\n\t\t# Default to a daytime hour if empty\n\t\treturn parse_time_to_seconds(\"00:00:00\"), parse_time_to_seconds(\"23:59:59\")\n\tmin_s = min(iv.start_s for iv in intervals)\n\tmax_s = max(iv.end_s for iv in intervals)\n\tif start:\n\t\tmin_s = max(min_s, parse_time_to_seconds(start))\n\tif end:\n\t\tmax_s = min(max_s, parse_time_to_seconds(end))\n\treturn min_s, max_s\n\n\ndef plot_alpha_overlay(\n\tintervals: Sequence[Interval],\n\tmin_s: int,\n\tmax_s: int,\n\ttitle: Optional[str],\n\toutput_path: Optional[str],\n\tend_markers_by_dir: Optional[dict] = None,\n\tcolor: str = \"#1f77b4\",\n\talpha_scale: float = 1.0,\n\tmin_alpha: Optional[float] = None,\n) -> None:\n\t\"\"\"\n\tDraw one translucent bar per interval. Overlaps naturally look darker.\n\t\"\"\"\n\tnum = max(1, len(intervals))\n\t# Dynamic alpha: fewer intervals => more visible; clamp to a reasonable range\n\tbase_alpha = float(np.clip(4.0 / num, 0.015, 0.08))\n\talpha = float(np.clip(base_alpha * max(0.1, float(alpha_scale)), 0.015, 0.30))\n\tif min_alpha is not None:\n\t\ttry:\n\t\t\talpha = max(alpha, float(min_alpha))\n\t\texcept Exception:\n\t\t\tpass\n\n\tfig, ax = plt.subplots(figsize=(14, 2.2), constrained_layout=True)\n\tfor iv in intervals:\n\t\t# Clip to bounds\n\t\tstart = max(min_s, iv.start_s)\n\t\tend = min(max_s, iv.end_s)\n\t\tif end <= start:\n\t\t\tcontinue\n\t\tax.add_patch(Rectangle((start, 0), end - start, 1, color=color, alpha=alpha, linewidth=0))\n\n\tax.set_ylim(0, 1)\n\tax.set_xlim(min_s, max_s)\n\tax.set_yticks([])\n\tax.set_xlabel(\"Time (HH:MM)\")\n\tif title:\n\t\tax.set_title(title)\n\n\t# Draw end_time markers as vertical dashed lines (per direction)\n\tif end_markers_by_dir:\n\t\tlegend_handles = []\n\t\tfor d, times in end_markers_by_dir.items():\n\t\t\tcol = ENDLINE_COLORS.get(d, \"#444444\")\n\t\t\tfor t in times:\n\t\t\t\tif min_s <= t <= max_s:\n\t\t\t\t\tax.axvline(t, 0, 1, color=col, linestyle=ENDLINE_LS, linewidth=ENDLINE_LW, alpha=ENDLINE_ALPHA, zorder=ENDLINE_ZORDER)\n\t\t\t# Add legend proxy if this direction had any markers\n\t\t\tif times:\n\t\t\t\tlegend_handles.append(Line2D([0], [0], color=col, linestyle=ENDLINE_LS, linewidth=ENDLINE_LW, label=d))\n\t\tif legend_handles:\n\t\t\tax.legend(handles=legend_handles, loc=\"upper right\", frameon=False, fontsize=9, ncol=len(legend_handles))\n\n\tax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: format_seconds_as_hhmm(x)))\n\tax.grid(axis=\"x\", linestyle=\"--\", alpha=0.25)\n\n\tensure_parent_dir(output_path)\n\tif output_path:\n\t\tplt.savefig(output_path, dpi=SAVE_DPI)\n\telse:\n\t\tplt.show()\n\tplt.close(fig)\n\n\ndef compute_overlap_counts(\n\tintervals: Sequence[Interval],\n\tmin_s: int,\n\tmax_s: int,\n\tstep_s: int = 1,\n) -> Tuple[np.ndarray, np.ndarray]:\n\t\"\"\"\n\tCompute overlap counts per time step in [min_s, max_s) using a difference array.\n\tReturns:\n\t\txs_seconds: np.ndarray of second marks (seconds since midnight)\n\t\tcounts: np.ndarray of counts per second\n\t\"\"\"\n\tif max_s <= min_s:\n\t\treturn np.array([], dtype=np.int64), np.array([], dtype=np.int32)\n\tstep_s = max(1, int(step_s))\n\t# For step_s > 1, we still compute at 1-second resolution and then aggregate\n\tn_seconds = max(0, int(max_s - min_s))\n\tif n_seconds == 0:\n\t\treturn np.array([], dtype=np.int64), np.array([], dtype=np.int32)\n\tdiff = np.zeros(n_seconds + 1, dtype=np.int32)\n\tfor iv in intervals:\n\t\tstart = max(min_s, iv.start_s)\n\t\tend = min(max_s, iv.end_s)  # half-open [start, end)\n\t\tif end <= start:\n\t\t\tcontinue\n\t\ti0 = int(start - min_s)\n\t\ti1 = int(end - min_s)\n\t\tdiff[i0] += 1\n\t\tdiff[i1] -= 1\n\tper_sec = np.cumsum(diff[:-1])\n\tif step_s == 1:\n\t\txs = np.arange(min_s, max_s, dtype=np.int64)\n\t\treturn xs, per_sec\n\t# Aggregate into bins of size step_s\n\tn_bins = int(np.ceil(n_seconds / step_s))\n\tagg = np.zeros(n_bins, dtype=np.int32)\n\tfor i in range(n_bins):\n\t\tstart_idx = i * step_s\n\t\tend_idx = min(n_seconds, (i + 1) * step_s)\n\t\tif end_idx <= start_idx:\n\t\t\tcontinue\n\t\tagg[i] = int(per_sec[start_idx:end_idx].mean())\n\txs = np.arange(min_s, min_s + n_bins * step_s, step_s, dtype=np.int64)\n\treturn xs, agg\n\n\ndef plot_overlap_count_line(\n\tintervals: Sequence[Interval],\n\tmin_s: int,\n\tmax_s: int,\n\ttitle: Optional[str],\n\toutput_path: Optional[str],\n\tcolor: str = \"#1f77b4\",\n\tstep_s: int = 1,\n\tlinewidth: float = 1.8,\n) -> None:\n\t\"\"\"\n\tDraw a line chart where Y is the number of intervals overlapping each second.\n\t\"\"\"\n\txs, counts = compute_overlap_counts(intervals, min_s, max_s, step_s=step_s)\n\tif xs.size == 0:\n\t\tensure_parent_dir(output_path)\n\t\tif output_path:\n\t\t\t# Save an empty figure to keep pipeline consistent\n\t\t\tfig, ax = plt.subplots(figsize=(14, 2.2), constrained_layout=True)\n\t\t\tax.set_yticks([])\n\t\t\tax.set_xticks([])\n\t\t\tax.set_title(title or \"Empty\")\n\t\t\tplt.savefig(output_path, dpi=SAVE_DPI)\n\t\t\tplt.close(fig)\n\t\treturn\n\tfig, ax = plt.subplots(figsize=(14, 2.2), constrained_layout=True)\n\tax.plot(xs, counts, color=color, linewidth=linewidth)\n\tax.set_xlim(min_s, max_s)\n\tax.set_xlabel(\"Time (HH:MM)\")\n\tax.set_ylabel(\"Count\")\n\tif title:\n\t\tax.set_title(title)\n\tax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: format_seconds_as_hhmm(x)))\n\tax.grid(axis=\"both\", linestyle=\"--\", alpha=0.25)\n\tensure_parent_dir(output_path)\n\tif output_path:\n\t\tplt.savefig(output_path, dpi=SAVE_DPI)\n\telse:\n\t\tplt.show()\n\tplt.close(fig)\n\ndef _parse_group_key(g: str) -> Tuple[Optional[str], Optional[str], Optional[str], Optional[str]]:\n\ttry:\n\t\tparts = str(g).split(\"|\")\n\t\tif len(parts) >= 4:\n\t\t\treturn parts[0], parts[1], parts[2], parts[3]\n\t\treturn None, None, None, None\n\texcept Exception:\n\t\treturn None, None, None, None\n\ndef load_cycle_markers(\n\tcycle_csv_path: str,\n\troad_id: Optional[str],\n\tallowed_dirs: Sequence[str],\n\tmin_s: Optional[int] = None,\n\tmax_s: Optional[int] = None,\n) -> dict:\n\t\"\"\"\n\tLoad cycle and green start times from cycle_preview.csv and return:\n\t{\n\t  'cycle_start': {dir: [seconds...]},\n\t  'green_start': {dir: [seconds...]}\n\t}\n\t\"\"\"\n\tdf = pd.read_csv(cycle_csv_path, dtype=str)\n\tneed_cols = {\"group_key\", \"cycle_start_time\", \"green_start_time\"}\n\tmissing = need_cols - set(df.columns)\n\tif missing:\n\t\traise ValueError(f\"cycle_preview.csv missing columns: {missing}\")\n\n\t# Parse group_key to columns: road_id, direction, seg_id, date\n\tmeta = df[\"group_key\"].apply(_parse_group_key)\n\tdf[\"road_id_parsed\"] = [t[0] for t in meta]\n\tdf[\"direction_parsed\"] = [t[1] for t in meta]\n\tdf[\"seg_id_parsed\"] = [t[2] for t in meta]\n\tdf[\"date_parsed\"] = [t[3] for t in meta]\n\n\tif road_id:\n\t\tdf = df[df[\"road_id_parsed\"] == str(road_id)]\n\tdf = df[df[\"direction_parsed\"].isin(list(allowed_dirs))]\n\n\tdef times_to_seconds(series: pd.Series) -> List[int]:\n\t\tout: List[int] = []\n\t\tfor v in series.fillna(\"\").astype(str):\n\t\t\tvt = v.strip()\n\t\t\tif not vt:\n\t\t\t\tcontinue\n\t\t\ttry:\n\t\t\t\tsec = parse_time_to_seconds(vt)\n\t\t\t\tout.append(sec)\n\t\t\texcept Exception:\n\t\t\t\tcontinue\n\t\t# Dedup and keep sorted\n\t\tout = sorted(set(out))\n\t\t# Filter view if requested\n\t\tif min_s is not None and max_s is not None:\n\t\t\tout = [t for t in out if min_s <= t <= max_s]\n\t\treturn out\n\n\tresult = {\n\t\t\"cycle_start\": {},\n\t\t\"green_start\": {},\n\t}\n\tfor d in allowed_dirs:\n\t\tsub = df[df[\"direction_parsed\"] == d]\n\t\tcycle_list = times_to_seconds(sub[\"cycle_start_time\"])\n\t\tgreen_list = times_to_seconds(sub[\"green_start_time\"])\n\t\tresult[\"cycle_start\"][d] = cycle_list\n\t\tresult[\"green_start\"][d] = green_list\n\treturn result\n\n\ndef plot_combined_alpha_overlay(\n\tintervals1: Sequence[Interval],\n\tintervals2: Sequence[Interval],\n\tmin_s: int,\n\tmax_s: int,\n\ttitle: Optional[str],\n\toutput_path: Optional[str],\n\tcolor1: str,\n\tcolor2: str,\n\tcycle_markers: Optional[dict] = None,\n\talpha_scale1: float = 1.0,\n\talpha_scale2: float = 1.6,\n\tmin_alpha1: Optional[float] = None,\n\tmin_alpha2: Optional[float] = None,\n) -> None:\n\t\"\"\"\n\tDraw two translucent overlays (cross_over and wait) on the same time axis.\n\tOverlaps within each set and between sets will appear darker.\n\t\"\"\"\n\tnum1 = max(1, len(intervals1))\n\tnum2 = max(1, len(intervals2))\n\tbase_alpha1 = float(np.clip(4.0 / num1, 0.015, 0.08))\n\tbase_alpha2 = float(np.clip(4.0 / num2, 0.015, 0.08))\n\talpha1 = float(np.clip(base_alpha1 * max(0.1, float(alpha_scale1)), 0.015, 0.30))\n\talpha2 = float(np.clip(base_alpha2 * max(0.1, float(alpha_scale2)), 0.015, 0.30))\n\tif min_alpha1 is not None:\n\t\ttry:\n\t\t\talpha1 = max(alpha1, float(min_alpha1))\n\t\texcept Exception:\n\t\t\tpass\n\tif min_alpha2 is not None:\n\t\ttry:\n\t\t\talpha2 = max(alpha2, float(min_alpha2))\n\t\texcept Exception:\n\t\t\tpass\n\n\tfig, ax = plt.subplots(figsize=(14, 2.2), constrained_layout=True)\n\n\t# First layer\n\tfor iv in intervals1:\n\t\tstart = max(min_s, iv.start_s)\n\t\tend = min(max_s, iv.end_s)\n\t\tif end <= start:\n\t\t\tcontinue\n\t\tax.add_patch(Rectangle((start, 0), end - start, 1, color=color1, alpha=alpha1, linewidth=0))\n\n\t# Second layer\n\tfor iv in intervals2:\n\t\tstart = max(min_s, iv.start_s)\n\t\tend = min(max_s, iv.end_s)\n\t\tif end <= start:\n\t\t\tcontinue\n\t\tax.add_patch(Rectangle((start, 0), end - start, 1, color=color2, alpha=alpha2, linewidth=0))\n\n\tax.set_ylim(0, 1)\n\tax.set_xlim(min_s, max_s)\n\tax.set_yticks([])\n\tax.set_xlabel(\"Time (HH:MM)\")\n\tif title:\n\t\tax.set_title(title)\n\n\tax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: format_seconds_as_hhmm(x)))\n\tax.grid(axis=\"x\", linestyle=\"--\", alpha=0.25)\n\n\t# Legend for colors\n\ttry:\n\t\tlegend_handles = [\n\t\t\tLine2D([0], [0], color=color1, linewidth=6, label=\"cross_over\"),\n\t\t\tLine2D([0], [0], color=color2, linewidth=6, label=\"wait\"),\n\t\t]\n\t\t# Add cycle legend markers if provided\n\t\tif cycle_markers:\n\t\t\tlegend_handles.extend([\n\t\t\t\tLine2D([0], [0], color=CYCLE_START_COLOR, linestyle=CYCLE_START_LS, linewidth=2.5, label=\"cycle start\"),\n\t\t\t\tLine2D([0], [0], color=GREEN_START_COLOR, linestyle=GREEN_START_LS, linewidth=2.5, label=\"green start\"),\n\t\t\t])\n\t\tax.legend(handles=legend_handles, loc=\"upper right\", frameon=False, fontsize=9, ncol=2 if not cycle_markers else 3)\n\texcept Exception:\n\t\tpass\n\n\t# Draw cycle markers as short vertical ticks near top/bottom to avoid clutter\n\tif cycle_markers:\n\t\tdef dir_band(direction: str) -> Tuple[float, float]:\n\t\t\t# Reserve top band for A1-1, bottom band for A1-2\n\t\t\tif direction == \"A1-1\":\n\t\t\t\treturn 0.80, 0.98\n\t\t\tif direction == \"A1-2\":\n\t\t\t\treturn 0.02, 0.20\n\t\t\treturn 0.10, 0.30\n\t\tfor kind, by_dir in cycle_markers.items():\n\t\t\tcol = CYCLE_START_COLOR if kind == \"cycle_start\" else GREEN_START_COLOR\n\t\t\tls = CYCLE_START_LS if kind == \"cycle_start\" else GREEN_START_LS\n\t\t\tfor d, times in by_dir.items():\n\t\t\t\ty0, y1 = dir_band(d)\n\t\t\t\tfor t in times:\n\t\t\t\t\tif min_s <= t <= max_s:\n\t\t\t\t\t\tax.vlines(\n\t\t\t\t\t\t\tt, y0, y1,\n\t\t\t\t\t\t\tcolors=col,\n\t\t\t\t\t\t\tlinestyles=ls,\n\t\t\t\t\t\t\tlinewidth=CYCLE_MARK_LW,\n\t\t\t\t\t\t\tzorder=CYCLE_ZORDER,\n\t\t\t\t\t\t\tclip_on=False,\n\t\t\t\t\t\t)\n\n\tensure_parent_dir(output_path)\n\tif output_path:\n\t\tplt.savefig(output_path, dpi=SAVE_DPI)\n\telse:\n\t\tplt.show()\n\tplt.close(fig)\n\ndef plot_heat_overlap(\n\tintervals: Sequence[Interval],\n\tmin_s: int,\n\tmax_s: int,\n\ttitle: Optional[str],\n\toutput_path: Optional[str],\n\tbin_s: int = 5,\n\tcmap: str = \"Blues\",\n\tend_markers_by_dir: Optional[dict] = None,\n) -> None:\n\t\"\"\"\n\tAggregate overlap counts per bin and render as a 1D heat strip with a colorbar.\n\tDarker color => higher count (more vehicles simultaneously inside).\n\t\"\"\"\n\tbin_s = max(1, int(bin_s))\n\tif max_s <= min_s:\n\t\tmax_s = min_s + 1\n\tn_bins = int(np.ceil((max_s - min_s) / bin_s))\n\tcounts = np.zeros(n_bins, dtype=np.int32)\n\n\tfor iv in intervals:\n\t\tstart = max(min_s, iv.start_s)\n\t\tend = min(max_s, iv.end_s)\n\t\tif end <= start:\n\t\t\tcontinue\n\t\ti0 = int((start - min_s) // bin_s)\n\t\t# Subtract a tiny epsilon so an interval ending exactly at a bin edge does not spill into next bin\n\t\ti1 = int((max(min_s, end) - min_s - 1e-9) // bin_s)\n\t\ti0 = max(0, min(i0, n_bins - 1))\n\t\ti1 = max(0, min(i1, n_bins - 1))\n\t\tif i1 >= i0:\n\t\t\tcounts[i0 : i1 + 1] += 1\n\n\t# Prepare the image (1 x n_bins)\n\timg = counts[np.newaxis, :]\n\n\tfig, ax = plt.subplots(figsize=(14, 1.8), constrained_layout=True)\n\textent = [min_s, min_s + n_bins * bin_s, 0, 1]\n\tim = ax.imshow(img, aspect=\"auto\", cmap=cmap, extent=extent, origin=\"lower\", interpolation=\"nearest\")\n\tax.set_ylim(0, 1)\n\tax.set_xlim(min_s, max_s)\n\tax.set_yticks([])\n\tax.set_xlabel(\"Time (HH:MM)\")\n\tif title:\n\t\tax.set_title(title)\n\tcb = fig.colorbar(im, ax=ax, fraction=0.08, pad=0.12)\n\tcb.set_label(\"Concurrent vehicles\")\n\n\t# Draw end_time markers as vertical dashed lines (per direction)\n\tif end_markers_by_dir:\n\t\tlegend_handles = []\n\t\tfor d, times in end_markers_by_dir.items():\n\t\t\tcol = ENDLINE_COLORS.get(d, \"#444444\")\n\t\t\tfor t in times:\n\t\t\t\tif min_s <= t <= max_s:\n\t\t\t\t\tax.axvline(t, 0, 1, color=col, linestyle=ENDLINE_LS, linewidth=ENDLINE_LW, alpha=ENDLINE_ALPHA, zorder=ENDLINE_ZORDER)\n\t\t\t# Add legend proxy if this direction had any markers\n\t\t\tif times:\n\t\t\t\tlegend_handles.append(Line2D([0], [0], color=col, linestyle=ENDLINE_LS, linewidth=ENDLINE_LW, label=d))\n\t\tif legend_handles:\n\t\t\tax.legend(handles=legend_handles, loc=\"upper right\", frameon=False, fontsize=9, ncol=len(legend_handles))\n\n\tax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: format_seconds_as_hhmm(x)))\n\tax.grid(axis=\"x\", linestyle=\"--\", alpha=0.25)\n\n\tensure_parent_dir(output_path)\n\tif output_path:\n\t\tplt.savefig(output_path, dpi=SAVE_DPI)\n\telse:\n\t\tplt.show()\n\tplt.close(fig)\n\n\ndef load_intervals_grouped_by_dir(\n\tcsv_path: str,\n\troad_id: Optional[str],\n\ttarget_date: Optional[str],\n\tsegment: Optional[str],\n) -> dict:\n\t\"\"\"\n\tLoad intervals from cross_over_time.csv and group into:\n\t  A1: {A1-1, A1-2}\n\t  B1: {B1-1, B1-2}\n\t  A2: {A2-1, A2-2}\n\t  B2: {B2-1, B2-2}\n\t\"\"\"\n\tdf = pd.read_csv(csv_path, dtype=str)\n\tif road_id:\n\t\tdf = df[df[\"road_id\"] == str(road_id)]\n\tif target_date:\n\t\tdf = df[df[\"date\"] == str(target_date)]\n\tif segment:\n\t\tdf = df[df[\"seg_id\"] == str(segment)]\n\tdf = df.dropna(subset=[\"enter_time\", \"exit_time\", \"direction\"])\n\n\tdir_map = {\n\t\t\"A1-1\": \"A1\", \"A1-2\": \"A1\",\n\t\t\"B1-1\": \"B1\", \"B1-2\": \"B1\",\n\t\t\"A2-1\": \"A2\", \"A2-2\": \"A2\",\n\t\t\"B2-1\": \"B2\", \"B2-2\": \"B2\",\n\t}\n\tgrouped: Dict[str, List[Interval]] = {\"A1\": [], \"B1\": [], \"A2\": [], \"B2\": []}\n\tfor _, row in df.iterrows():\n\t\td = str(row[\"direction\"]).strip()\n\t\tg = dir_map.get(d)\n\t\tif not g:\n\t\t\tcontinue\n\t\ttry:\n\t\t\tstart = parse_time_to_seconds(str(row[\"enter_time\"]))\n\t\t\tend = parse_time_to_seconds(str(row[\"exit_time\"]))\n\t\t\tif end <= start:\n\t\t\t\tcontinue\n\t\t\tgrouped[g].append(Interval(start, end))\n\t\texcept Exception:\n\t\t\tcontinue\n\treturn grouped\n\n\ndef plot_multi_alpha_overlay(\n\tlayers: Sequence[Tuple[str, Sequence[Interval], str]],\n\tmin_s: int,\n\tmax_s: int,\n\ttitle: Optional[str],\n\toutput_path: Optional[str],\n\talpha_scale: float = 2.2,\n\tmin_alpha: Optional[float] = 0.10,\n) -> None:\n\t\"\"\"\n\tDraw multiple translucent overlays on the same axis.\n\tlayers: list of (label, intervals, color)\n\t\"\"\"\n\tfig, ax = plt.subplots(figsize=(14, 2.4), constrained_layout=True)\n\tlegend_handles: List[Line2D] = []\n\n\tfor label, intervals, color in layers:\n\t\tnum = max(1, len(intervals))\n\t\tbase_alpha = float(np.clip(4.0 / num, 0.015, 0.08))\n\t\talpha = float(np.clip(base_alpha * max(0.1, float(alpha_scale)), 0.015, 0.30))\n\t\tif min_alpha is not None:\n\t\t\ttry:\n\t\t\t\talpha = max(alpha, float(min_alpha))\n\t\t\texcept Exception:\n\t\t\t\tpass\n\t\tfor iv in intervals:\n\t\t\tstart = max(min_s, iv.start_s)\n\t\t\tend = min(max_s, iv.end_s)\n\t\t\tif end <= start:\n\t\t\t\tcontinue\n\t\t\tax.add_patch(Rectangle((start, 0), end - start, 1, color=color, alpha=alpha, linewidth=0))\n\t\tlegend_handles.append(Line2D([0], [0], color=color, linewidth=6, label=label))\n\n\tax.set_ylim(0, 1)\n\tax.set_xlim(min_s, max_s)\n\tax.set_yticks([])\n\tax.set_xlabel(\"Time (HH:MM)\")\n\tif title:\n\t\tax.set_title(title)\n\tax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: format_seconds_as_hhmm(x)))\n\tax.grid(axis=\"x\", linestyle=\"--\", alpha=0.25)\n\tif legend_handles:\n\t\tax.legend(handles=legend_handles, loc=\"upper right\", frameon=False, fontsize=9, ncol=4)\n\n\tensure_parent_dir(output_path)\n\tif output_path:\n\t\tplt.savefig(output_path, dpi=SAVE_DPI)\n\telse:\n\t\tplt.show()\n\tplt.close(fig)\n\n\ndef plot_single_group_overlays(\n\tgrouped: dict,\n\ttitle_prefix: str,\n\toutput_dir: str,\n\tuse_common_bounds: bool = True,\n\talpha_scale: float = 2.2,\n\tmin_alpha: float = 0.10,\n) -> None:\n\t\"\"\"\n\tSave four standalone images for A1, B1, A2, B2.\n\tIf use_common_bounds=True, time axis is aligned using all groups' min/max.\n\t\"\"\"\n\tkeys = (\"A1\", \"B1\", \"A2\", \"B2\")\n\t# Compute bounds (common or per-group)\n\tif use_common_bounds:\n\t\tall_intervals = [iv for k in keys for iv in grouped.get(k, [])]\n\t\tif len(all_intervals) == 0:\n\t\t\tprint(\"[single] No intervals in any group; skip single overlays.\")\n\t\t\treturn\n\t\tmin_s = min(iv.start_s for iv in all_intervals)\n\t\tmax_s = max(iv.end_s for iv in all_intervals)\n\telse:\n\t\tmin_s = None\n\t\tmax_s = None\n\n\tfor k in keys:\n\t\tivals = grouped.get(k, [])\n\t\tif len(ivals) == 0:\n\t\t\tprint(f\"[single] {k}: empty; skip.\")\n\t\t\tcontinue\n\t\tout_path = f\"/home/mw/project/cross_over_time_{k}_overlay.png\"\n\t\tcolor = GROUP_DIR_COLORS.get(k, \"#999999\")\n\t\tif not use_common_bounds:\n\t\t\t# Per-group bounds\n\t\t\tmin_s_k = min(iv.start_s for iv in ivals)\n\t\t\tmax_s_k = max(iv.end_s for iv in ivals)\n\t\t\tms, mx = min_s_k, max_s_k\n\t\telse:\n\t\t\tms, mx = min_s, max_s\n\t\tprint(f\"[single] {k}: n={len(ivals)} range={format_seconds_as_hhmm(ms)}-{format_seconds_as_hhmm(mx)} -> {out_path}\")\n\t\tplot_alpha_overlay(\n\t\t\tintervals=ivals,\n\t\t\tmin_s=ms,\n\t\t\tmax_s=mx,\n\t\t\ttitle=f\"{title_prefix}{k}\",\n\t\t\toutput_path=out_path,\n\t\t\tend_markers_by_dir=None,\n\t\t\tcolor=color,\n\t\t\talpha_scale=alpha_scale,\n\t\t\tmin_alpha=min_alpha,\n\t\t)\n\n\ndef ensure_parent_dir(path: Optional[str]) -> None:\n\tif not path:\n\t\treturn\n\tparent = os.path.dirname(os.path.abspath(path))\n\tif parent and not os.path.exists(parent):\n\t\tos.makedirs(parent, exist_ok=True)\n\ndef load_end_time_markers(\n\trefined_csv_path: str,\n\tdirection_csv_path: str,\n\troad_id: Optional[str],\n\tallowed_dirs: Sequence[str],\n) -> dict:\n\t\"\"\"\n\tLoad merged points' end_time for specified directions and return mapping:\n\t{direction: [seconds_of_day, ...]}\n\t\"\"\"\n\ttry:\n\t\trefined = pd.read_csv(refined_csv_path, dtype=str, usecols=[\n\t\t\t\"vehicle_id\",\"date\",\"seg_id\",\"road_id\",\"end_time\"\n\t\t])\n\texcept Exception:\n\t\t# Fallback: read full if selective read fails (schema differences)\n\t\trefined = pd.read_csv(refined_csv_path, dtype=str)\n\t\tcolset = set(refined.columns)\n\t\tneed = {\"vehicle_id\",\"date\",\"seg_id\",\"road_id\",\"end_time\"}\n\t\tmissing = need - colset\n\t\tif missing:\n\t\t\traise ValueError(f\"Refined CSV missing columns: {missing}\")\n\t\trefined = refined[list(need)]\n\n\tdirections = pd.read_csv(direction_csv_path, dtype=str)\n\tdirections = directions[[\"vehicle_id\",\"date\",\"seg_id\",\"road_id\",\"direction\"]]\n\n\tif road_id:\n\t\trefined = refined[refined[\"road_id\"] == str(road_id)]\n\t\tdirections = directions[directions[\"road_id\"] == str(road_id)]\n\n\tdirections = directions[directions[\"direction\"].isin(list(allowed_dirs))]\n\n\tif len(directions) == 0:\n\t\treturn {d: [] for d in allowed_dirs}\n\n\tkeys = [\"vehicle_id\",\"date\",\"seg_id\",\"road_id\"]\n\tdf = refined.merge(directions, on=keys, how=\"inner\")\n\t# Filter rows with non-empty end_time\n\tdf = df[df[\"end_time\"].astype(str).str.strip().astype(bool)]\n\n\tend_by_dir = {}\n\tfor d in allowed_dirs:\n\t\tsub = df[df[\"direction\"] == d]\n\t\t# Convert HH:MM:SS to seconds-of-day, drop malformed values\n\t\tseconds_list: List[int] = []\n\t\tfor t in sub[\"end_time\"].tolist():\n\t\t\ttry:\n\t\t\t\tseconds_list.append(parse_time_to_seconds(str(t)))\n\t\t\texcept Exception:\n\t\t\t\tcontinue\n\t\t# Deduplicate and sort\n\t\tend_by_dir[d] = sorted(set(seconds_list))\n\treturn end_by_dir\n\n\ndef main() -> None:\n\tintervals = load_intervals(\n\t\tcsv_path=CSV_PATH,\n\t\troad_id=ROAD_ID,\n\t\ttarget_date=TARGET_DATE,\n\t\tsegment=SEGMENT,\n\t\tdirection=DIRECTION,\n\t)\n\n\tif not intervals:\n\t\tprint(\"No intervals after filtering. Skip base plots but continue with grouped overlay.\")\n\n\tmin_s, max_s = compute_bounds(intervals, start=None, end=None)\n\tprint(f\"[plot] intervals={len(intervals)}  range={format_seconds_as_hhmm(min_s)}-{format_seconds_as_hhmm(max_s)}  mode={MODE}\")\n\n\tend_markers_by_dir = None\n\tif DRAW_END_TIME_LINES:\n\t\ttry:\n\t\t\tend_markers_by_dir = load_end_time_markers(\n\t\t\t\trefined_csv_path=REFINED_CSV_PATH,\n\t\t\t\tdirection_csv_path=DIRECTION_CSV_PATH,\n\t\t\t\troad_id=ROAD_ID,\n\t\t\t\tallowed_dirs=list(ENDLINE_DIRECTIONS),\n\t\t\t)\n\t\texcept Exception as e:\n\t\t\tprint(f\"Failed to load end_time markers: {e}\")\n\t\t\tend_markers_by_dir = None\n\t\n\t# Print marker statistics\n\tif end_markers_by_dir is None:\n\t\tprint(\"[markers] none loaded (disabled or load failed)\")\n\telse:\n\t\tfor d in ENDLINE_DIRECTIONS:\n\t\t\ttimes = end_markers_by_dir.get(d, []) if isinstance(end_markers_by_dir, dict) else []\n\t\t\ttotal_cnt = len(times)\n\t\t\tin_view = [t for t in times if min_s <= t <= max_s]\n\t\t\tin_cnt = len(in_view)\n\t\t\tprint(f\"[markers] {d}: total={total_cnt}, in_view={in_cnt}\")\n\t\t\tif in_cnt > 0:\n\t\t\t\tsample = \", \".join(format_seconds_as_hhmm(t) for t in (in_view[:10]))\n\t\t\t\tif in_cnt > 10:\n\t\t\t\t\tprint(f\"          samples: {sample} ...\")\n\t\t\t\telse:\n\t\t\t\t\tprint(f\"          times: {sample}\")\n\n\tif MODE == \"alpha\":\n\t\tprint(f\"[save] output -> {OUTPUT_PATH}\")\n\t\tplot_alpha_overlay(\n\t\t\tintervals,\n\t\t\tmin_s,\n\t\t\tmax_s,\n\t\t\tTITLE,\n\t\t\tOUTPUT_PATH,\n\t\t\tend_markers_by_dir=end_markers_by_dir,\n\t\t\tcolor=CROSS_COLOR,\n\t\t\talpha_scale=2.2,\n\t\t\tmin_alpha=0.12,\n\t\t)\n\telse:\n\t\tprint(f\"[save] output -> {OUTPUT_PATH}\")\n\t\tplot_heat_overlap(intervals, min_s, max_s, TITLE, OUTPUT_PATH, bin_s=HEAT_BIN_SECONDS, end_markers_by_dir=end_markers_by_dir)\n\n\t# Real (A1) overlay with the same configuration\n\ttry:\n\t\treal_intervals = load_intervals(\n\t\t\tcsv_path=REAL_CSV_PATH,\n\t\t\troad_id=ROAD_ID,\n\t\t\ttarget_date=TARGET_DATE,\n\t\t\tsegment=SEGMENT,\n\t\t\tdirection=DIRECTION,\n\t\t)\n\t\tif not real_intervals:\n\t\t\tprint(\"[real] No intervals after filtering. Skip real overlay.\")\n\t\telse:\n\t\t\trmin_s, rmax_s = compute_bounds(real_intervals, start=None, end=None)\n\t\t\tprint(f\"[real-plot] intervals={len(real_intervals)}  range={format_seconds_as_hhmm(rmin_s)}-{format_seconds_as_hhmm(rmax_s)}\")\n\t\t\tprint(f\"[save] output -> {REAL_OUTPUT_PATH}\")\n\t\t\tplot_alpha_overlay(\n\t\t\t\tintervals=real_intervals,\n\t\t\t\tmin_s=rmin_s,\n\t\t\t\tmax_s=rmax_s,\n\t\t\t\ttitle=f\"{TITLE} (real)\",\n\t\t\t\toutput_path=REAL_OUTPUT_PATH,\n\t\t\t\tend_markers_by_dir=None,\n\t\t\t\tcolor=CROSS_COLOR,\n\t\t\t\talpha_scale=2.2,\n\t\t\t\tmin_alpha=0.12,\n\t\t\t)\n\texcept Exception as e:\n\t\tprint(f\"[real] Failed to plot real overlay: {e}\")\n\n\t# Line chart for overlap counts (cross_over)\n\ttry:\n\t\tprint(f\"[save] output -> {COUNT_OUTPUT_PATH}\")\n\t\tplot_overlap_count_line(\n\t\t\tintervals=intervals,\n\t\t\tmin_s=min_s,\n\t\t\tmax_s=max_s,\n\t\t\ttitle=COUNT_TITLE,\n\t\t\toutput_path=COUNT_OUTPUT_PATH,\n\t\t\tcolor=CROSS_COLOR,\n\t\t\tstep_s=1,\n\t\t\tlinewidth=2.0,\n\t\t)\n\texcept Exception as e:\n\t\tprint(f\"[count] Failed to plot overlap count line: {e}\")\n\n\t# Additional figure: wait intervals from wait.csv (darker shading, overlap => darker)\n\ttry:\n\t\t# Load cycle markers for combined plot\n\t\tcycle_markers = None\n\t\tif DRAW_CYCLE_MARKERS:\n\t\t\ttry:\n\t\t\t\tcycle_markers = load_cycle_markers(\n\t\t\t\t\tcycle_csv_path=CYCLE_CSV_PATH,\n\t\t\t\t\troad_id=ROAD_ID,\n\t\t\t\t\tallowed_dirs=list(ENDLINE_DIRECTIONS),\n\t\t\t\t\tmin_s=min_s,\n\t\t\t\t\tmax_s=max_s,\n\t\t\t\t)\n\t\t\t\t# Print stats\n\t\t\t\tfor kind in (\"cycle_start\", \"green_start\"):\n\t\t\t\t\tby_dir = cycle_markers.get(kind, {}) if isinstance(cycle_markers, dict) else {}\n\t\t\t\t\tfor d in ENDLINE_DIRECTIONS:\n\t\t\t\t\t\ttimes = by_dir.get(d, [])\n\t\t\t\t\t\tprint(f\"[cycles] {kind} {d}: count={len(times)}\")\n\t\t\texcept Exception as e:\n\t\t\t\tprint(f\"[cycles] Failed to load cycle markers: {e}\")\n\t\t\t\tcycle_markers = None\n\n\t\twait_intervals = load_wait_intervals(\n\t\t\tcsv_path=WAIT_CSV_PATH,\n\t\t\troad_id=ROAD_ID,\n\t\t\ttarget_date=TARGET_DATE,\n\t\t\tsegment=SEGMENT,\n\t\t\tdirection=DIRECTION,\n\t\t)\n\t\tif not wait_intervals:\n\t\t\tprint(\"[wait] No wait intervals after filtering. Skip wait plot.\")\n\t\telse:\n\t\t\twmin_s, wmax_s = compute_bounds(wait_intervals, start=None, end=None)\n\t\t\tprint(f\"[plot-wait] intervals={len(wait_intervals)}  range={format_seconds_as_hhmm(wmin_s)}-{format_seconds_as_hhmm(wmax_s)}\")\n\t\t\tprint(f\"[save] output -> {WAIT_OUTPUT_PATH}\")\n\t\t\tplot_alpha_overlay(\n\t\t\t\twait_intervals,\n\t\t\t\twmin_s,\n\t\t\t\twmax_s,\n\t\t\t\tWAIT_TITLE,\n\t\t\t\tWAIT_OUTPUT_PATH,\n\t\t\t\tend_markers_by_dir=None,\n\t\t\t\tcolor=WAIT_COLOR,\n\t\t\t\talpha_scale=2.6,\n\t\t\t\tmin_alpha=0.14,\n\t\t\t)\n\t\t\t# Combined figure (cross_over + wait)\n\t\t\tcmin_s = min(min_s, wmin_s)\n\t\t\tcmax_s = max(max_s, wmax_s)\n\t\t\tprint(f\"[plot-combined] cross={len(intervals)}, wait={len(wait_intervals)}  range={format_seconds_as_hhmm(cmin_s)}-{format_seconds_as_hhmm(cmax_s)}\")\n\t\t\tprint(f\"[save] output -> {COMBINED_OUTPUT_PATH}\")\n\t\t\tplot_combined_alpha_overlay(\n\t\t\t\tintervals1=intervals,\n\t\t\t\tintervals2=wait_intervals,\n\t\t\t\tmin_s=cmin_s,\n\t\t\t\tmax_s=cmax_s,\n\t\t\t\ttitle=COMBINED_TITLE,\n\t\t\t\toutput_path=COMBINED_OUTPUT_PATH,\n\t\t\t\tcolor1=CROSS_COLOR,\n\t\t\t\tcolor2=WAIT_COLOR,\n\t\t\t\tcycle_markers=cycle_markers,\n\t\t\t\talpha_scale1=2.2,\n\t\t\t\talpha_scale2=2.6,\n\t\t\t\tmin_alpha1=0.12,\n\t\t\t\tmin_alpha2=0.14,\n\t\t\t)\n\t\t\t# Wait count-per-second line chart\n\t\t\ttry:\n\t\t\t\tprint(f\"[save] output -> {WAIT_COUNT_OUTPUT_PATH}\")\n\t\t\t\tplot_overlap_count_line(\n\t\t\t\t\tintervals=wait_intervals,\n\t\t\t\t\tmin_s=wmin_s,\n\t\t\t\t\tmax_s=wmax_s,\n\t\t\t\t\ttitle=WAIT_COUNT_TITLE,\n\t\t\t\t\toutput_path=WAIT_COUNT_OUTPUT_PATH,\n\t\t\t\t\tcolor=WAIT_COLOR,\n\t\t\t\t\tstep_s=1,\n\t\t\t\t\tlinewidth=2.0,\n\t\t\t\t)\n\t\t\texcept Exception as e:\n\t\t\t\tprint(f\"[wait-count] Failed to plot wait count line: {e}\")\n\texcept Exception as e:\n\t\tprint(f\"[wait] Failed to plot wait intervals: {e}\")\n\n\t# Grouped overlay (A1/B1/A2/B2) from cross_over_time.csv\n\ttry:\n\t\tgrouped = load_intervals_grouped_by_dir(\n\t\t\tcsv_path=CSV_PATH_ALL,\n\t\t\troad_id=ROAD_ID,\n\t\t\ttarget_date=TARGET_DATE,\n\t\t\tsegment=SEGMENT,\n\t\t)\n\t\ttotal = sum(len(v) for v in grouped.values())\n\t\tif total == 0:\n\t\t\tprint(\"[grouped] No intervals found in cross_over_time.csv after filters. Skip grouped overlay.\")\n\t\telse:\n\t\t\tgmin = min((iv.start_s for vals in grouped.values() for iv in vals), default=None)\n\t\t\tgmax = max((iv.end_s for vals in grouped.values() for iv in vals), default=None)\n\t\t\tif gmin is None or gmax is None or gmax <= gmin:\n\t\t\t\tprint(\"[grouped] Invalid bounds. Skip.\")\n\t\t\telse:\n\t\t\t\tprint(f\"[grouped] counts: A1={len(grouped['A1'])}, B1={len(grouped['B1'])}, A2={len(grouped['A2'])}, B2={len(grouped['B2'])}\")\n\t\t\t\tlayers: List[Tuple[str],] = []  # placeholder for typing context\n\t\t\t\tlayers = []\n\t\t\t\tfor key in (\"A1\", \"B1\", \"A2\", \"B2\"):\n\t\t\t\t\tivals = grouped.get(key, [])\n\t\t\t\t\tif len(ivals) == 0:\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tcolor = GROUP_DIR_COLORS.get(key, \"#999999\")\n\t\t\t\t\tlayers.append((key, ivals, color))\n\t\t\t\tif layers:\n\t\t\t\t\tprint(f\"[save] output -> {GROUPED_OUTPUT_PATH}\")\n\t\t\t\t\tplot_multi_alpha_overlay(\n\t\t\t\t\t\tlayers=layers,\n\t\t\t\t\t\tmin_s=gmin,\n\t\t\t\t\t\tmax_s=gmax,\n\t\t\t\t\t\ttitle=GROUPED_TITLE,\n\t\t\t\t\t\toutput_path=GROUPED_OUTPUT_PATH,\n\t\t\t\t\t\talpha_scale=2.2,\n\t\t\t\t\t\tmin_alpha=0.10,\n\t\t\t\t\t)\n\t\t\t\telse:\n\t\t\t\t\tprint(\"[grouped] No non-empty groups to draw.\")\n\texcept Exception as e:\n\t\tprint(f\"[grouped] Failed to plot grouped overlay: {e}\")\n\n\t# Separate single-group overlays for A1, B1, A2, B2\n\ttry:\n\t\tif 'grouped' not in locals():\n\t\t\tgrouped = load_intervals_grouped_by_dir(\n\t\t\t\tcsv_path=CSV_PATH_ALL,\n\t\t\t\troad_id=ROAD_ID,\n\t\t\t\ttarget_date=TARGET_DATE,\n\t\t\t\tsegment=SEGMENT,\n\t\t\t)\n\t\tfor key in (\"A1\", \"B1\", \"A2\", \"B2\"):\n\t\t\tivals = grouped.get(key, [])\n\t\t\tif not ivals:\n\t\t\t\tprint(f\"[single] {key}: no intervals, skip.\")\n\t\t\t\tcontinue\n\t\t\tsmin, smax = compute_bounds(ivals, start=None, end=None)\n\t\t\tout_path = GROUP_SINGLE_OUTPUTS.get(key)\n\t\t\tcolor = GROUP_DIR_COLORS.get(key, \"#999999\")\n\t\t\ttitle = f\"{key} overlap\"\n\t\t\tprint(f\"[single] {key}: {len(ivals)} intervals  range={format_seconds_as_hhmm(smin)}-{format_seconds_as_hhmm(smax)}\")\n\t\t\tprint(f\"[save] output -> {out_path}\")\n\t\t\tplot_alpha_overlay(\n\t\t\t\tintervals=ivals,\n\t\t\t\tmin_s=smin,\n\t\t\t\tmax_s=smax,\n\t\t\t\ttitle=title,\n\t\t\t\toutput_path=out_path,\n\t\t\t\tend_markers_by_dir=None,\n\t\t\t\tcolor=color,\n\t\t\t\talpha_scale=2.2,\n\t\t\t\tmin_alpha=0.10,\n\t\t\t)\n\texcept Exception as e:\n\t\tprint(f\"[single] Failed to plot single-group overlays: {e}\")\n\nif __name__ == \"__main__\":\n\tmain()\n\n\n"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}