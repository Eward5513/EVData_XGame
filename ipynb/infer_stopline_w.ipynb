{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Auto-generated from `infer_stopline_w.py`\n\nGenerated on 2025-11-09T22:01:34.\n\nThis notebook was created programmatically to mirror the original Python script.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nimport sys\nproject_root = str(Path.cwd().parent.resolve())\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport json\nimport math\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom shapely.geometry import LineString, Point\nfrom pyproj import CRS, Transformer\n\n# =========================\n# Hardcoded paths & parameters\n# =========================\nDATA_DIR = \"/home/tzhang174/EVData_XGame\"\nREFINED = {\n    \"A0003\": f\"/home/mw/project/A0003_refined.csv\",\n    \"A0008\": f\"/home/mw/project/A0008_refined.csv\",\n}\nDIRECTION_PATH = f\"/home/mw/project/direction.csv\"\nINTERSECTION_JSON_PATH = f\"/home/mw/project/intersection_A.json\"  # JSON with lane_divider\nOUT_DIR = f\"{DATA_DIR}/data\"\n\n# Directions for the west approach (from direction.csv)\nDIRECTIONS_USED = {\"A1-1\", \"B2-1\", \"B3-2\"}\n\n# Stop decision & sampling window\nSPEED_THRESH = 5.0 / 3.6   # m/s (5 km/h)\nMAX_UPSTREAM_M = 120.0     # use only this upstream distance from center\nSTOP_Q = 0.95              # 95th percentile → ~5% beyond; increase to reduce beyond\n\n# Override center point (you provide (lat, lon); script converts to (lon, lat))\nCENTER_OVERRIDES_LATLON = {\n    \"A0003\": (32.34513595, 123.15253329),\n    \"A0008\": (32.32708227, 123.18126882),\n}\n\n# =========================\n# Utilities\n# =========================\ndef best_local_crs(lon, lat):\n    utm_zone = int(math.floor((lon + 180) / 6) + 1)\n    return CRS.from_epsg(32600 + utm_zone if lat >= 0 else 32700 + utm_zone)\n\ndef unit(v):\n    n = np.linalg.norm(v)\n    return v if n == 0 else v / n\n\ndef load_intersection(json_path: str, road_id: str):\n    \"\"\"\n    Read intersection_A.json:\n    {\n      \"A0003\": {\n        \"lane_divider\": [[lon,lat], [lon,lat], ...],   # ideally ordered West→East (upstream→center)\n        \"center\": [lon,lat]    # optional (this script prefers the override center)\n      },\n      \"A0008\": {...}\n    }\n    \"\"\"\n    text = Path(json_path).read_text(encoding=\"utf-8\").strip()\n    try:\n        data = json.loads(text)\n    except Exception:\n        fixed = text.replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n        data = json.loads(fixed)\n\n    if road_id not in data:\n        raise ValueError(f\"{json_path} 中没有 {road_id} 条目\")\n\n    node = data[road_id]\n    if \"lane_divider\" not in node:\n        raise ValueError(f\"{json_path} 的 {road_id} 缺少 lane_divider\")\n\n    lane_div = np.array(node[\"lane_divider\"], dtype=float)  # (N,2) -> [lon,lat]\n    if lane_div.ndim != 2 or lane_div.shape[1] != 2 or lane_div.shape[0] < 2:\n        raise ValueError(f\"{road_id} 的 lane_divider 至少需要两个 [lon,lat] 点\")\n\n    # Center: prefer override (lat,lon → lon,lat)\n    if road_id in CENTER_OVERRIDES_LATLON:\n        lat, lon = CENTER_OVERRIDES_LATLON[road_id]\n        center = np.array([lon, lat], dtype=float)\n    else:\n        center = None\n        for k in (\"center\", \"center_point\", \"centerPoint\"):\n            if k in node and isinstance(node[k], (list, tuple)) and len(node[k]) == 2:\n                center = np.array(node[k], dtype=float)\n                break\n        if center is None:\n            center = lane_div[-1].copy()  # fallback\n\n    return lane_div, center\n\ndef describe_series(x: np.ndarray):\n    x = x[~np.isnan(x)]\n    if x.size == 0:\n    return None\n    return {\n        \"count\": int(x.size),\n        \"min\": float(np.min(x)),\n        \"p10\": float(np.percentile(x, 10)),\n        \"p25\": float(np.percentile(x, 25)),\n        \"median\": float(np.percentile(x, 50)),\n        \"p75\": float(np.percentile(x, 75)),\n        \"p90\": float(np.percentile(x, 90)),\n        \"p95\": float(np.percentile(x, 95)),\n        \"max\": float(np.max(x)),\n        \"mean\": float(np.mean(x)),\n        \"std\": float(np.std(x, ddof=1)) if x.size > 1 else 0.0,\n    }\n\n# =========================\n# Core pipeline (per road)\n# =========================\ndef process_road(road_id: str):\n    refined_path = REFINED[road_id]\n    refined = pd.read_csv(refined_path)\n    direction = pd.read_csv(DIRECTION_PATH)\n\n    # Filter by direction/road and join\n    keys = [\"vehicle_id\", \"date\", \"seg_id\", \"road_id\"]\n    direction = direction[(direction[\"road_id\"] == road_id) & (direction[\"direction\"].isin(DIRECTIONS_USED))]\n    df = refined.merge(direction[keys + [\"direction\"]], on=keys, how=\"inner\")\n\n    # Stop decision: prefer end_time; otherwise fallback to low speed\n    def is_stop(row) -> bool:\n        et = str(row.get(\"end_time\", \"\")).strip()\n        if et and et.lower() != \"nan\":\n            return True\n        try:\n            spd = float(row.get(\"speed\", 0.0))\n        except Exception:\n            spd = 0.0\n        return spd <= SPEED_THRESH\n    df = df[df.apply(is_stop, axis=1)].copy()\n    if len(df) == 0:\n        return {\n            \"stopline_segment\": None,\n            \"analysis\": {\"n_points\": 0, \"note\": \"no stop points after filter\"}\n        }\n\n    # Centerline and center point\n    lane_div_ll, center_ll = load_intersection(INTERSECTION_JSON_PATH, road_id)\n\n    # Local projection\n    crs_geo = CRS.from_epsg(4326)\n    crs_loc = best_local_crs(center_ll[0], center_ll[1])  # center_ll = (lon,lat)\n    to_xy = Transformer.from_crs(crs_geo, crs_loc, always_xy=True)\n    to_ll = Transformer.from_crs(crs_loc, crs_geo, always_xy=True)\n\n    def ll_to_xy(arr_ll):\n        x, y = to_xy.transform(arr_ll[:, 0], arr_ll[:, 1])  # lon, lat\n        return np.column_stack([x, y])\n\n    def one_ll_to_xy(lon, lat):\n        x, y = to_xy.transform(lon, lat)\n        return np.array([x, y])\n\n    lane_div_xy = ll_to_xy(lane_div_ll)\n    center_xy = one_ll_to_xy(center_ll[0], center_ll[1])\n\n    # ---- Direction determination (key correction) ----\n    # Take the last lane_divider segment direction and force it toward the center\n    v = lane_div_xy[-1] - lane_div_xy[-2]\n    v_hat = unit(v)\n    to_center_vec = center_xy - lane_div_xy[-1]\n    if np.dot(v_hat, to_center_vec) < 0:\n        v_hat = -v_hat\n\n    n_hat = np.array([-v_hat[1], v_hat[0]])\n\n    # Compute s_raw (along-road coordinate relative to center; increases toward center)\n    pts_ll = df[[\"longitude\", \"latitude\"]].to_numpy(dtype=float)\n    pts_xy = ll_to_xy(pts_ll)\n    s_raw = np.einsum(\"ij,j->i\", pts_xy - center_xy, v_hat)\n\n    # If most stops have s_raw>0 (upstream turned positive), flip direction to enforce upstream as s≤0\n    share_pos = float(np.nanmean(s_raw > 0))\n    if share_pos > 0.5:\n        v_hat = -v_hat\n        n_hat = np.array([-v_hat[1], v_hat[0]])\n        s_raw = np.einsum(\"ij,j->i\", pts_xy - center_xy, v_hat)\n\n    # Keep only upstream (west approach) stop points within distance window\n    df[\"s_m\"] = s_raw\n    df = df[(df[\"s_m\"] <= 0.0) & (df[\"s_m\"] >= -MAX_UPSTREAM_M)].copy()\n    if len(df) == 0:\n        return {\n            \"stopline_segment\": None,\n            \"analysis\": {\"n_points\": 0, \"note\": \"no upstream stop points after orientation check\"}\n        }\n\n    # Stopline: take the chosen quantile (s ≤ 0). Smaller (more negative) stop_s → fewer beyond-line points.\n    stop_s = float(np.nanpercentile(df[\"s_m\"].to_numpy(), int(STOP_Q * 100)))\n    # Clamp stop_s to the window\n    stop_s = min(0.0, max(stop_s, -MAX_UPSTREAM_M))\n\n    # Beyond line: closer to center (s > stop_s)\n    df[\"beyond_line\"] = df[\"s_m\"] > stop_s\n    frac_beyond = float(df[\"beyond_line\"].mean())\n\n    # Stopline segment (20 m normal)\n    stop_pt_xy = center_xy + stop_s * v_hat\n    half_len = 10.0\n    p_left_xy = stop_pt_xy - half_len * n_hat\n    p_right_xy = stop_pt_xy + half_len * n_hat\n\n    def xy_to_ll(xy):\n        lon, lat = to_ll.transform(xy[0], xy[1])\n        return [float(lon), float(lat)]\n\n    stopline_segment = [xy_to_ll(p_left_xy), xy_to_ll(p_right_xy)]\n\n    # Analysis: include self-check metrics to verify the upstream constraint (s≤0)\n    analyse = {\n        \"params\": {\n            \"directions_used\": sorted(list(DIRECTIONS_USED)),\n            \"speed_thresh_mps\": SPEED_THRESH,\n            \"max_upstream_m\": MAX_UPSTREAM_M,\n            \"quantile_for_stopline\": STOP_Q,\n        },\n        \"orientation_check\": {\n            \"share_s_raw_pos_before_flip\": share_pos,\n            \"final_share_s_pos\": float(np.nanmean(df[\"s_m\"] > 0)),\n            \"expect_upstream_nonpos\": True\n        },\n        \"stopline\": {\n            \"stop_s_m\": stop_s,                           # ≤ 0\n            \"distance_to_center_m\": abs(stop_s),\n            \"beyond_fraction\": frac_beyond,               # approximately (1-STOP_Q)\n            \"constraint_ok\": frac_beyond <= (1.0 - STOP_Q + 1e-6)\n        },\n        \"overall\": {\n            \"n_points\": int(len(df)),\n            \"s_m_summary\": describe_series(df[\"s_m\"].to_numpy(float)),\n            \"unique_vehicles\": int(df[\"vehicle_id\"].nunique()) if \"vehicle_id\" in df.columns else None,\n            \"unique_segments\": int(df[\"seg_id\"].nunique()) if \"seg_id\" in df.columns else None,\n        }\n    }\n\n    return {\n        \"stopline_segment\": stopline_segment,\n        \"analysis\": analyse\n    }\n\n# =========================\n# Entry point: write two JSON files\n# =========================\ndef main():\n    Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n\n    stoplines = {}\n    analyses = {}\n\n    for rid in (\"A0003\", \"A0008\"):\n        result = process_road(rid)\n        stoplines[rid] = {\n            \"stopline_segment\": result[\"stopline_segment\"]\n        }\n        analyses[rid] = result[\"analysis\"]\n\n    # 1) File with stopline endpoints only (target format)\n    with open(f\"/home/mw/project/stopline_west.json\", \"w\", encoding=\"utf-8\") as f:\n        json.dump(stoplines, f, ensure_ascii=False, indent=2)\n\n    # 2) Analysis file (both roads combined for inspection)\n    with open(f\"/home/mw/project/analyse_stopline_w.json\", \"w\", encoding=\"utf-8\") as f:\n        json.dump(analyses, f, ensure_ascii=False, indent=2)\n\n    print(\"[OK] 输出完成：\")\n    print(f\"/home/mw/project/stopline_west.json\")\n    print(f\"/home/mw/project/analyse_stopline_w.json\")\n\nif __name__ == \"__main__\":\n    main()\n"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}