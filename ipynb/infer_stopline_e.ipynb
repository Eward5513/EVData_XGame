{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Auto-generated from `infer_stopline_e.py`\n\nGenerated on 2025-11-09T22:01:34.\n\nThis notebook was created programmatically to mirror the original Python script.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nimport sys\nproject_root = str(Path.cwd().parent.resolve())\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport json, math\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nfrom shapely.geometry import LineString, Point\nfrom pyproj import CRS, Transformer\n\n# =========================\n# 硬编码路径 & 参数\n# =========================\nDATA_DIR = \"/home/tzhang174/EVData_XGame\"\nREFINED = {\n    \"A0003\": f\"/home/mw/project/A0003_refined.csv\",\n    \"A0008\": f\"/home/mw/project/A0008_refined.csv\",\n}\nDIRECTION_PATH = f\"/home/mw/project/direction.csv\"\nINTERSECTION_JSON_PATH = f\"/home/mw/project/intersection_A.json\"  # JSON，包含 lane_divider\nOUT_DIR = f\"{DATA_DIR}/data\"\n\n# 东侧进口相关方向\nDIRECTIONS_USED = {\"A1-2\", \"B2-2\", \"B3-1\"}\n\n# 驻停判定与采样窗口\nSPEED_THRESH = 5.0 / 3.6   # m/s，对应 5 km/h\nMAX_UPSTREAM_M = 120.0     # 仅使用中心点上游这段距离\nSTOP_Q = 0.95              # 90% 分位 → 约 10% 越过；想更少越过可调更大(如0.95)\n\n# 覆盖中心点（你提供的是 (lat, lon)，脚本会转成 (lon, lat)）\nCENTER_OVERRIDES_LATLON = {\n    \"A0003\": (32.34513595, 123.15253329),\n    \"A0008\": (32.32708227, 123.18126882),\n}\n\n# =========================\n# 工具函数\n# =========================\ndef best_local_crs(lon, lat):\n    utm_zone = int(math.floor((lon + 180) / 6) + 1)\n    return CRS.from_epsg(32600 + utm_zone if lat >= 0 else 32700 + utm_zone)\n\ndef unit(v):\n    n = np.linalg.norm(v)\n    return v if n == 0 else v / n\n\ndef load_intersection(json_path: str, road_id: str):\n    text = Path(json_path).read_text(encoding=\"utf-8\").strip()\n    try:\n        data = json.loads(text)\n    except Exception:\n        fixed = text.replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n        data = json.loads(fixed)\n\n    if road_id not in data:\n        raise ValueError(f\"{json_path} 中没有 {road_id} 条目\")\n    node = data[road_id]\n    if \"lane_divider\" not in node:\n        raise ValueError(f\"{json_path} 的 {road_id} 缺少 lane_divider\")\n\n    lane_div = np.array(node[\"lane_divider\"], dtype=float)  # (N,2) -> [lon,lat]\n    if lane_div.ndim != 2 or lane_div.shape[1] != 2 or lane_div.shape[0] < 2:\n        raise ValueError(f\"{road_id} 的 lane_divider 至少需要两个 [lon,lat] 点\")\n\n    # 中心点：优先使用覆盖（lat,lon -> lon,lat）\n    if road_id in CENTER_OVERRIDES_LATLON:\n        lat, lon = CENTER_OVERRIDES_LATLON[road_id]\n        center = np.array([lon, lat], dtype=float)\n    else:\n        center = None\n        for k in (\"center\", \"center_point\", \"centerPoint\"):\n            if k in node and isinstance(node[k], (list, tuple)) and len(node[k]) == 2:\n                center = np.array(node[k], dtype=float)\n                break\n        if center is None:\n            center = lane_div[-1].copy()  # 兜底\n\n    return lane_div, center\n\ndef describe_series(x: np.ndarray):\n    x = x[~np.isnan(x)]\n    if x.size == 0:\n        return None\n    return {\n        \"count\": int(x.size),\n        \"min\": float(np.min(x)),\n        \"p10\": float(np.percentile(x, 10)),\n        \"p25\": float(np.percentile(x, 25)),\n        \"median\": float(np.percentile(x, 50)),\n        \"p75\": float(np.percentile(x, 75)),\n        \"p90\": float(np.percentile(x, 90)),\n        \"p95\": float(np.percentile(x, 95)),\n        \"max\": float(np.max(x)),\n        \"mean\": float(np.mean(x)),\n        \"std\": float(np.std(x, ddof=1)) if x.size > 1 else 0.0,\n    }\n\n# =========================\n# 核心流程（每个路口）\n# =========================\ndef process_road(road_id: str):\n    refined_path = REFINED[road_id]\n    refined = pd.read_csv(refined_path)\n    direction = pd.read_csv(DIRECTION_PATH)\n\n    # 方向/路口筛选并关联\n    keys = [\"vehicle_id\", \"date\", \"seg_id\", \"road_id\"]\n    direction = direction[(direction[\"road_id\"] == road_id) & (direction[\"direction\"].isin(DIRECTIONS_USED))]\n    df = refined.merge(direction[keys + [\"direction\"]], on=keys, how=\"inner\")\n\n    # 驻停判定：end_time 优先；无则速度兜底\n    def is_stop(row) -> bool:\n        et = str(row.get(\"end_time\", \"\")).strip()\n        if et and et.lower() != \"nan\":\n            return True\n        try:\n            spd = float(row.get(\"speed\", 0.0))\n        except Exception:\n            spd = 0.0\n        return spd <= SPEED_THRESH\n    df = df[df.apply(is_stop, axis=1)].copy()\n    if len(df) == 0:\n        return {\n            \"stopline_segment\": None,\n            \"analysis\": {\"n_points\": 0, \"note\": \"no stop points after filter\"}\n        }\n\n    # 中心线与中心点\n    lane_div_ll, center_ll = load_intersection(INTERSECTION_JSON_PATH, road_id)\n\n    # 局部投影\n    crs_geo = CRS.from_epsg(4326)\n    crs_loc = best_local_crs(center_ll[0], center_ll[1])  # center_ll = (lon,lat)\n    to_xy = Transformer.from_crs(crs_geo, crs_loc, always_xy=True)\n    to_ll = Transformer.from_crs(crs_loc, crs_geo, always_xy=True)\n\n    def ll_to_xy(arr_ll):\n        x, y = to_xy.transform(arr_ll[:, 0], arr_ll[:, 1])  # lon, lat\n        return np.column_stack([x, y])\n\n    def one_ll_to_xy(lon, lat):\n        x, y = to_xy.transform(lon, lat)\n        return np.array([x, y])\n\n    lane_div_xy = ll_to_xy(lane_div_ll)\n    center_xy = one_ll_to_xy(center_ll[0], center_ll[1])\n\n    # ---- 方向确定（自动自检翻转，确保上游为 s<=0）----\n    v = lane_div_xy[-1] - lane_div_xy[-2]\n    v_hat = unit(v)\n    to_center_vec = center_xy - lane_div_xy[-1]\n    if np.dot(v_hat, to_center_vec) < 0:\n        v_hat = -v_hat\n    n_hat = np.array([-v_hat[1], v_hat[0]])\n\n    # s_raw：相对中心的沿路坐标（朝向中心增大）\n    pts_ll = df[[\"longitude\", \"latitude\"]].to_numpy(dtype=float)\n    pts_xy = ll_to_xy(pts_ll)\n    s_raw = np.einsum(\"ij,j->i\", pts_xy - center_xy, v_hat)\n\n    # 多数应在上游（s<=0）；若多数s_raw>0，翻转\n    share_pos = float(np.nanmean(s_raw > 0))\n    if share_pos > 0.5:\n        v_hat = -v_hat\n        n_hat = np.array([-v_hat[1], v_hat[0]])\n        s_raw = np.einsum(\"ij,j->i\", pts_xy - center_xy, v_hat)\n\n    # 仅用上游窗口\n    df[\"s_m\"] = s_raw\n    df = df[(df[\"s_m\"] <= 0.0) & (df[\"s_m\"] >= -MAX_UPSTREAM_M)].copy()\n    if len(df) == 0:\n        return {\n            \"stopline_segment\": None,\n            \"analysis\": {\"n_points\": 0, \"note\": \"no upstream stop points after orientation check\"}\n        }\n\n    # ====== 严格控制越线比例 ≤ (1-STOP_Q) ======\n    s_vals = np.sort(df[\"s_m\"].to_numpy(float))  # 更负→更上游\n    N = s_vals.size\n    m_allow = int(math.floor((1.0 - STOP_Q) * N))  # 允许越线的最大数量\n    idx = max(0, N - m_allow - 1)                  # 选阈值，使严格 > 阈值 的个数 ≤ m_allow\n    stop_s = float(s_vals[idx])\n    stop_s = min(0.0, max(stop_s, -MAX_UPSTREAM_M))  # 约束在窗口内\n\n    df[\"beyond_line\"] = df[\"s_m\"] > stop_s\n    frac_beyond = float(df[\"beyond_line\"].mean())\n\n    # 停止线段（20m 垂线）\n    stop_pt_xy = center_xy + stop_s * v_hat\n    half_len = 10.0\n    p_left_xy = stop_pt_xy - half_len * n_hat\n    p_right_xy = stop_pt_xy + half_len * n_hat\n\n    def xy_to_ll(xy):\n        lon, lat = to_ll.transform(xy[0], xy[1])\n        return [float(lon), float(lat)]\n\n    stopline_segment = [xy_to_ll(p_left_xy), xy_to_ll(p_right_xy)]\n\n    # 分析\n    analyse = {\n        \"params\": {\n            \"directions_used\": sorted(list(DIRECTIONS_USED)),\n            \"speed_thresh_mps\": SPEED_THRESH,\n            \"max_upstream_m\": MAX_UPSTREAM_M,\n            \"quantile_for_stopline\": STOP_Q,\n        },\n        \"orientation_check\": {\n            \"share_s_raw_pos_before_flip\": share_pos,\n            \"final_share_s_pos\": float(np.nanmean(df[\"s_m\"] > 0)),\n            \"expect_upstream_nonpos\": True\n        },\n        \"stopline\": {\n            \"stop_s_m\": stop_s,                           # ≤ 0\n            \"distance_to_center_m\": abs(stop_s),\n            \"beyond_fraction\": frac_beyond,               # 严格 ≤ (1-STOP_Q)\n            \"constraint_ok\": frac_beyond <= (1.0 - STOP_Q + 1e-12)\n        },\n        \"overall\": {\n            \"n_points\": int(len(df)),\n            \"s_m_summary\": describe_series(df[\"s_m\"].to_numpy(float)),\n            \"unique_vehicles\": int(df[\"vehicle_id\"].nunique()) if \"vehicle_id\" in df.columns else None,\n            \"unique_segments\": int(df[\"seg_id\"].nunique()) if \"seg_id\" in df.columns else None,\n        }\n    }\n\n    return {\n        \"stopline_segment\": stopline_segment,\n        \"analysis\": analyse\n    }\n\n# =========================\n# 主入口：只写两个 JSON 文件（EAST）\n# =========================\ndef main():\n    Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n\n    stoplines = {}\n    analyses = {}\n\n    for rid in (\"A0003\", \"A0008\"):\n        result = process_road(rid)\n        stoplines[rid] = {\"stopline_segment\": result[\"stopline_segment\"]}\n        analyses[rid] = result[\"analysis\"]\n\n    with open(f\"/home/mw/project/stopline_east.json\", \"w\", encoding=\"utf-8\") as f:\n        json.dump(stoplines, f, ensure_ascii=False, indent=2)\n\n    with open(f\"/home/mw/project/analyse_stopline_east.json\", \"w\", encoding=\"utf-8\") as f:\n        json.dump(analyses, f, ensure_ascii=False, indent=2)\n\n    print(\"[OK] 输出完成：\")\n    print(f\"/home/mw/project/stopline_east.json\")\n    print(f\"/home/mw/project/analyse_stopline_east.json\")\n\nif __name__ == \"__main__\":\n    main()\n"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}