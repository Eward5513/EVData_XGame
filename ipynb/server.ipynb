{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Auto-generated from `visualization/backend/server.py`\n\nGenerated on 2025-11-09T22:01:34.\n\nThis notebook was created programmatically to mirror the original Python script.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nimport sys\nproject_root = str(Path.cwd().parent.resolve())\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from typing import Dict, List, Tuple, Set, Optional, Union\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport http.server\nimport socketserver\nimport json\nimport pandas as pd\nimport os\nfrom urllib.parse import urlparse, parse_qs\n\n# CSV/data base path moved under repository data directory\nCSV_BASE_PATH = '../../data'\nTRAFFIC_SIGNAL_FILE = '/home/mw/project/traffic_signal.csv'\nDIRECTION_FILE = '/home/mw/project/direction.csv'\nSTOPLINE_FILE = '/home/mw/project/stopline.json'\n\n# Global variable to cache direction data\ndirection_data = None\n\ndef load_direction_data():\n    \"\"\"/home/mw/project/Load direction data from direction.csv\"\"\"\n    global direction_data\n    if direction_data is None:\n        try:\n            direction_data = pd.read_csv(DIRECTION_FILE)\n            print(f\"Loaded direction data: {len(direction_data)} records\")\n        except FileNotFoundError:\n            print(f\"Direction file not found: {DIRECTION_FILE}\")\n            direction_data = pd.DataFrame()  # Empty dataframe as fallback\n        except Exception as e:\n            print(f\"Error loading direction data: {e}\")\n            direction_data = pd.DataFrame()\n    return direction_data\n\ndef _prefer_merged_csv_path(road_id: str) -> str:\n    \"\"\"Return merged CSV path if exists, else fallback to split CSV.\"\"\"\n    merged = f'/home/mw/project/{road_id}_merged.csv'\n    split = f'/home/mw/project/{road_id}_split.csv'\n    return merged if os.path.exists(merged) else split\n\ndef _csv_path_for_source(road_id: str, source: Optional[str]) -> str:\n    \"\"\"Resolve CSV path based on explicit source selection.\n    source in {'split','original','before'} => split\n    source in {'merged','after','merge'} => merged if exists else split\n    source in {'refined','skeleton'} => refined if exists else merged if exists else split\n    else => prefer merged\n    \"\"\"\n    s = (str(source).strip().lower() if source is not None else '')\n    refined = f'/home/mw/project/{road_id}_refined.csv'\n    merged = f'/home/mw/project/{road_id}_merged.csv'\n    split = f'/home/mw/project/{road_id}_split.csv'\n    if s in ('split', 'original', 'before'):\n        return split\n    if s in ('merged', 'after', 'merge'):\n        return merged if os.path.exists(merged) else split\n    if s in ('refined', 'skeleton'):\n        return refined if os.path.exists(refined) else (merged if os.path.exists(merged) else split)\n    return merged if os.path.exists(merged) else split\n\ndef parse_directions_param(direction_value):\n    \"\"\"Parse 'direction' query parameter allowing single, comma-separated, or repeated values.\n    Returns a list of uppercase direction codes (e.g., ['A1','B2']).\n    \"\"\"\n    if direction_value is None:\n        return []\n    values = direction_value if isinstance(direction_value, list) else [direction_value]\n    results = []\n    for v in values:\n        for part in str(v).split(','):\n            code = part.strip().upper()\n            if code:\n                results.append(code)\n    # de-duplicate while preserving order\n    seen = set()\n    deduped = []\n    for code in results:\n        if code not in seen:\n            seen.add(code)\n            deduped.append(code)\n    return deduped\n\n## Movement-based filters are deprecated; keep codebase lean by removing loader\n\ndef load_vehicle_data(vehicle_id=None,\n                      road_id='A0003',\n                      vehicle_count=None,\n                      date=None,\n                      start_time=None,\n                      end_time=None,\n                      direction=None,\n                      source=None):\n    \"\"\"\n    Load data for specified vehicle ID(s) and road ID using pandas\n    \n    Args:\n        vehicle_id: Single vehicle ID to load (for single mode)\n        road_id: Road intersection ID \n        vehicle_count: Number of vehicles to load from the beginning (for batch mode)\n        date: Date filter in YYYY-MM-DD format (optional)\n        start_time: Start time filter in HH:MM format (optional)\n        end_time: End time filter in HH:MM format (optional)\n        direction: Direction filter (e.g., A1-1/A1-2/B1-1/B1-2/A2-*/A3-* or C) (optional)\n        source: Data source selector (split/merged/refined)\n    \"\"\"\n    try:\n        # Build CSV file path based on road_id and selected source\n        csv_file_path = _csv_path_for_source(road_id, source)\n        \n        # Read CSV file\n        df = pd.read_csv(csv_file_path)\n        \n        # Filter by date if specified\n        if date:\n            df = df[df['date'] == date]\n        \n        # Filter by time range if specified\n        if start_time and end_time:\n            # Convert time_stamp to time for comparison\n            df['time_only'] = pd.to_datetime(df['time_stamp']).dt.time\n            start_time_obj = pd.to_datetime(start_time, format='%H:%M').time()\n            end_time_obj = pd.to_datetime(end_time, format='%H:%M').time()\n            df = df[(df['time_only'] >= start_time_obj) & (df['time_only'] <= end_time_obj)]\n            df = df.drop('time_only', axis=1)  # Remove temporary column\n        \n        # Filter data based on mode\n        if start_time and end_time:\n            # Time range mode: get all vehicles in the time range\n            vehicle_data = df\n        elif vehicle_count is not None:\n            # Batch mode: get vehicles with ID <= vehicle_count\n            vehicle_data = df[df['vehicle_id'] <= vehicle_count]\n        else:\n            # Single mode: get specific vehicle (default to 1 if not specified)\n            if vehicle_id is None:\n                vehicle_id = 1\n            vehicle_data = df[df['vehicle_id'] == vehicle_id]\n        \n        # Apply direction filter if specified (single or multiple)\n        if direction:\n            directions = parse_directions_param(direction)\n            direction_df = load_direction_data()\n            if not direction_df.empty and directions:\n                # Filter direction data by specified directions and road_id\n                filtered_directions = direction_df[\n                    (direction_df['direction'].astype(str).str.upper().isin(directions)) &\n                    (direction_df['road_id'] == road_id)\n                ]\n\n                # Get vehicle_ids and dates that match the direction filter\n                if date:\n                    filtered_directions = filtered_directions[filtered_directions['date'] == date]\n\n                if not filtered_directions.empty:\n                    # Create a set of (vehicle_id, date, seg_id) triplets for faster lookup\n                    valid_triplets = set(\n                        (int(v), str(d), int(s))\n                        for v, d, s in zip(\n                            filtered_directions['vehicle_id'],\n                            filtered_directions['date'],\n                            filtered_directions['seg_id'],\n                        )\n                    )\n\n                    def dir_match(row):\n                        try:\n                            veh_id = int(row['vehicle_id'])\n                        except Exception:\n                            try:\n                                veh_id = int(float(row['vehicle_id']))\n                            except Exception:\n                                veh_id = 0\n                        try:\n                            seg_val = int(row['seg_id'])\n                        except Exception:\n                            try:\n                                seg_val = int(float(row['seg_id']))\n                            except Exception:\n                                seg_val = 0\n                        return (veh_id, str(row['date']), seg_val) in valid_triplets\n\n                    vehicle_data = vehicle_data[\n                        vehicle_data.apply(dir_match, axis=1)\n                    ]\n                else:\n                    # No vehicles match the direction filter\n                    vehicle_data = vehicle_data.iloc[0:0]  # Empty dataframe with same structure\n        # Movement-based filters removed\n        \n        # Convert to list of dictionaries format\n        data_list = []\n        for _, row in vehicle_data.iterrows():\n            data_point = {\n                'vehicle_id': int(row['vehicle_id']),\n                'collectiontime': int(row['collectiontime']),\n                'date': str(row['date']),\n                'time_stamp': str(row['time_stamp']),\n                'road_id': str(row['road_id']),\n                'longitude': float(row['longitude']),\n                'latitude': float(row['latitude']),\n                'speed': float(row['speed']),\n                'acceleratorpedal': float(row['acceleratorpedal']),\n                'brakestatus': int(row['brakestatus'])\n            }\n            \n            # seg_id if present (from split files)\n            if 'seg_id' in row and pd.notna(row['seg_id']):\n                try:\n                    data_point['seg_id'] = int(row['seg_id'])\n                except Exception:\n                    data_point['seg_id'] = 0\n                \n            # Add optional new fields if they exist in the CSV\n            if 'gearnum' in row and pd.notna(row['gearnum']) and str(row['gearnum']).strip():\n                data_point['gearnum'] = str(row['gearnum'])\n            else:\n                data_point['gearnum'] = 'N/A'\n                \n            if 'havebrake' in row and pd.notna(row['havebrake']) and str(row['havebrake']).strip():\n                data_point['havebrake'] = str(row['havebrake'])\n            else:\n                data_point['havebrake'] = 'N/A'\n                \n            if 'havedriver' in row and pd.notna(row['havedriver']) and str(row['havedriver']).strip():\n                data_point['havedriver'] = str(row['havedriver'])\n            else:\n                data_point['havedriver'] = 'N/A'\n            # Optional end_time (present in merged CSV for merged stationary points)\n            if 'end_time' in row and pd.notna(row['end_time']) and str(row['end_time']).strip():\n                data_point['end_time'] = str(row['end_time'])\n            data_list.append(data_point)\n        \n        return data_list\n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        return []\n\nclass CustomHTTPRequestHandler(http.server.BaseHTTPRequestHandler):\n    \"\"\"\n    Custom HTTP request handler for the vehicle data API\n    \"\"\"\n    \n    def _set_cors_headers(self):\n        \"\"\"Set CORS headers for cross-origin requests\"\"\"\n        self.send_header('Access-Control-Allow-Origin', '*')\n        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')\n        self.send_header('Access-Control-Allow-Headers', 'Content-Type')\n    \n    def _send_json_response(self, data, status_code=200):\n        \"\"\"Send JSON response with proper headers\"\"\"\n        self.send_response(status_code)\n        self.send_header('Content-type', 'application/json')\n        self._set_cors_headers()\n        self.end_headers()\n        \n        response_json = json.dumps(data, ensure_ascii=False, indent=2)\n        self.wfile.write(response_json.encode('utf-8'))\n    \n    def _parse_query_params(self):\n        \"\"\"Parse URL query parameters\"\"\"\n        parsed_url = urlparse(self.path)\n        query_params = parse_qs(parsed_url.query)\n        \n        # Convert single-item lists to values; keep lists when multiple are provided\n        params = {}\n        for key, value_list in query_params.items():\n            if not value_list:\n                params[key] = None\n            elif len(value_list) == 1:\n                params[key] = value_list[0]\n            else:\n                params[key] = value_list\n        \n        return parsed_url.path, params\n    \n    def do_OPTIONS(self):\n        \"\"\"Handle preflight OPTIONS requests for CORS\"\"\"\n        self.send_response(200)\n        self._set_cors_headers()\n        self.end_headers()\n    \n    def do_GET(self):\n        \"\"\"Handle GET requests\"\"\"\n        try:\n            path, params = self._parse_query_params()\n            \n            if path == '/':\n                self._handle_index()\n            elif path == '/health':\n                self._handle_health_check()\n            elif path == '/api/vehicle/data':\n                self._handle_vehicle_data(params)\n            elif path == '/api/vehicle/summary':\n                self._handle_vehicle_summary(params)\n            elif path == '/api/vehicle/dates':\n                self._handle_available_dates(params)\n            elif path == '/api/traffic/cycles':\n                self._handle_traffic_cycles(params)\n            elif path == '/api/traffic/status':\n                self._handle_traffic_status(params)\n            elif path == '/api/speed/analysis':\n                self._handle_speed_analysis(params)\n            elif path == '/api/speed/traffic-lights':\n                self._handle_speed_traffic_lights(params)\n            elif path == '/api/speed/time-range':\n                self._handle_speed_time_range(params)\n            elif path == '/api/topology/intersection':\n                self._handle_intersection_topology(params)\n            elif path == '/api/intersection/inference':\n                self._handle_intersection_inference(params)\n            elif path == '/api/intersection/centerlines':\n                self._handle_intersection_centerlines(params)\n            elif path == '/api/stopline/west':\n                self._handle_stopline_west(params)\n            elif path == '/api/stopline/east':\n                self._handle_stopline_east(params)\n            elif path == '/api/stopline/all':\n                self._handle_stopline_all(params)\n            elif path == '/api/excluded/data':\n                self._handle_excluded_data(params)\n            elif path == '/api/direction/segments':\n                self._handle_direction_segments(params)\n            elif path == '/api/trajectory/segment':\n                self._handle_trajectory_segment(params)\n            elif path == '/api/crossover/data':\n                self._handle_crossover_data(params)\n            elif path == '/api/crossover/time':\n                self._handle_crossover_time(params)\n            elif path == '/api/raw/data':\n                self._handle_raw_data(params)\n            elif path == '/api/raw/dates':\n                self._handle_raw_dates(params)\n            else:\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'Endpoint not found'\n                }, 404)\n                \n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': str(e)\n            }, 500)\n    \n    def _handle_index(self):\n        \"\"\"Handle root endpoint\"\"\"\n        response = {\n            'message': 'Geographic Data Visualization Backend Service',\n            'version': '1.0.0',\n            'endpoints': [\n                '/api/vehicle/data - Get vehicle trajectory data',\n                '/api/vehicle/summary - Get vehicle data summary',\n                '/api/vehicle/dates - Get available dates',\n                '/api/traffic/cycles - Get available cycles for traffic lights',\n                '/api/traffic/status - Get traffic light status for specific cycle',\n                '/api/speed/analysis - Get speed analysis data for specific vehicle or time range',\n                '/api/speed/traffic-lights - Get traffic light data for speed analysis time range',\n                '/api/topology/intersection - Get intersection topology GeoJSON',\n                '/api/speed/time-range - Get available time range for specific date',\n                '/api/crossover/data - Get crossover (all directions) trajectory points',\n                '/api/crossover/time - Get crossover time intervals (all directions)',\n                '/api/raw/data - Get raw CSV trajectory data',\n                '/api/raw/dates - Get available raw dates',\n                '/health - Health check'\n            ]\n        }\n        self._send_json_response(response)\n    \n    def _handle_health_check(self):\n        \"\"\"Handle health check endpoint\"\"\"\n        response = {\n            'status': 'healthy',\n            'message': 'Server is running normally'\n        }\n        self._send_json_response(response)\n    \n    def _handle_vehicle_data(self, params):\n        \"\"\"Handle vehicle data endpoint\"\"\"\n        try:\n            # Get road ID from query parameters, default to A0003\n            road_id = params.get('road_id', 'A0003')\n            source = params.get('source')\n            \n            # Get date filter from query parameters\n            date = params.get('date')\n            \n            # Get direction/movement filters and source\n            direction = params.get('direction')\n            \n            # Get data point limit, default to return all data\n            limit = params.get('limit')\n            if limit:\n                limit = int(limit)\n            \n            # Check mode: time_range, batch, or single\n            start_time = params.get('start_time')\n            end_time = params.get('end_time')\n            vehicle_count_param = params.get('vehicle_count')\n            \n            if start_time and end_time:\n                # Time range mode: load all vehicles in time range\n                data = load_vehicle_data(\n                    road_id=road_id,\n                    date=date,\n                    start_time=start_time,\n                    end_time=end_time,\n                    direction=direction,\n                    source=source\n                )\n                vehicle_id = None  # Not applicable in time range mode\n                vehicle_count = None  # Will be calculated from data\n            elif vehicle_count_param:\n                # Batch mode: load multiple vehicles\n                vehicle_count = int(vehicle_count_param)\n                data = load_vehicle_data(\n                    road_id=road_id,\n                    vehicle_count=vehicle_count,\n                    date=date,\n                    direction=direction,\n                    source=source\n                )\n                vehicle_id = None  # Not applicable in batch mode\n            else:\n                # Single mode: load specific vehicle\n                vehicle_id = int(params.get('vehicle_id', 1))\n                vehicle_count = None  # Not applicable in single mode\n                data = load_vehicle_data(\n                    vehicle_id=vehicle_id,\n                    road_id=road_id,\n                    date=date,\n                    direction=direction,\n                    source=source\n                )\n            \n            if limit and limit > 0:\n                data = data[:limit]\n            \n            # Build response based on mode\n            if start_time and end_time:\n                # Time range mode response\n                unique_vehicles = list(set([point['vehicle_id'] for point in data]))\n                response = {\n                    'status': 'success',\n                    'mode': 'time_range',\n                    'start_time': start_time,\n                    'end_time': end_time,\n                    'vehicle_count': len(unique_vehicles),\n                    'vehicle_ids': unique_vehicles,\n                    'total_points': len(data),\n                    'data': data\n                }\n            elif vehicle_count:\n                # Batch mode response\n                unique_vehicles = list(set([point['vehicle_id'] for point in data]))\n                response = {\n                    'status': 'success',\n                    'mode': 'batch',\n                    'vehicle_count': len(unique_vehicles),\n                    'vehicle_ids': unique_vehicles,\n                    'total_points': len(data),\n                    'data': data\n                }\n            else:\n                # Single mode response\n                response = {\n                    'status': 'success',\n                    'mode': 'single',\n                    'vehicle_id': vehicle_id,\n                    'total_points': len(data),\n                    'data': data\n                }\n            \n            self._send_json_response(response)\n            \n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': str(e)\n            }, 500)\n    \n    def _handle_vehicle_summary(self, params):\n        \"\"\"Handle vehicle summary endpoint\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            source = params.get('source')\n            \n            # Get date filter from query parameters\n            date = params.get('date')\n            \n            # Get direction filter from query parameters (single or multiple)\n            direction = params.get('direction')\n            \n            # Check mode: time_range, batch, or single\n            start_time = params.get('start_time')\n            end_time = params.get('end_time')\n            vehicle_count_param = params.get('vehicle_count')\n            \n            if start_time and end_time:\n                # Time range mode: load all vehicles in time range\n                data = load_vehicle_data(\n                    road_id=road_id,\n                    date=date,\n                    start_time=start_time,\n                    end_time=end_time,\n                    direction=direction,\n                    source=source\n                )\n                vehicle_id = None  # Not applicable in time range mode\n                vehicle_count = None  # Will be calculated from data\n            elif vehicle_count_param:\n                # Batch mode: load multiple vehicles\n                vehicle_count = int(vehicle_count_param)\n                data = load_vehicle_data(\n                    road_id=road_id,\n                    vehicle_count=vehicle_count,\n                    date=date,\n                    direction=direction,\n                    source=source\n                )\n                vehicle_id = None  # Not applicable in batch mode\n            else:\n                # Single mode: load specific vehicle\n                vehicle_id = int(params.get('vehicle_id', 1))\n                vehicle_count = None  # Not applicable in single mode\n                data = load_vehicle_data(\n                    vehicle_id=vehicle_id,\n                    road_id=road_id,\n                    date=date,\n                    direction=direction,\n                    source=source\n                )\n            \n            if not data:\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'No data found'\n                }, 404)\n                return\n            \n            # Calculate summary information\n            longitudes = [point['longitude'] for point in data]\n            latitudes = [point['latitude'] for point in data]\n            speeds = [point['speed'] for point in data]\n            \n            # Build summary based on mode\n            if start_time and end_time:\n                # Time range mode summary\n                unique_vehicles = list(set([point['vehicle_id'] for point in data]))\n                summary = {\n                    'status': 'success',\n                    'mode': 'time_range',\n                    'start_time': start_time,\n                    'end_time': end_time,\n                    'vehicle_count': len(unique_vehicles),\n                    'vehicle_ids': unique_vehicles,\n                    'total_points': len(data),\n                    'time_range': {\n                        'start': data[0]['time_stamp'],\n                        'end': data[-1]['time_stamp']\n                    },\n                    'coordinate_bounds': {\n                        'longitude_min': min(longitudes),\n                        'longitude_max': max(longitudes),\n                        'latitude_min': min(latitudes),\n                        'latitude_max': max(latitudes)\n                    },\n                    'speed_stats': {\n                        'min': min(speeds),\n                        'max': max(speeds),\n                        'avg': sum(speeds) / len(speeds)\n                    }\n                }\n            elif vehicle_count:\n                # Batch mode summary\n                unique_vehicles = list(set([point['vehicle_id'] for point in data]))\n                summary = {\n                    'status': 'success',\n                    'mode': 'batch',\n                    'vehicle_count': len(unique_vehicles),\n                    'vehicle_ids': unique_vehicles,\n                    'total_points': len(data),\n                    'time_range': {\n                        'start': data[0]['time_stamp'],\n                        'end': data[-1]['time_stamp']\n                    },\n                    'coordinate_bounds': {\n                        'longitude_min': min(longitudes),\n                        'longitude_max': max(longitudes),\n                        'latitude_min': min(latitudes),\n                        'latitude_max': max(latitudes)\n                    },\n                    'speed_stats': {\n                        'min': min(speeds),\n                        'max': max(speeds),\n                        'avg': sum(speeds) / len(speeds)\n                    }\n                }\n            else:\n                # Single mode summary\n                summary = {\n                    'status': 'success',\n                    'mode': 'single',\n                    'vehicle_id': vehicle_id,\n                    'total_points': len(data),\n                    'time_range': {\n                        'start': data[0]['time_stamp'],\n                        'end': data[-1]['time_stamp']\n                    },\n                    'coordinate_bounds': {\n                        'longitude_min': min(longitudes),\n                        'longitude_max': max(longitudes),\n                        'latitude_min': min(latitudes),\n                        'latitude_max': max(latitudes)\n                    },\n                    'speed_stats': {\n                        'min': min(speeds),\n                        'max': max(speeds),\n                        'avg': sum(speeds) / len(speeds)\n                    }\n                }\n            \n            self._send_json_response(summary)\n            \n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': str(e)\n            }, 500)\n    \n    def _handle_available_dates(self, params):\n        \"\"\"Handle available dates endpoint\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            source = params.get('source')\n            \n            # Build CSV file path based on road_id and selected source\n            csv_file_path = _csv_path_for_source(road_id, source)\n            \n            if not os.path.exists(csv_file_path):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'CSV file for road {road_id} not found'\n                }, 404)\n                return\n            \n            # Read CSV file and get unique dates\n            df = pd.read_csv(csv_file_path)\n            unique_dates = sorted(df['date'].unique().tolist())\n            \n            response = {\n                'status': 'success',\n                'road_id': road_id,\n                'dates': unique_dates,\n                'total_dates': len(unique_dates)\n            }\n            \n            self._send_json_response(response)\n            \n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': str(e)\n            }, 500)\n    \n    def _handle_traffic_cycles(self, params):\n        \"\"\"Handle traffic cycles endpoint\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            source = params.get('source')\n            \n            # Check if traffic signal file exists\n            if not os.path.exists(TRAFFIC_SIGNAL_FILE):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'Traffic signal file not found'\n                }, 404)\n                return\n            \n            # Read traffic signal data\n            df = pd.read_csv(TRAFFIC_SIGNAL_FILE)\n            \n            # Get available cycles for the road\n            road_data = df[df['road_id'] == road_id]\n            if road_data.empty:\n                cycles = []\n            else:\n                cycles = sorted(road_data['cycle_num'].unique().tolist())\n            \n            response = {\n                'status': 'success',\n                'road_id': road_id,\n                'cycles': cycles,\n                'total_cycles': len(cycles)\n            }\n            \n            self._send_json_response(response)\n            \n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': str(e)\n            }, 500)\n    \n    def _handle_traffic_status(self, params):\n        \"\"\"Handle traffic status endpoint\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            cycle_num = params.get('cycle_num')\n            \n            if not cycle_num:\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'cycle_num parameter is required'\n                }, 400)\n                return\n            \n            try:\n                cycle_num = int(cycle_num)\n            except ValueError:\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'cycle_num must be a valid integer'\n                }, 400)\n                return\n            \n            # Check if traffic signal file exists\n            if not os.path.exists(TRAFFIC_SIGNAL_FILE):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'Traffic signal file not found'\n                }, 404)\n                return\n            \n            # Read traffic signal data\n            df = pd.read_csv(TRAFFIC_SIGNAL_FILE)\n            \n            # Filter by road_id and cycle_num\n            cycle_data = df[(df['road_id'] == road_id) & (df['cycle_num'] == cycle_num)]\n            \n            if cycle_data.empty:\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'No data found for road {road_id} cycle {cycle_num}'\n                }, 404)\n                return\n            \n            # Convert to list of dictionaries\n            traffic_lights = []\n            for _, row in cycle_data.iterrows():\n                traffic_lights.append({\n                    'road_id': row['road_id'],\n                    'phase_id': row['phase_id'],\n                    'cycle_num': int(row['cycle_num']),\n                    'start_time': row['start_time'],\n                    'end_time': row['end_time']\n                })\n            \n            response = {\n                'status': 'success',\n                'road_id': road_id,\n                'cycle_num': cycle_num,\n                'phases': traffic_lights,\n                'total_phases': len(traffic_lights)\n            }\n            \n            self._send_json_response(response)\n            \n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': str(e)\n            }, 500)\n    \n    def _handle_speed_analysis(self, params):\n        \"\"\"Handle speed analysis endpoint\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            source = params.get('source')\n            vehicle_id = params.get('vehicle_id')\n            start_time = params.get('start_time')\n            end_time = params.get('end_time')\n            date = params.get('date')\n            direction = params.get('direction')  # Single or multiple\n            seg_id_param = params.get('seg_id')\n            \n            if not date:\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'date parameter is required'\n                }, 400)\n                return\n            \n            # Check if this is time range mode or single vehicle mode\n            if start_time and end_time:\n                # Time range mode: analyze all vehicles in time range\n                mode = 'time_range'\n            else:\n                # Single mode: analyze specific vehicle\n                if not vehicle_id:\n                    self._send_json_response({\n                        'status': 'error',\n                        'message': 'vehicle_id parameter is required for single mode'\n                    }, 400)\n                    return\n                \n                try:\n                    vehicle_id = int(vehicle_id)\n                except ValueError:\n                    self._send_json_response({\n                        'status': 'error',\n                        'message': 'vehicle_id must be a valid integer'\n                    }, 400)\n                    return\n                    \n                mode = 'single'\n            \n            # Build CSV file path based on road_id and selected source\n            csv_file_path = _csv_path_for_source(road_id, source)\n            \n            if not os.path.exists(csv_file_path):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'CSV file for road {road_id} not found'\n                }, 404)\n                return\n            \n            # Read CSV file and filter data\n            df = pd.read_csv(csv_file_path)\n            \n            # Apply date filter first\n            df_filtered = df[df['date'] == date]\n            \n            if df_filtered.empty:\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'No data found for date {date}'\n                }, 404)\n                return\n            \n            # Apply filter based on mode\n            if mode == 'time_range':\n                # Time range mode: filter by time range\n                # Convert time strings to time objects for comparison\n                try:\n                    import datetime\n                    start_time_obj = datetime.datetime.strptime(start_time, '%H:%M').time()\n                    end_time_obj = datetime.datetime.strptime(end_time, '%H:%M').time()\n                    \n                    # Filter data by time range\n                    def time_in_range(time_stamp):\n                        try:\n                            time_obj = datetime.datetime.strptime(time_stamp, '%H:%M:%S').time()\n                            return start_time_obj <= time_obj <= end_time_obj\n                        except:\n                            return False\n                    \n                    vehicle_data = df_filtered[df_filtered['time_stamp'].apply(time_in_range)]\n                    \n                except ValueError:\n                    self._send_json_response({\n                        'status': 'error',\n                        'message': 'Invalid time format. Use HH:MM format for start_time and end_time'\n                    }, 400)\n                    return\n            else:\n                # Single mode: filter by vehicle ID\n                vehicle_data = df_filtered[df_filtered['vehicle_id'] == vehicle_id]\n            \n            # Apply direction filter if specified (single or multiple)\n            if direction:\n                directions = parse_directions_param(direction)\n                direction_df = load_direction_data()\n                if not direction_df.empty and directions:\n                    # Filter direction data by the specified directions and road_id\n                    filtered_directions = direction_df[\n                        (direction_df['direction'].astype(str).str.upper().isin(directions)) & \n                        (direction_df['road_id'] == road_id)\n                    ]\n                    \n                    # Get vehicle_ids and dates that match the direction filter\n                    if date:\n                        # If date is specified, filter by date as well\n                        filtered_directions = filtered_directions[filtered_directions['date'] == date]\n                    \n                    if not filtered_directions.empty:\n                        # Create a set of (vehicle_id, date, seg_id) triplets for faster lookup\n                        valid_triplets = set(\n                            (int(v), str(d), int(s))\n                            for v, d, s in zip(\n                                filtered_directions['vehicle_id'],\n                                filtered_directions['date'],\n                                filtered_directions['seg_id'],\n                            )\n                        )\n                        \n                        # Filter vehicle_data to only include rows with matching (vehicle_id, date, seg_id)\n                        vehicle_data = vehicle_data[\n                            vehicle_data.apply(\n                                lambda row: (int(row['vehicle_id']), str(row['date']), int(row['seg_id'])) in valid_triplets,\n                                axis=1,\n                            )\n                        ]\n                    else:\n                        # No vehicles match the direction filter\n                        vehicle_data = vehicle_data.iloc[0:0]  # Empty dataframe with same structure\n            \n            if vehicle_data.empty:\n                if mode == 'time_range':\n                    if direction:\n                        dirs_text = ','.join(parse_directions_param(direction))\n                        error_msg = f'No data found in time range {start_time}-{end_time} on date {date} with direction {dirs_text}'\n                    else:\n                        error_msg = f'No data found in time range {start_time}-{end_time} on date {date}'\n                else:\n                    if direction:\n                        dirs_text = ','.join(parse_directions_param(direction))\n                        error_msg = f'No data found for vehicle {vehicle_id} on date {date} with direction {dirs_text}'\n                    else:\n                        error_msg = f'No data found for vehicle {vehicle_id} on date {date}'\n                    \n                self._send_json_response({\n                    'status': 'error',\n                    'message': error_msg\n                }, 404)\n                return\n            \n            # Sort by time for proper time series\n            vehicle_data = vehicle_data.sort_values('collectiontime')\n            \n            # Optional seg_id filtering\n            if seg_id_param is not None:\n                try:\n                    seg_id_int = int(seg_id_param)\n                    if 'seg_id' in vehicle_data.columns:\n                        vehicle_data = vehicle_data[vehicle_data['seg_id'] == seg_id_int]\n                except ValueError:\n                    pass\n\n            # Convert to list of dictionaries with all metrics for charting\n            speed_data = []\n            for _, row in vehicle_data.iterrows():\n                point = {\n                    'vehicle_id': int(row['vehicle_id']),\n                    'collectiontime': int(row['collectiontime']),\n                    'date': str(row['date']),\n                    'time_stamp': str(row['time_stamp']),\n                    'road_id': str(row['road_id']),\n                    'speed': float(row['speed']) if 'speed' in row and pd.notna(row['speed']) else None\n                }\n                # seg_id if present\n                if 'seg_id' in row and pd.notna(row['seg_id']):\n                    try:\n                        point['seg_id'] = int(row['seg_id'])\n                    except Exception:\n                        point['seg_id'] = None\n                # include other optional metrics if present\n                if 'acceleratorpedal' in row and pd.notna(row['acceleratorpedal']):\n                    try:\n                        point['acceleratorpedal'] = float(row['acceleratorpedal'])\n                    except Exception:\n                        point['acceleratorpedal'] = None\n                if 'brakestatus' in row and pd.notna(row['brakestatus']):\n                    try:\n                        point['brakestatus'] = int(row['brakestatus'])\n                    except Exception:\n                        point['brakestatus'] = None\n                if 'gearnum' in row and pd.notna(row['gearnum']):\n                    point['gearnum'] = str(row['gearnum'])\n                if 'havebrake' in row and pd.notna(row['havebrake']):\n                    point['havebrake'] = str(row['havebrake'])\n                if 'havedriver' in row and pd.notna(row['havedriver']):\n                    point['havedriver'] = str(row['havedriver'])\n                speed_data.append(point)\n            \n            # Build response based on mode\n            if mode == 'time_range':\n                unique_vehicles = list(set([point['vehicle_id'] for point in speed_data]))\n                response = {\n                    'status': 'success',\n                    'mode': 'time_range',\n                    'road_id': road_id,\n                    'date': date,\n                    'start_time': start_time,\n                    'end_time': end_time,\n                    'vehicle_count': len(unique_vehicles),\n                    'vehicle_ids': sorted(unique_vehicles),\n                    'total_points': len(speed_data),\n                    'data': speed_data\n                }\n            else:\n                response = {\n                    'status': 'success',\n                    'mode': 'single',\n                    'road_id': road_id,\n                    'vehicle_id': vehicle_id,\n                    'date': date,\n                    'total_points': len(speed_data),\n                    'data': speed_data\n                }\n            \n            self._send_json_response(response)\n            \n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': str(e)\n            }, 500)\n    \n    def _handle_speed_traffic_lights(self, params):\n        \"\"\"Handle traffic lights data for speed analysis endpoint\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            source = params.get('source')\n            start_time = params.get('start_time')\n            end_time = params.get('end_time')\n            \n            if not start_time or not end_time:\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'start_time and end_time parameters are required'\n                }, 400)\n                return\n            \n            # Check if traffic signal file exists\n            if not os.path.exists(TRAFFIC_SIGNAL_FILE):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'Traffic signal file not found'\n                }, 404)\n                return\n            \n            # Read traffic signal data\n            df = pd.read_csv(TRAFFIC_SIGNAL_FILE)\n            \n            # Filter by road_id\n            road_data = df[df['road_id'] == road_id]\n            \n            if road_data.empty:\n                self._send_json_response({\n                    'status': 'success',\n                    'road_id': road_id,\n                    'traffic_lights': [],\n                    'total_lights': 0\n                })\n                return\n            \n            # Convert time strings to datetime for comparison\n            road_data = road_data.copy()\n            road_data['start_datetime'] = pd.to_datetime(road_data['start_time'])\n            road_data['end_datetime'] = pd.to_datetime(road_data['end_time'])\n            \n            start_datetime = pd.to_datetime(start_time)\n            end_datetime = pd.to_datetime(end_time)\n            \n            # Filter by time range - find traffic lights that overlap with the speed analysis time range\n            overlapping_lights = road_data[\n                (road_data['start_datetime'] <= end_datetime) & \n                (road_data['end_datetime'] >= start_datetime)\n            ]\n            \n            # Convert to list of dictionaries\n            traffic_lights = []\n            for _, row in overlapping_lights.iterrows():\n                traffic_lights.append({\n                    'road_id': row['road_id'],\n                    'phase_id': row['phase_id'],\n                    'cycle_num': int(row['cycle_num']),\n                    'start_time': row['start_time'],\n                    'end_time': row['end_time']\n                })\n            \n            response = {\n                'status': 'success',\n                'road_id': road_id,\n                'start_time': start_time,\n                'end_time': end_time,\n                'traffic_lights': traffic_lights,\n                'total_lights': len(traffic_lights)\n            }\n            \n            self._send_json_response(response)\n            \n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': str(e)\n            }, 500)\n    \n    def _handle_speed_time_range(self, params):\n        \"\"\"Handle speed time range endpoint to get available time range for a date\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            source = params.get('source')\n            date = params.get('date')\n            \n            if not date:\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'date parameter is required'\n                }, 400)\n                return\n            \n            # Build CSV file path based on road_id and selected source (default prefer merged)\n            csv_file_path = _csv_path_for_source(road_id, source)\n            \n            if not os.path.exists(csv_file_path):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'CSV file for road {road_id} not found'\n                }, 404)\n                return\n            \n            # Read CSV file and filter by date\n            df = pd.read_csv(csv_file_path)\n            date_data = df[df['date'] == date]\n            \n            if date_data.empty:\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'No data found for date {date}'\n                }, 404)\n                return\n            \n            # Get time range from the data\n            time_stamps = date_data['time_stamp'].tolist()\n            min_time = min(time_stamps)\n            max_time = max(time_stamps)\n            \n            # Get unique vehicle count\n            unique_vehicles = date_data['vehicle_id'].nunique()\n            total_records = len(date_data)\n            \n            response = {\n                'status': 'success',\n                'road_id': road_id,\n                'date': date,\n                'min_time': min_time,\n                'max_time': max_time,\n                'total_vehicles': unique_vehicles,\n                'total_records': total_records,\n                'time_range_duration': self._calculate_time_duration(min_time, max_time)\n            }\n            \n            self._send_json_response(response)\n            \n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': str(e)\n            }, 500)\n    \n    def _calculate_time_duration(self, start_time, end_time):\n        \"\"\"Calculate duration between two time strings\"\"\"\n        try:\n            import datetime\n            start_obj = datetime.datetime.strptime(start_time, '%H:%M:%S')\n            end_obj = datetime.datetime.strptime(end_time, '%H:%M:%S')\n            \n            # Handle case where end time is next day\n            if end_obj < start_obj:\n                end_obj += datetime.timedelta(days=1)\n            \n            duration = end_obj - start_obj\n            total_seconds = int(duration.total_seconds())\n            hours = total_seconds // 3600\n            minutes = (total_seconds % 3600) // 60\n            \n            if hours > 0:\n                return f\"{hours}h {minutes}m\"\n            else:\n                return f\"{minutes}m\"\n        except:\n            return \"Unknown\"\n    \n    def _handle_intersection_topology(self, params):\n        \"\"\"Handle intersection topology endpoint to load GeoJSON road network\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            \n            # Path to the output directory containing the geojson file\n            topology_file = os.path.join(CSV_BASE_PATH, 'output', 'intersection_topology.geojson')\n            # Fallback to repo root output if not found under data\n            if not os.path.exists(topology_file):\n                alt = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'output', 'intersection_topology.geojson'))\n                if os.path.exists(alt):\n                    topology_file = alt\n            \n            print(f\"Loading intersection topology from: {topology_file}\")\n            \n            # Check if file exists\n            if not os.path.exists(topology_file):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'Topology file not found: {topology_file}',\n                    'hint': 'Please run infer_intersection.py first to generate the topology file'\n                }, 404)\n                return\n            \n            # Read the GeoJSON file\n            with open(topology_file, 'r', encoding='utf-8') as f:\n                geojson_data = json.load(f)\n            \n            # Also load the summary file if available\n            summary_file = '/home/mw/project/summary.json'\n            if not os.path.exists(summary_file):\n                alt_sum = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'output', '/home/mw/project/summary.json'))\n                if os.path.exists(alt_sum):\n                    summary_file = alt_sum\n            summary_data = None\n            if os.path.exists(summary_file):\n                with open(summary_file, 'r', encoding='utf-8') as f:\n                    summary_data = json.load(f)\n            \n            response = {\n                'status': 'success',\n                'road_id': road_id,\n                'topology': geojson_data,\n                'summary': summary_data,\n                'file_path': topology_file\n            }\n            \n            print(f\"Successfully loaded intersection topology with {len(geojson_data.get('features', []))} features\")\n            \n            self._send_json_response(response)\n            \n        except json.JSONDecodeError as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': f'Invalid JSON in topology file: {str(e)}'\n            }, 500)\n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': f'Error loading topology: {str(e)}'\n            }, 500)\n\n    def _handle_intersection_inference(self, params):\n        \"\"\"Serve intersection inference JSON (center, axes, stoplines) per road_id.\n        Expects files like A0003_intersection.json, A0008_intersection.json under CSV_BASE_PATH.\n        \"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            json_path = f'/home/mw/project/{road_id}_intersection.json'\n            # Fallback to repo root data if not found under data\n            if not os.path.exists(json_path):\n                alt_json = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'data', f'/home/mw/project/{road_id}_intersection.json'))\n                if os.path.exists(alt_json):\n                    json_path = alt_json\n\n            if not os.path.exists(json_path):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'Inference file not found for road {road_id}: {json_path}',\n                    'hint': 'Run main.py to generate data/{road}_intersection.json via Step 5'\n                }, 404)\n                return\n\n            with open(json_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n\n            self._send_json_response({\n                'status': 'success',\n                'road_id': road_id,\n                'inference': data,\n                'file_path': json_path\n            })\n        except json.JSONDecodeError as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': f'Invalid JSON in inference file: {str(e)}'\n            }, 500)\n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': f'Error loading inference: {str(e)}'\n            }, 500)\n\n    def _handle_intersection_centerlines(self, params):\n        \"\"\"Serve intersections' centerlines from data/intersection_*.json.\n        Allows selecting file source via ?source=A|B and filtering to a single road via ?road_id=A0003.\n        Supported filenames:\n          - intersection_B.json (newest)\n          - intersection_A.json (older/new format)\n          - intersection.json   (legacy)\n        \"\"\"\n        try:\n            source_param = (params.get('source') or '').strip().upper()\n            road_id = params.get('road_id')\n\n            # Candidate filenames based on requested source\n            if source_param == 'A':\n                candidates = ['/home/mw/project/intersection_A.json']\n            elif source_param == 'B':\n                candidates = ['/home/mw/project/intersection_B.json']\n            else:\n                # Default priority order\n                candidates = ['/home/mw/project/intersection_B.json', '/home/mw/project/intersection_A.json', '/home/mw/project/intersection.json']\n\n            inter_path = None\n            inter_source = None\n            # Resolve first existing candidate under data/ or repo-root/data/\n            for name in candidates:\n                p1 = os.path.join(CSV_BASE_PATH, name)\n                if os.path.exists(p1):\n                    inter_path = p1\n                    inter_source = name\n                    break\n                p2 = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'data', name))\n                if os.path.exists(p2):\n                    inter_path = p2\n                    inter_source = name\n                    break\n\n            if not inter_path:\n                tried = ', '.join(candidates)\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'Centerlines file not found (tried {tried})'\n                }, 404)\n                return\n\n            with open(inter_path, 'r', encoding='utf-8') as f:\n                payload = json.load(f)\n\n            if not isinstance(payload, dict):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'Invalid intersection.json format (expected object mapping road_id to lines)'\n                }, 400)\n                return\n\n            # Optionally filter to a single road\n            if road_id:\n                if road_id in payload:\n                    payload = { road_id: payload[road_id] }\n                else:\n                    self._send_json_response({\n                        'status': 'error',\n                        'message': f'Road {road_id} not found in {inter_source}'\n                    }, 404)\n                    return\n\n            roads = list(payload.keys())\n            self._send_json_response({\n                'status': 'success',\n                'centerlines': payload,\n                'roads': roads,\n                'total': len(roads),\n                'file_path': inter_path,\n                'source_file': inter_source\n            })\n        except json.JSONDecodeError as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': f'Invalid JSON in centerlines file: {str(e)}'\n            }, 500)\n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': f'Error loading centerlines: {str(e)}'\n            }, 500)\n\n    def _handle_stopline_west(self, params):\n        \"\"\"Serve west-approach stopline geometry from data/west_stopline.json.\n        Returns an object keyed by road_id with fields including stopline_segment.\n        \"\"\"\n        try:\n            road_id = params.get('road_id')\n            stopline_path = '/home/mw/project/west_stopline.json'\n            if not os.path.exists(stopline_path):\n                # Fallback to repo-root/data\n                alt_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'data', '/home/mw/project/stopline_west.json'))\n                if os.path.exists(alt_path):\n                    stopline_path = alt_path\n\n            if not os.path.exists(stopline_path):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'west_stopline.json not found'\n                }, 404)\n                return\n\n            with open(stopline_path, 'r', encoding='utf-8') as f:\n                payload = json.load(f)\n\n            if not isinstance(payload, dict):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'Invalid west_stopline.json format (expected object keyed by road_id)'\n                }, 400)\n                return\n\n            if road_id:\n                if road_id in payload:\n                    payload = { road_id: payload[road_id] }\n                else:\n                    self._send_json_response({\n                        'status': 'error',\n                        'message': f'/home/mw/project/Road {road_id} not found in west_stopline.json'\n                    }, 404)\n                    return\n\n            self._send_json_response({\n                'status': 'success',\n                'stoplines': payload,\n                'roads': list(payload.keys()),\n                'file_path': stopline_path\n            })\n        except json.JSONDecodeError as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': f'Invalid JSON in west_stopline.json: {str(e)}'\n            }, 500)\n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': str(e)\n            }, 500)\n\n    def _handle_stopline_east(self, params):\n        \"\"\"Serve east-approach stopline geometry from data/east_stopline.json.\n        Returns an object keyed by road_id with fields including stopline_segment.\n        \"\"\"\n        try:\n            road_id = params.get('road_id')\n            stopline_path = '/home/mw/project/east_stopline.json'\n            if not os.path.exists(stopline_path):\n                # Fallback to repo-root/data\n                alt_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'data', '/home/mw/project/stopline_east.json'))\n                if os.path.exists(alt_path):\n                    stopline_path = alt_path\n\n            if not os.path.exists(stopline_path):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'east_stopline.json not found'\n                }, 404)\n                return\n\n            with open(stopline_path, 'r', encoding='utf-8') as f:\n                payload = json.load(f)\n\n            if not isinstance(payload, dict):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'Invalid east_stopline.json format (expected object keyed by road_id)'\n                }, 400)\n                return\n\n            if road_id:\n                if road_id in payload:\n                    payload = { road_id: payload[road_id] }\n                else:\n                    self._send_json_response({\n                        'status': 'error',\n                        'message': f'/home/mw/project/Road {road_id} not found in east_stopline.json'\n                    }, 404)\n                    return\n\n            self._send_json_response({\n                'status': 'success',\n                'stoplines': payload,\n                'roads': list(payload.keys()),\n                'file_path': stopline_path\n            })\n        except json.JSONDecodeError as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': f'Invalid JSON in east_stopline.json: {str(e)}'\n            }, 500)\n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': str(e)\n            }, 500)\n\n    def _handle_stopline_all(self, params):\n        \"\"\"Serve all-direction stopline geometry from data/stopline.json.\n        Expected format:\n        {\n          \"A0003\": {\n            \"west\": {\"stopline_segment\": [[lon,lat],[lon,lat]]},\n            \"east\": {\"stopline_segment\": [[lon,lat],[lon,lat]]},\n            \"south\": {\"stopline_segment\": [[lon,lat],[lon,lat]]},\n            \"north\": {\"stopline_segment\": [[lon,lat],[lon,lat]]}\n          },\n          ...\n        }\n        Optional query param road_id filters to a single intersection.\n        \"\"\"\n        try:\n            road_id = params.get('road_id')\n            # Primary path under data/\n            stopline_path = '/home/mw/project/stopline.json'\n            if not os.path.exists(stopline_path):\n                # Fallback to repo-root/data/\n                alt_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'data', '/home/mw/project/stopline.json'))\n                if os.path.exists(alt_path):\n                    stopline_path = alt_path\n\n            if not os.path.exists(stopline_path):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'stopline.json not found'\n                }, 404)\n                return\n\n            with open(stopline_path, 'r', encoding='utf-8') as f:\n                payload = json.load(f)\n\n            if not isinstance(payload, dict):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': 'Invalid stopline.json format (expected object keyed by road_id)'\n                }, 400)\n                return\n\n            if road_id:\n                if road_id in payload:\n                    payload = { road_id: payload[road_id] }\n                else:\n                    self._send_json_response({\n                        'status': 'error',\n                        'message': f'/home/mw/project/Road {road_id} not found in stopline.json'\n                    }, 404)\n                    return\n\n            self._send_json_response({\n                'status': 'success',\n                'stoplines': payload,\n                'roads': list(payload.keys()),\n                'file_path': stopline_path\n            })\n        except json.JSONDecodeError as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': f'Invalid JSON in stopline.json: {str(e)}'\n            }, 500)\n        except Exception as e:\n            self._send_json_response({\n                'status': 'error',\n                'message': str(e)\n            }, 500)\n    def _handle_raw_dates(self, params):\n        \"\"\"Return available dates from the raw CSV (<road_id>.csv).\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            csv_file_path = f'/home/mw/project/{road_id}.csv'\n\n            if not os.path.exists(csv_file_path):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'CSV file for road {road_id} not found'\n                }, 404)\n                return\n\n            df = pd.read_csv(csv_file_path)\n            if 'road_id' in df.columns:\n                df = df[df['road_id'] == road_id]\n            unique_dates = sorted(df['date'].unique().tolist()) if 'date' in df.columns else []\n\n            self._send_json_response({\n                'status': 'success',\n                'road_id': road_id,\n                'dates': unique_dates,\n                'total_dates': len(unique_dates)\n            })\n        except Exception as e:\n            self._send_json_response({'status': 'error', 'message': str(e)}, 500)\n\n    def _handle_raw_data(self, params):\n        \"\"\"Return raw trajectory data from <road_id>.csv filtered by date and optional vehicle_id.\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            date = params.get('date')\n            vehicle_id_param = params.get('vehicle_id')\n\n            csv_file_path = f'/home/mw/project/{road_id}.csv'\n            if not os.path.exists(csv_file_path):\n                self._send_json_response({'status': 'error', 'message': f'CSV file for road {road_id} not found'}, 404)\n                return\n\n            df = pd.read_csv(csv_file_path)\n\n            # Filter to requested road if column exists\n            if 'road_id' in df.columns:\n                df = df[df['road_id'] == road_id]\n\n            # Filter by date if provided\n            if date and 'date' in df.columns:\n                df = df[df['date'] == date]\n\n            # Filter by vehicle if provided\n            if vehicle_id_param and 'vehicle_id' in df.columns:\n                try:\n                    vid = int(vehicle_id_param)\n                    df = df[df['vehicle_id'] == vid]\n                except ValueError:\n                    pass\n\n            if df.empty:\n                self._send_json_response({\n                    'status': 'success',\n                    'road_id': road_id,\n                    'date': date,\n                    'vehicle_id': vehicle_id_param,\n                    'total_points': 0,\n                    'data': []\n                })\n                return\n\n            # Order by typical keys when present\n            sort_cols = [c for c in ['vehicle_id', 'date', 'seg_id', 'collectiontime'] if c in df.columns]\n            if sort_cols:\n                df = df.sort_values(sort_cols)\n\n            data_list = []\n            for _, row in df.iterrows():\n                point = {\n                    'vehicle_id': int(row['vehicle_id']) if 'vehicle_id' in row and pd.notna(row['vehicle_id']) else 0,\n                    'collectiontime': int(row['collectiontime']) if 'collectiontime' in row and pd.notna(row['collectiontime']) else 0,\n                    'date': str(row['date']) if 'date' in row and pd.notna(row['date']) else '',\n                    'time_stamp': str(row['time_stamp']) if 'time_stamp' in row and pd.notna(row['time_stamp']) else '',\n                    'road_id': str(row['road_id']) if 'road_id' in row and pd.notna(row['road_id']) else road_id,\n                    'longitude': float(row['longitude']) if 'longitude' in row and pd.notna(row['longitude']) else 0.0,\n                    'latitude': float(row['latitude']) if 'latitude' in row and pd.notna(row['latitude']) else 0.0,\n                    'speed': float(row['speed']) if 'speed' in row and pd.notna(row['speed']) else 0.0,\n                    'acceleratorpedal': float(row['acceleratorpedal']) if 'acceleratorpedal' in row and pd.notna(row['acceleratorpedal']) else 0.0,\n                    'brakestatus': int(row['brakestatus']) if 'brakestatus' in row and pd.notna(row['brakestatus']) else 0,\n                }\n\n                if 'seg_id' in row and pd.notna(row['seg_id']):\n                    try:\n                        point['seg_id'] = int(row['seg_id'])\n                    except Exception:\n                        point['seg_id'] = 0\n\n                if 'gearnum' in row and pd.notna(row['gearnum']) and str(row['gearnum']).strip():\n                    point['gearnum'] = str(row['gearnum'])\n                else:\n                    point['gearnum'] = 'N/A'\n\n                if 'havebrake' in row and pd.notna(row['havebrake']) and str(row['havebrake']).strip():\n                    point['havebrake'] = str(row['havebrake'])\n                else:\n                    point['havebrake'] = 'N/A'\n\n                if 'havedriver' in row and pd.notna(row['havedriver']) and str(row['havedriver']).strip():\n                    point['havedriver'] = str(row['havedriver'])\n                else:\n                    point['havedriver'] = 'N/A'\n\n                data_list.append(point)\n\n            self._send_json_response({\n                'status': 'success',\n                'road_id': road_id,\n                'date': date,\n                'vehicle_id': vehicle_id_param,\n                'total_points': len(data_list),\n                'data': data_list\n            })\n        except Exception as e:\n            self._send_json_response({'status': 'error', 'message': str(e)}, 500)\n\n    def _handle_excluded_data(self, params):\n        \"\"\"Return excluded trajectory points filtered by road_id and optional date/vehicle_id.\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            date = params.get('date')\n            vehicle_id_param = params.get('vehicle_id')\n\n            csv_file_path = f'/home/mw/project/{road_id}_excluded.csv'\n            if not os.path.exists(csv_file_path):\n                self._send_json_response({\n                    'status': 'success',\n                    'road_id': road_id,\n                    'date': date,\n                    'total_points': 0,\n                    'data': []\n                })\n                return\n\n            df = pd.read_csv(csv_file_path)\n            if 'road_id' in df.columns:\n                df = df[df['road_id'] == road_id]\n            if date:\n                df = df[df['date'] == date]\n            if vehicle_id_param:\n                try:\n                    vid = int(vehicle_id_param)\n                    df = df[df['vehicle_id'] == vid]\n                except ValueError:\n                    pass\n\n            if df.empty:\n                self._send_json_response({\n                    'status': 'success',\n                    'road_id': road_id,\n                    'date': date,\n                    'total_points': 0,\n                    'data': []\n                })\n                return\n\n            # Stable ordering\n            sort_cols = [c for c in ['vehicle_id', 'date', 'seg_id', 'collectiontime'] if c in df.columns]\n            if sort_cols:\n                df = df.sort_values(sort_cols)\n\n            data_list = []\n            for _, row in df.iterrows():\n                data_point = {\n                    'vehicle_id': int(row['vehicle_id']),\n                    'collectiontime': int(row['collectiontime']),\n                    'date': str(row['date']),\n                    'time_stamp': str(row['time_stamp']),\n                    'road_id': str(row['road_id']),\n                    'longitude': float(row['longitude']),\n                    'latitude': float(row['latitude']),\n                    'speed': float(row['speed']) if 'speed' in row and pd.notna(row['speed']) else 0.0,\n                    'brakestatus': int(row['brakestatus']) if 'brakestatus' in row and pd.notna(row['brakestatus']) else 0\n                }\n\n                if 'seg_id' in row and pd.notna(row['seg_id']):\n                    try:\n                        data_point['seg_id'] = int(row['seg_id'])\n                    except Exception:\n                        data_point['seg_id'] = 0\n\n                if 'acceleratorpedal' in row and pd.notna(row['acceleratorpedal']):\n                    try:\n                        data_point['acceleratorpedal'] = float(row['acceleratorpedal'])\n                    except Exception:\n                        data_point['acceleratorpedal'] = None\n                else:\n                    data_point['acceleratorpedal'] = None\n\n                if 'gearnum' in row and pd.notna(row['gearnum']) and str(row['gearnum']).strip():\n                    data_point['gearnum'] = str(row['gearnum'])\n                else:\n                    data_point['gearnum'] = 'N/A'\n\n                if 'havebrake' in row and pd.notna(row['havebrake']) and str(row['havebrake']).strip():\n                    data_point['havebrake'] = str(row['havebrake'])\n                else:\n                    data_point['havebrake'] = 'N/A'\n\n                if 'havedriver' in row and pd.notna(row['havedriver']) and str(row['havedriver']).strip():\n                    data_point['havedriver'] = str(row['havedriver'])\n                else:\n                    data_point['havedriver'] = 'N/A'\n\n                data_list.append(data_point)\n\n            # total segments\n            total_segments = 0\n            if {'vehicle_id', 'date', 'seg_id'}.issubset(df.columns):\n                total_segments = df.drop_duplicates(['vehicle_id', 'date', 'seg_id']).shape[0]\n\n            self._send_json_response({\n                'status': 'success',\n                'road_id': road_id,\n                'date': date,\n                'vehicle_id': int(vehicle_id_param) if vehicle_id_param and str(vehicle_id_param).isdigit() else None,\n                'total_points': len(data_list),\n                'total_segments': int(total_segments),\n                'data': data_list\n            })\n        except Exception as e:\n            self._send_json_response({'status': 'error', 'message': str(e)}, 500)\n\n    def _handle_direction_segments(self, params):\n        \"\"\"List segments filtered by road_id and direction (and optional vehicle_id/date/seg_id).\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            direction = params.get('direction')\n            vehicle_id = params.get('vehicle_id')\n            date = params.get('date')\n            seg_id = params.get('seg_id')\n\n            df = load_direction_data()\n            if df is None or df.empty:\n                self._send_json_response({'status': 'success', 'segments': [], 'total': 0})\n                return\n\n            filt = (df['road_id'] == road_id)\n            if direction:\n                filt &= (df['direction'] == direction)\n            if vehicle_id:\n                try:\n                    vid = int(vehicle_id)\n                    filt &= (df['vehicle_id'] == vid)\n                except ValueError:\n                    pass\n            if date:\n                filt &= (df['date'] == date)\n            if seg_id:\n                try:\n                    sid = int(seg_id)\n                    filt &= (df['seg_id'] == sid)\n                except ValueError:\n                    pass\n\n            df_out = df[filt].copy()\n            df_out = df_out.sort_values(['vehicle_id', 'date', 'seg_id'])\n            segments = [\n                {\n                    'vehicle_id': int(r['vehicle_id']),\n                    'date': str(r['date']),\n                    'seg_id': int(r['seg_id']),\n                    'road_id': str(r['road_id']),\n                    'direction': str(r['direction'])\n                }\n                for _, r in df_out.iterrows()\n            ]\n\n            self._send_json_response({'status': 'success', 'road_id': road_id, 'direction': direction, 'total': len(segments), 'segments': segments})\n        except Exception as e:\n            self._send_json_response({'status': 'error', 'message': str(e)}, 500)\n\n    def _handle_trajectory_segment(self, params):\n        \"\"\"Return time series for a specific (vehicle_id, date, seg_id) on a road.\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            source = params.get('source')\n            vehicle_id = params.get('vehicle_id')\n            date = params.get('date')\n            seg_id = params.get('seg_id')\n\n            if not (vehicle_id and date and seg_id):\n                self._send_json_response({'status': 'error', 'message': 'vehicle_id, date, seg_id are required'}, 400)\n                return\n\n            try:\n                vehicle_id_i = int(vehicle_id)\n                seg_id_i = int(seg_id)\n            except ValueError:\n                self._send_json_response({'status': 'error', 'message': 'vehicle_id and seg_id must be integers'}, 400)\n                return\n\n            csv_file_path = _csv_path_for_source(road_id, source)\n            if not os.path.exists(csv_file_path):\n                self._send_json_response({'status': 'error', 'message': f'CSV file for road {road_id} not found'}, 404)\n                return\n\n            df = pd.read_csv(csv_file_path)\n            df_seg = df[(df['vehicle_id'] == vehicle_id_i) & (df['date'] == date) & (df['seg_id'] == seg_id_i)].copy()\n\n            if df_seg.empty:\n                self._send_json_response({'status': 'error', 'message': 'No data for specified segment'}, 404)\n                return\n\n            df_seg = df_seg.sort_values('collectiontime')\n\n            rows = []\n            for _, r in df_seg.iterrows():\n                row = {\n                    'vehicle_id': int(r['vehicle_id']),\n                    'collectiontime': int(r['collectiontime']),\n                    'date': str(r['date']),\n                    'time_stamp': str(r['time_stamp']),\n                    'road_id': str(r['road_id']),\n                    'seg_id': int(r['seg_id']),\n                    'speed': float(r['speed']) if pd.notna(r['speed']) else None,\n                    'acceleratorpedal': float(r['acceleratorpedal']) if 'acceleratorpedal' in r and pd.notna(r['acceleratorpedal']) else None,\n                    'brakestatus': int(r['brakestatus']) if 'brakestatus' in r and pd.notna(r['brakestatus']) else None,\n                    'gearnum': (str(r['gearnum']) if 'gearnum' in r and pd.notna(r['gearnum']) else 'N/A'),\n                    'havebrake': (str(r['havebrake']) if 'havebrake' in r and pd.notna(r['havebrake']) else 'N/A'),\n                    'havedriver': (str(r['havedriver']) if 'havedriver' in r and pd.notna(r['havedriver']) else 'N/A'),\n                }\n                if 'end_time' in r and pd.notna(r['end_time']) and str(r['end_time']).strip():\n                    row['end_time'] = str(r['end_time'])\n                rows.append(row)\n\n            self._send_json_response({'status': 'success', 'road_id': road_id, 'vehicle_id': vehicle_id_i, 'date': date, 'seg_id': seg_id_i, 'total_points': len(rows), 'data': rows})\n        except Exception as e:\n            self._send_json_response({'status': 'error', 'message': str(e)}, 500)\n\n    def _handle_crossover_data(self, params):\n        \"\"\"Serve crossover trajectory points from precomputed CSV (all supported directions).\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            direction_param = params.get('direction')\n            date = params.get('date')\n            directions = parse_directions_param(direction_param) or ['A1-1', 'A1-2']\n            dataset = str(params.get('dataset', 'standard') or 'standard').lower()\n\n            # Select dataset file\n            if dataset == 'real':\n                # A1 real synthesized boundary points\n                out_points_path = '/home/mw/project/cross_overA.csv'\n            else:\n                out_points_path = '/home/mw/project/cross_over.csv'\n            if not os.path.exists(out_points_path):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'{os.path.basename(out_points_path)} not found. Please run generate_timing.py to produce it.'\n                }, 404)\n                return\n\n            base = pd.read_csv(out_points_path)\n            base = base[base['road_id'] == road_id]\n            if date:\n                base = base[base['date'] == date]\n            if not base.empty and directions:\n                dir_df = load_direction_data()\n                filt = (dir_df['road_id'] == road_id)\n                if directions:\n                    up_dirs = [d.upper() for d in directions]\n                    filt &= dir_df['direction'].astype(str).str.upper().isin(up_dirs)\n                if date:\n                    filt &= (dir_df['date'] == date)\n                dir_df = dir_df[filt][['vehicle_id', 'date', 'seg_id']].drop_duplicates()\n                if not dir_df.empty:\n                    key = ['vehicle_id', 'date', 'seg_id']\n                    base = base.merge(dir_df, on=key, how='inner')\n                else:\n                    base = base.iloc[0:0]\n            points_df = base\n\n            # Format response as list of dicts with refined-like fields\n            rows = []\n            if points_df is not None and not points_df.empty:\n                # Stable sort\n                sort_cols = [c for c in ['vehicle_id', 'date', 'seg_id', 'collectiontime'] if c in points_df.columns]\n                if sort_cols:\n                    points_df = points_df.sort_values(sort_cols)\n                for _, r in points_df.iterrows():\n                    item = {\n                        'vehicle_id': int(r['vehicle_id']),\n                        'collectiontime': int(r['collectiontime']),\n                        'date': str(r['date']),\n                        'time_stamp': str(r['time_stamp']),\n                        'road_id': str(r['road_id']),\n                        'longitude': float(r['longitude']),\n                        'latitude': float(r['latitude']),\n                        'speed': float(r['speed']) if 'speed' in r and pd.notna(r['speed']) else 0.0,\n                        'acceleratorpedal': float(r['acceleratorpedal']) if 'acceleratorpedal' in r and pd.notna(r['acceleratorpedal']) else 0.0,\n                        'brakestatus': int(r['brakestatus']) if 'brakestatus' in r and pd.notna(r['brakestatus']) else 0\n                    }\n                    if 'seg_id' in r and pd.notna(r['seg_id']):\n                        try:\n                            item['seg_id'] = int(r['seg_id'])\n                        except Exception:\n                            item['seg_id'] = 0\n                    if 'gearnum' in r:\n                        item['gearnum'] = str(r['gearnum']) if pd.notna(r['gearnum']) else 'N/A'\n                    if 'havebrake' in r:\n                        item['havebrake'] = str(r['havebrake']) if pd.notna(r['havebrake']) else 'N/A'\n                    if 'havedriver' in r:\n                        item['havedriver'] = str(r['havedriver']) if pd.notna(r['havedriver']) else 'N/A'\n                    if 'end_time' in r and pd.notna(r['end_time']) and str(r['end_time']).strip():\n                        item['end_time'] = str(r['end_time'])\n                    rows.append(item)\n\n            self._send_json_response({\n                'status': 'success',\n                'road_id': road_id,\n                'date': date,\n                'directions': directions,\n                'dataset': dataset,\n                'total_points': len(rows),\n                'data': rows\n            })\n        except Exception as e:\n            self._send_json_response({'status': 'error', 'message': str(e)}, 500)\n\n    def _handle_crossover_time(self, params):\n        \"\"\"Serve crossover intervals from precomputed CSV (all supported directions).\"\"\"\n        try:\n            road_id = params.get('road_id', 'A0003')\n            direction_param = params.get('direction')\n            date = params.get('date')\n            directions = parse_directions_param(direction_param) or ['A1-1', 'A1-2']\n            dataset = str(params.get('dataset', 'standard') or 'standard').lower()\n\n            # Select dataset file\n            if dataset == 'real':\n                out_time_path = '/home/mw/project/corss_timeA_real.csv'\n            else:\n                out_time_path = '/home/mw/project/cross_over_time.csv'\n            if not os.path.exists(out_time_path):\n                self._send_json_response({\n                    'status': 'error',\n                    'message': f'{os.path.basename(out_time_path)} not found. Please run generate_timing.py to produce it.'\n                }, 404)\n                return\n\n            df = pd.read_csv(out_time_path)\n            df = df[df['road_id'] == road_id]\n            if directions:\n                up_dirs = [d.upper() for d in directions]\n                df = df[df['direction'].astype(str).str.upper().isin(up_dirs)]\n            if date:\n                df = df[df['date'] == date]\n            payload = []\n            if not df.empty:\n                df = df.sort_values(['vehicle_id', 'date', 'seg_id', 'enter_time'])\n                for _, r in df.iterrows():\n                    item = {\n                        'road_id': str(r['road_id']),\n                        'vehicle_id': int(r['vehicle_id']),\n                        'date': str(r['date']),\n                        'seg_id': int(r['seg_id']),\n                        'direction': str(r['direction']),\n                        'enter_time': str(r['enter_time']),\n                        'exit_time': str(r['exit_time']),\n                        'enter_idx': int(r['enter_idx']) if 'enter_idx' in r and pd.notna(r['enter_idx']) else None,\n                        'exit_idx': int(r['exit_idx']) if 'exit_idx' in r and pd.notna(r['exit_idx']) else None,\n                        'duration_s': int(r['duration_s']) if 'duration_s' in r and pd.notna(r['duration_s']) else None\n                    }\n                    if 'num_points' in r and pd.notna(r['num_points']):\n                        try:\n                            item['num_points'] = int(r['num_points'])\n                        except Exception:\n                            pass\n                    payload.append(item)\n\n            self._send_json_response({\n                'status': 'success',\n                'road_id': road_id,\n                'date': date,\n                'directions': directions,\n                'dataset': dataset,\n                'total_intervals': len(payload),\n                'intervals': payload\n            })\n        except Exception as e:\n            self._send_json_response({'status': 'error', 'message': str(e)}, 500)\n\n    \n    \n    def log_message(self, format, *args):\n        \"\"\"Override log message to show custom format\"\"\"\n        print(f\"[{self.address_string()}] {format % args}\")\n\ndef run_server(host='127.0.0.1', port=5555):\n    \"\"\"Run the HTTP server\"\"\"\n    print(\"Starting Geographic Data Visualization Backend Service...\")\n    print(f\"CSV base path: {os.path.abspath(CSV_BASE_PATH)}\")\n    \n    # Check if split CSV files exist\n    road_ids = ['A0003', 'A0008']\n    for road_id in road_ids:\n        csv_file = f'/home/mw/project/{road_id}_split.csv'\n        if os.path.exists(csv_file):\n            print(f\"/home/mw/project/ Found split CSV file: {road_id}_split.csv\")\n        else:\n            print(f\" Warning: split CSV file {road_id}_split.csv does not exist in {os.path.abspath(CSV_BASE_PATH)}\")\n    \n    # Create and start server\n    # Allow address reuse to prevent \"Address already in use\" errors\n    socketserver.TCPServer.allow_reuse_address = True\n    with socketserver.TCPServer((host, port), CustomHTTPRequestHandler) as httpd:\n        print(f\"Server running at http://{host}:{port}\")\n        print(\"Press Ctrl+C to stop the server\")\n        \n        try:\n            httpd.serve_forever()\n        except KeyboardInterrupt:\n            print(\"\\nServer stopped by user\")\n\nif __name__ == '__main__':\n    run_server()"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}