{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Auto-generated from `generate_timing.py`\n\nGenerated on 2025-11-09T22:01:34.\n\nThis notebook was created programmatically to mirror the original Python script.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nimport sys\nproject_root = str(Path.cwd().parent.resolve())\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nGenerate intersection crossover segments for straight and left-turn directions and write:\n  - data/cross_over.csv            (points with same schema/order as <road>_refined.csv)\n  - data/cross_over_time.csv       (intervals: road_id,vehicle_id,date,seg_id,direction,enter_time,exit_time,enter_idx,exit_idx,duration_s,num_points)\n\"\"\"\nimport json\nimport math\nimport os\nimport sys\nfrom typing import List, Tuple, Dict, Any, Optional\n\nimport pandas as pd\n\n# Resolve repository root (this file in repo root)\nREPO_ROOT = os.path.abspath(os.path.dirname(__file__))\nDATA_DIR = os.path.join(REPO_ROOT, 'data')\n\nSTOPLINE_FILE = os.path.join(DATA_DIR, '/home/mw/project/stopline.json')\nDIRECTION_FILE = os.path.join(DATA_DIR, '/home/mw/project/direction.csv')\nINTERSECTION_FILE = os.path.join(DATA_DIR, '/home/mw/project/intersection_A.json')\n\n\ndef load_centers() -> Dict[str, Tuple[float, float]]:\n    \"\"\"Load CENTERS from config.py (lat, lon).\"\"\"\n    centers = {}\n    try:\n        sys.path.insert(0, REPO_ROOT)\n        import config  # type: ignore\n        c = getattr(config, 'CENTERS', {}) or {}\n        for k, v in c.items():\n            try:\n                lat, lon = float(v[0]), float(v[1])\n                centers[str(k)] = (lat, lon)\n            except Exception:\n                continue\n    except Exception as e:\n        print(f\"[WARN] Failed to load centers from config.py: {e}\")\n    finally:\n        try:\n            sys.path.remove(REPO_ROOT)\n        except ValueError:\n            pass\n    return centers\n\n\ndef parse_directions(directions_str: str | None) -> List[str]:\n    if not directions_str:\n        return []\n    out = []\n    for part in str(directions_str).split(','):\n        v = part.strip()\n        if v:\n            out.append(v)\n    return out\n\n\ndef lonlat_to_xy(lon: float, lat: float, cos_lat: float) -> Tuple[float, float]:\n    return (float(lon) * cos_lat, float(lat))\n\n\ndef unit_normal(ax: float, ay: float, bx: float, by: float) -> Tuple[float, float]:\n    vx, vy = (bx - ax), (by - ay)\n    nx, ny = (vy, -vx)\n    norm = math.hypot(nx, ny)\n    if norm <= 0:\n        return (0.0, 0.0)\n    return (nx / norm, ny / norm)\n\n\ndef between_band(val: float, a: float, b: float) -> bool:\n    lo, hi = (a, b) if a <= b else (b, a)\n    return (val >= lo) and (val <= hi)\n\n\ndef _load_refined_df(road_id: str, date: Optional[str]) -> pd.DataFrame:\n    refined_path = os.path.join(DATA_DIR, f'/home/mw/project/{road_id}_refined.csv')\n    if not os.path.exists(refined_path):\n        raise FileNotFoundError(f'Refined CSV not found: {refined_path}')\n    df = pd.read_csv(refined_path)\n    if 'seg_id' not in df.columns:\n        raise ValueError('Required column seg_id not found in refined CSV')\n    if date:\n        df = df[df['date'] == date]\n    return df\n\n\ndef _filter_segments_by_direction(df: pd.DataFrame, road_id: str, directions: List[str], date: Optional[str]) -> Tuple[pd.DataFrame, pd.DataFrame, set]:\n    \"\"\"Filter trajectory df to only rows (veh,date,seg) listed in direction.csv for the requested directions.\"\"\"\n    if df is None or df.empty:\n        return df, pd.DataFrame(), set()\n    dir_df = pd.read_csv(DIRECTION_FILE)\n    dir_filt = (dir_df['road_id'] == road_id)\n    if directions:\n        up_dirs = [d.upper() for d in directions]\n        dir_filt &= dir_df['direction'].astype(str).str.upper().isin(up_dirs)\n    if date:\n        dir_filt &= (dir_df['date'] == date)\n    dir_df = dir_df[dir_filt].copy()\n    if dir_df.empty:\n        return df.iloc[0:0], dir_df, set()\n    valid_triplets = set((int(r['vehicle_id']), str(r['date']), int(r['seg_id']), str(r['direction'])) for _, r in dir_df.iterrows())\n    base_keys = {(v, d, s) for (v, d, s, _) in valid_triplets}\n    df2 = df[df.apply(lambda r: (int(r['vehicle_id']), str(r['date']), int(r['seg_id'])) in base_keys, axis=1)]\n    return df2, dir_df, valid_triplets\n\n\ndef _get_stopline_segment(stop_all: Dict[str, Any], road_id: str, key: str) -> Optional[List[List[float]]]:\n    one = stop_all.get(road_id, {}) or {}\n    obj = one.get(key) or {}\n    seg = obj.get('stopline_segment')\n    if isinstance(seg, list) and len(seg) >= 2:\n        return seg\n    return None\n\n\ndef _ensure_projection_center(road_id: str,\n                              seg1: List[List[float]],\n                              seg2: List[List[float]],\n                              centers: Dict[str, Tuple[float, float]]) -> Tuple[float, float, float]:\n    \"\"\"Return (lat_center, lon_center, cos_lat).\"\"\"\n    lat_center, lon_center = centers.get(road_id, (None, None))\n    if lat_center is None or lon_center is None:\n        # Average the two segments' endpoints as fallback\n        lats = [float(seg1[0][1]), float(seg1[1][1]), float(seg2[0][1]), float(seg2[1][1])]\n        lons = [float(seg1[0][0]), float(seg1[1][0]), float(seg2[0][0]), float(seg2[1][0])]\n        lat_center = sum(lats) / 4.0\n        lon_center = sum(lons) / 4.0\n    cos_lat = math.cos(float(lat_center) * math.pi / 180.0) or 1.0\n    return float(lat_center), float(lon_center), float(cos_lat)\n\n\ndef _signed_distance_to_line(ax: float, ay: float, bx: float, by: float, px: float, py: float) -> float:\n    nx, ny = unit_normal(ax, ay, bx, by)\n    return (px - ax) * nx + (py - ay) * ny\n\n\ndef _load_lane_divider(road_id: str) -> Optional[List[List[float]]]:\n    try:\n        with open(INTERSECTION_FILE, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n        one = data.get(str(road_id), {}) or {}\n        lane_div = one.get('lane_divider')\n        if isinstance(lane_div, list) and len(lane_div) >= 2:\n            return lane_div\n    except Exception as e:\n        print(f'[WARN] Failed to load lane_divider for {road_id} from {INTERSECTION_FILE}: {e}')\n    return None\n\n\ndef _build_centerline_projector(lane_divider: List[List[float]], cos_lat: float) -> Dict[str, Any]:\n    \"\"\"\n    Build centerline projector with precomputed XY (deg-scaled) and cumulative arclength in meters.\n    \"\"\"\n    xs: List[float] = []\n    ys: List[float] = []\n    for lon, lat in lane_divider:\n        x, y = lonlat_to_xy(float(lon), float(lat), cos_lat)\n        xs.append(x)\n        ys.append(y)\n    # cumulative arclength in meters (degree metric: deg_y * 111_320; x already scaled by cos_lat)\n    M_PER_DEG_LAT = 111_320.0\n    s_m: List[float] = [0.0]\n    seg_len_m: List[float] = []\n    for i in range(1, len(xs)):\n        dx = xs[i] - xs[i - 1]\n        dy = ys[i] - ys[i - 1]\n        seg_len = math.hypot(dx, dy) * M_PER_DEG_LAT\n        seg_len_m.append(seg_len)\n        s_m.append(s_m[-1] + seg_len)\n    return {\n        'xs': xs,\n        'ys': ys,\n        's_m': s_m,\n        'seg_len_m': seg_len_m,\n        'M_PER_DEG_LAT': M_PER_DEG_LAT\n    }\n\n\ndef _project_point_to_centerline_s(lon: float, lat: float, cos_lat: float, proj: Dict[str, Any]) -> Tuple[float, int, float]:\n    \"\"\"\n    Project a point to centerline and return (s_m, seg_index, t_on_segment in [0,1]).\n    \"\"\"\n    px, py = lonlat_to_xy(float(lon), float(lat), cos_lat)\n    xs = proj['xs']\n    ys = proj['ys']\n    s_m = proj['s_m']\n    seg_len_m = proj['seg_len_m']\n    best_dd = float('inf')\n    best_i = 0\n    best_t = 0.0\n    for i in range(len(xs) - 1):\n        ax, ay = xs[i], ys[i]\n        bx, by = xs[i + 1], ys[i + 1]\n        vx, vy = (bx - ax), (by - ay)\n        denom = vx * vx + vy * vy\n        if denom <= 0:\n            continue\n        t = ((px - ax) * vx + (py - ay) * vy) / denom\n        if t < 0.0:\n            t = 0.0\n        elif t > 1.0:\n            t = 1.0\n        qx = ax + t * vx\n        qy = ay + t * vy\n        dd = (px - qx) * (px - qx) + (py - qy) * (py - qy)\n        if dd < best_dd:\n            best_dd = dd\n            best_i = i\n            best_t = t\n    s_here = s_m[best_i] + best_t * seg_len_m[best_i] if best_i < len(seg_len_m) else s_m[-1]\n    return s_here, best_i, best_t\n\n\ndef _find_centerline_crossings_s(ax: float, ay: float, bx: float, by: float, proj: Dict[str, Any]) -> List[float]:\n    \"\"\"\n    Find all s_m positions where the centerline crosses the given line (ax,ay)-(bx,by).\n    \"\"\"\n    xs = proj['xs']\n    ys = proj['ys']\n    s_m = proj['s_m']\n    seg_len_m = proj['seg_len_m']\n    out: List[float] = []\n    for i in range(len(xs) - 1):\n        d0 = _signed_distance_to_line(ax, ay, bx, by, xs[i], ys[i])\n        d1 = _signed_distance_to_line(ax, ay, bx, by, xs[i + 1], ys[i + 1])\n        if d0 == 0.0:\n            out.append(float(s_m[i]))\n        elif d0 * d1 < 0.0:\n            # Crossing within segment\n            t = d0 / (d0 - d1)  # fraction along i->i+1 where distance crosses zero\n            if t < 0.0:\n                t = 0.0\n            elif t > 1.0:\n                t = 1.0\n            out.append(float(s_m[i] + t * seg_len_m[i]))\n        elif d1 == 0.0:\n            out.append(float(s_m[i + 1]))\n    # Deduplicate near-equal s values\n    out_sorted = sorted(out)\n    dedup: List[float] = []\n    EPS = 1e-6\n    for v in out_sorted:\n        if not dedup or abs(dedup[-1] - v) > EPS:\n            dedup.append(v)\n    return dedup\n\n\ndef _choose_boundary_pair_s(s_w_list: List[float], s_e_list: List[float], proj: Dict[str, Any], lon_center: float, lat_center: float, cos_lat: float) -> Tuple[float, float]:\n    \"\"\"\n    Choose one s for west and one s for east crossings, preferring those nearest to the center projection.\n    \"\"\"\n    s_center, _, _ = _project_point_to_centerline_s(lon_center, lat_center, cos_lat, proj)\n    def pick_nearest(cands: List[float]) -> Optional[float]:\n        if not cands:\n            return None\n        return sorted(cands, key=lambda v: abs(v - s_center))[0]\n    s_w = pick_nearest(s_w_list)\n    s_e = pick_nearest(s_e_list)\n    if s_w is None and s_e is None:\n        # Fallback: take min and max centerline s as a degenerate band\n        return float(proj['s_m'][0]), float(proj['s_m'][-1])\n    if s_w is None:\n        # Fallback: choose closest centerline node for west\n        s_w = float(proj['s_m'][0])\n    if s_e is None:\n        s_e = float(proj['s_m'][-1])\n    lo, hi = (s_w, s_e) if s_w <= s_e else (s_e, s_w)\n    return float(lo), float(hi)\n\n\ndef _centerline_lonlat_at_s(proj: Dict[str, Any], s_target: float, cos_lat: float) -> Tuple[float, float]:\n    \"\"\"\n    Return (lon, lat) on the centerline at arclength s_target (meters).\n    Clamps to [s_min, s_max] if outside.\n    \"\"\"\n    xs = proj['xs']\n    ys = proj['ys']\n    s_m = proj['s_m']\n    seg_len_m = proj['seg_len_m']\n    if not xs or len(xs) < 2:\n        return (0.0, 0.0)\n    if s_target <= s_m[0]:\n        x, y = xs[0], ys[0]\n        return (x / cos_lat, y)\n    if s_target >= s_m[-1]:\n        x, y = xs[-1], ys[-1]\n        return (x / cos_lat, y)\n    # Find segment\n    lo = 0\n    hi = len(s_m) - 1\n    while lo < hi - 1:\n        mid = (lo + hi) // 2\n        if s_m[mid] <= s_target:\n            lo = mid\n        else:\n            hi = mid\n    i = max(0, min(lo, len(xs) - 2))\n    denom = seg_len_m[i] if i < len(seg_len_m) else 0.0\n    if denom <= 0:\n        x, y = xs[i], ys[i]\n        return (x / cos_lat, y)\n    t = (s_target - s_m[i]) / denom\n    if t < 0.0:\n        t = 0.0\n    elif t > 1.0:\n        t = 1.0\n    x = xs[i] + t * (xs[i + 1] - xs[i])\n    y = ys[i] + t * (ys[i + 1] - ys[i])\n    return (x / cos_lat, y)\n\n\ndef _speed_avg_ms(row_a: pd.Series, row_b: pd.Series) -> Optional[float]:\n    \"\"\"\n    Average speed between two points in m/s using km/h speed column if available.\n    Fallback: None if speeds invalid.\n    \"\"\"\n    try:\n        va = float(row_a.get('speed', float('nan')))\n    except Exception:\n        va = float('nan')\n    try:\n        vb = float(row_b.get('speed', float('nan')))\n    except Exception:\n        vb = float('nan')\n    if (va != va) or (vb != vb):\n        return None\n    v_kmh = max(0.0, (va + vb) / 2.0)\n    return v_kmh / 3.6\n\n\ndef _interp_time_by_distance(t0: pd.Timestamp, t1: pd.Timestamp, dist0_m: float, dist1_m: float, dist_target_m: float) -> Optional[pd.Timestamp]:\n    \"\"\"\n    If speed invalid, fall back to linear interpolation by timestamps between two points based on distance fraction.\n    \"\"\"\n    if dist1_m <= dist0_m:\n        return None\n    frac = (dist_target_m - dist0_m) / (dist1_m - dist0_m)\n    if frac < 0.0:\n        frac = 0.0\n    elif frac > 1.0:\n        frac = 1.0\n    dt = (t1 - t0).total_seconds()\n    return t0 + pd.to_timedelta(frac * dt, unit='s')\n\n\ndef _synthesize_row_between(row_out: pd.Series,\n                            row_in: pd.Series,\n                            t_frac: float,\n                            time_real: pd.Timestamp) -> Dict[str, Any]:\n    \"\"\"\n    Synthesize a boundary row by interpolating lon/lat and time between row_out and row_in.\n    \"\"\"\n    out = dict(row_out.to_dict())\n    try:\n        lon0 = float(row_out['longitude'])\n        lat0 = float(row_out['latitude'])\n        lon1 = float(row_in['longitude'])\n        lat1 = float(row_in['latitude'])\n    except Exception:\n        lon0 = float(row_out.get('longitude', 0.0))\n        lat0 = float(row_out.get('latitude', 0.0))\n        lon1 = float(row_in.get('longitude', 0.0))\n        lat1 = float(row_in.get('latitude', 0.0))\n    if t_frac < 0.0:\n        t_frac = 0.0\n    elif t_frac > 1.0:\n        t_frac = 1.0\n    out['longitude'] = lon0 + (lon1 - lon0) * t_frac\n    out['latitude'] = lat0 + (lat1 - lat0) * t_frac\n    # time fields\n    out['time_stamp'] = str(time_real)\n    # collectiontime interpolation if available\n    try:\n        c0 = float(row_out.get('collectiontime', float('nan')))\n        c1 = float(row_in.get('collectiontime', float('nan')))\n        if c0 == c0 and c1 == c1:\n            out['collectiontime'] = int(round(c0 + (c1 - c0) * t_frac))\n    except Exception:\n        pass\n    # speed interpolation/averaging\n    try:\n        sp0 = float(row_out.get('speed', float('nan')))\n        sp1 = float(row_in.get('speed', float('nan')))\n        if sp0 == sp0 and sp1 == sp1:\n            out['speed'] = (sp0 + sp1) / 2.0\n    except Exception:\n        pass\n    return out\n\ndef _synthesize_row_on_centerline(template_row: pd.Series,\n                                  lon: float,\n                                  lat: float,\n                                  time_real: pd.Timestamp,\n                                  t_frac_for_collectiontime: Optional[float] = None) -> Dict[str, Any]:\n    \"\"\"\n    Create a new row using template_row for non-geom fields but placing the point at provided centerline lon/lat.\n    Optionally interpolate collectiontime using t_frac_for_collectiontime in [0,1] if provided.\n    \"\"\"\n    out = dict(template_row.to_dict())\n    out['longitude'] = float(lon)\n    out['latitude'] = float(lat)\n    out['time_stamp'] = str(time_real)\n    if t_frac_for_collectiontime is not None:\n        try:\n            c0 = float(template_row.get('collectiontime', float('nan')))\n            # Use same for both endpoints if unavailable; downstream code may overwrite\n            if c0 == c0:\n                out['collectiontime'] = int(round(c0 + 0.0 * t_frac_for_collectiontime))\n        except Exception:\n            pass\n    return out\n\n\ndef compute_a1_real_outputs(road_id: str,\n                            directions: List[str],\n                            date: Optional[str]) -> Tuple[pd.DataFrame, List[Dict[str, Any]]]:\n    \"\"\"\n    Compute A1 real entry/exit times and synthesized boundary points using centerline lane_divider\n    and average speeds between bracketing samples.\n    Returns (points_df_for_A1, intervals_real_for_A1).\n    \"\"\"\n    df = _load_refined_df(road_id, date)\n    if df.empty:\n        return df.iloc[0:0], []\n    df, dir_df, valid_triplets = _filter_segments_by_direction(df, road_id, directions, date)\n    if df.empty or dir_df.empty:\n        return df.iloc[0:0], []\n\n    # Stoplines and projection setup\n    with open(STOPLINE_FILE, 'r', encoding='utf-8') as f:\n        stop_all = json.load(f)\n    seg_west = _get_stopline_segment(stop_all, road_id, 'west')\n    seg_east = _get_stopline_segment(stop_all, road_id, 'east')\n    if not (seg_west and seg_east):\n        raise ValueError(f'Stoplines not found for {road_id}: west/east')\n    (w1_lon, w1_lat), (w2_lon, w2_lat) = seg_west[0], seg_west[1]\n    (e1_lon, e1_lat), (e2_lon, e2_lat) = seg_east[0], seg_east[1]\n\n    centers = load_centers()\n    lat_center, lon_center, cos_lat = _ensure_projection_center(road_id, seg_west, seg_east, centers)\n\n    # Build centerline projector\n    lane_div = _load_lane_divider(road_id)\n    if not lane_div:\n        print(f'[WARN] No lane_divider for {road_id}, skip A1 real outputs.')\n        return df.iloc[0:0], []\n    proj = _build_centerline_projector(lane_div, cos_lat)\n\n    # Compute centerline crossing s for west/east\n    wx1, wy1 = lonlat_to_xy(w1_lon, w1_lat, cos_lat)\n    wx2, wy2 = lonlat_to_xy(w2_lon, w2_lat, cos_lat)\n    ex1, ey1 = lonlat_to_xy(e1_lon, e1_lat, cos_lat)\n    ex2, ey2 = lonlat_to_xy(e2_lon, e2_lat, cos_lat)\n    s_w_all = _find_centerline_crossings_s(wx1, wy1, wx2, wy2, proj)\n    s_e_all = _find_centerline_crossings_s(ex1, ey1, ex2, ey2, proj)\n    s_lo, s_hi = _choose_boundary_pair_s(s_w_all, s_e_all, proj, lon_center, lat_center, cos_lat)\n\n    # Helper: inside by centerline s\n    def inside_by_s(sv: float) -> bool:\n        lo, hi = (s_lo, s_hi) if s_lo <= s_hi else (s_hi, s_lo)\n        return (sv >= lo) and (sv <= hi)\n\n    # Prepare mapping for direction text\n    key_to_dir = {}\n    for _, r in dir_df.iterrows():\n        key_to_dir[(int(r['vehicle_id']), str(r['date']), int(r['seg_id']))] = str(r['direction'])\n\n    df = df.sort_values(['vehicle_id', 'date', 'seg_id', 'collectiontime'])\n    points_real_parts: List[pd.DataFrame] = []\n    intervals_real: List[Dict[str, Any]] = []\n\n    for (veh, d, s), seg_df in df.groupby(['vehicle_id', 'date', 'seg_id']):\n        seg_df = seg_df.reset_index(drop=True)\n        if seg_df.empty or len(seg_df) < 2:\n            continue\n        # Precompute s along centerline for all points\n        s_list: List[float] = []\n        for _, row in seg_df.iterrows():\n            s_val, _, _ = _project_point_to_centerline_s(float(row['longitude']), float(row['latitude']), cos_lat, proj)\n            s_list.append(s_val)\n        inside_flags = [inside_by_s(v) for v in s_list]\n\n        # Find bands (outside->inside -> ... -> outside)\n        bands: List[Tuple[int, int]] = []\n        inside = False\n        enter_idx: Optional[int] = None\n        for i in range(1, len(inside_flags)):\n            prev_in = inside_flags[i - 1]\n            cur_in = inside_flags[i]\n            if (not prev_in) and cur_in:\n                enter_idx = i - 1\n                inside = True\n            elif prev_in and (not cur_in) and inside:\n                exit_idx = i\n                bands.append((int(enter_idx), int(exit_idx)))\n                inside = False\n                enter_idx = None\n\n        def add_interval_and_points(a: int, b: int, is_fallback_pair: bool) -> None:\n            nonlocal points_real_parts, intervals_real\n            a = max(0, int(a))\n            b = min(len(seg_df) - 1, int(b))\n            if a >= b:\n                return\n            # Bracketing pairs\n            enter_out = a\n            enter_in = min(a + 1, b)\n            exit_in = max(b - 1, a)\n            exit_out = b\n            # Determine entry/exit boundary s values that lie between the bracketing s's\n            s_out_e = s_list[enter_out]\n            s_in_e = s_list[enter_in]\n            s_out_x = s_list[exit_out]\n            s_in_x = s_list[exit_in]\n\n            def pick_boundary_between(s0: float, s1: float) -> float:\n                lo, hi = (s0, s1) if s0 <= s1 else (s1, s0)\n                if s_lo >= lo and s_lo <= hi:\n                    return s_lo\n                if s_hi >= lo and s_hi <= hi:\n                    return s_hi\n                # Fallback: choose closer boundary to s1\n                return s_lo if abs(s1 - s_lo) < abs(s1 - s_hi) else s_hi\n\n            if is_fallback_pair:\n                # Both points outside: use (a,b) pair for both entry/exit boundaries\n                s_entry = pick_boundary_between(s_list[a], s_list[b])\n                s_exit = pick_boundary_between(s_list[a], s_list[b])\n            else:\n                s_entry = pick_boundary_between(s_out_e, s_in_e)\n                s_exit = pick_boundary_between(s_in_x, s_out_x)  # use last-inside to first-outside segment\n\n            # Times and synthesized endpoints\n            row_a = seg_df.iloc[enter_out]\n            row_a1 = seg_df.iloc[enter_in]\n            row_bm1 = seg_df.iloc[exit_in]\n            row_b = seg_df.iloc[exit_out]\n\n            # Parse timestamps\n            t_a = pd.to_datetime(str(row_a['time_stamp']))\n            t_a1 = pd.to_datetime(str(row_a1['time_stamp']))\n            t_bm1 = pd.to_datetime(str(row_bm1['time_stamp']))\n            t_b = pd.to_datetime(str(row_b['time_stamp']))\n\n            # New rule: if there are inside-band points and the entering outside point has a valid end_time,\n            # do NOT project; use end_time as enter_time and exit_out time as exit_time. Points = interior only.\n            if not is_fallback_pair:\n                et_raw_nr = row_a.get('end_time') if 'end_time' in row_a else None\n                if et_raw_nr is not None and not pd.isna(et_raw_nr):\n                    et_str_nr = str(et_raw_nr).strip()\n                    if et_str_nr and et_str_nr.lower() not in ('nan', 'nat'):\n                        et_dt_nr = pd.to_datetime(et_str_nr, errors='coerce')\n                        if et_dt_nr is not None and not pd.isna(et_dt_nr):\n                            enter_time_real = et_dt_nr\n                            exit_time_real = t_b\n                            # Build points_df for this band: interior inside points only\n                            interior = []\n                            if (enter_in <= exit_in) and (exit_in - enter_in >= 0):\n                                interior = seg_df.iloc[enter_in:exit_in + 1].copy()\n                            if isinstance(interior, pd.DataFrame) and not interior.empty:\n                                band_df_real = interior[seg_df.columns.tolist()]\n                                points_real_parts.append(band_df_real)\n                            duration_s = int(max(0, (exit_time_real - enter_time_real).total_seconds()))\n                            intervals_real.append({\n                                'road_id': road_id,\n                                'vehicle_id': int(veh),\n                                'date': str(d),\n                                'seg_id': int(s),\n                                'direction': str(key_to_dir.get((int(veh), str(d), int(s)), '')),\n                                'enter_time': str(enter_time_real),\n                                'exit_time': str(exit_time_real),\n                                'enter_idx': int(enter_out),\n                                'exit_idx': int(exit_out),\n                                'duration_s': duration_s,\n                                'num_points': int(interior.shape[0]) if isinstance(interior, pd.DataFrame) else 0\n                            })\n                            return\n\n            # Entry time\n            use_stop_as_start = False\n            enter_time_real: Optional[pd.Timestamp] = None\n            # Robust end_time extraction (ignore NaN/NaT strings)\n            try:\n                et_raw = row_a.get('end_time') if 'end_time' in row_a else None\n            except Exception:\n                et_raw = None\n            if et_raw is not None and not pd.isna(et_raw):\n                et_field = str(et_raw).strip()\n                if et_field and et_field.lower() not in ('nan', 'nat'):\n                    # Stop-from-rest: use the stop row's end_time as entry time\n                    try:\n                        enter_time_real = pd.to_datetime(et_field, errors='coerce')\n                        if enter_time_real is not None and not pd.isna(enter_time_real):\n                            use_stop_as_start = True\n                        else:\n                            enter_time_real = None\n                    except Exception:\n                        enter_time_real = None\n            if not use_stop_as_start:\n                if is_fallback_pair:\n                    v_ms_e = _speed_avg_ms(row_a, row_b)\n                    s_a = s_list[a]\n                    dist_e = abs(s_entry - s_a)\n                    if v_ms_e and v_ms_e > 0:\n                        dt_e = dist_e / v_ms_e\n                        enter_time_real = t_a + pd.to_timedelta(dt_e, unit='s')\n                    else:\n                        # Timestamp interpolation between a and b\n                        dist0, dist1 = (0.0, abs(s_list[b] - s_list[a]))\n                        enter_time_real = _interp_time_by_distance(t_a, t_b, dist0, dist1, dist_e)\n                else:\n                    v_ms_e = _speed_avg_ms(row_a, row_a1)\n                    # Distance from outside to boundary along centerline\n                    dist_e = abs(s_entry - s_out_e)\n                    if v_ms_e and v_ms_e > 0:\n                        dt_e = dist_e / v_ms_e\n                        enter_time_real = t_a + pd.to_timedelta(dt_e, unit='s')\n                    else:\n                        # Fallback: interpolate by timestamps\n                        dist0, dist1 = (0.0, abs(s_in_e - s_out_e))\n                        enter_time_real = _interp_time_by_distance(t_a, t_a1, dist0, dist1, dist_e)\n\n            # Exit time\n            if is_fallback_pair:\n                v_ms_x = _speed_avg_ms(row_a, row_b)\n                s_a = s_list[a]\n                dist_x = abs(s_exit - s_a)\n                if v_ms_x and v_ms_x > 0:\n                    dt_x = dist_x / v_ms_x\n                    # If starting from a stop, base from end_time (enter_time_real)\n                    base_t = enter_time_real if use_stop_as_start and (enter_time_real is not None) else t_a\n                    exit_time_real = base_t + pd.to_timedelta(dt_x, unit='s')\n                else:\n                    dist0, dist1 = (0.0, abs(s_list[b] - s_list[a]))\n                    # Interpolate between t_a and t_b; if stop-start, shift by (enter_time_real - t_a)\n                    exit_time_tmp = _interp_time_by_distance(t_a, t_b, dist0, dist1, dist_x)\n                    if use_stop_as_start and (enter_time_real is not None) and (exit_time_tmp is not None):\n                        shift = (enter_time_real - t_a)\n                        exit_time_real = exit_time_tmp + shift\n                    else:\n                        exit_time_real = exit_time_tmp\n            else:\n                v_ms_x = _speed_avg_ms(row_bm1, row_b)\n                dist_x = abs(s_exit - s_in_x)\n                if v_ms_x and v_ms_x > 0:\n                    dt_x = dist_x / v_ms_x\n                    exit_time_real = t_bm1 + pd.to_timedelta(dt_x, unit='s')\n                else:\n                    dist0, dist1 = (0.0, abs(s_out_x - s_in_x))\n                    exit_time_real = _interp_time_by_distance(t_bm1, t_b, dist0, dist1, dist_x)\n\n            if (enter_time_real is None) or (exit_time_real is None) or pd.isna(enter_time_real) or pd.isna(exit_time_real):\n                return\n\n            # Synthesize boundary rows on centerline at exact stopline intersections\n            if use_stop_as_start:\n                start_row_dict = dict(row_a.to_dict())\n                start_row_dict['time_stamp'] = str(enter_time_real)\n            else:\n                lon_e, lat_e = _centerline_lonlat_at_s(proj, s_entry, cos_lat)\n                # Choose template for non-geom fields\n                start_row_dict = _synthesize_row_on_centerline(row_a, lon_e, lat_e, enter_time_real)\n            lon_x, lat_x = _centerline_lonlat_at_s(proj, s_exit, cos_lat)\n            # Use row_bm1 as template for exit-side attributes\n            end_row_dict = _synthesize_row_on_centerline(row_bm1, lon_x, lat_x, exit_time_real)\n\n            # Build points_df for this band: start + interior inside points + end\n            # Interior points: strictly inside indices (a+1 .. b-1), but ensure order\n            interior = []\n            if (enter_in <= exit_in) and (exit_in - enter_in >= 1):\n                interior = seg_df.iloc[enter_in:exit_in + 1].copy()\n                # Adjust first/last if needed: we already synthesized boundaries\n                if len(interior) > 0:\n                    # Drop the very first and very last original boundary bracketing points\n                    if len(interior) >= 1:\n                        interior = interior.iloc[0:len(interior)]\n            band_rows = [pd.DataFrame([start_row_dict])]\n            if isinstance(interior, pd.DataFrame) and not interior.empty:\n                band_rows.append(interior)\n            band_rows.append(pd.DataFrame([end_row_dict]))\n            band_df_real = pd.concat(band_rows, ignore_index=True)\n            # Ensure ordering and required columns\n            band_df_real = band_df_real[seg_df.columns.tolist()]\n            points_real_parts.append(band_df_real)\n\n            duration_s = int(max(0, (exit_time_real - enter_time_real).total_seconds()))\n            intervals_real.append({\n                'road_id': road_id,\n                'vehicle_id': int(veh),\n                'date': str(d),\n                'seg_id': int(s),\n                'direction': str(key_to_dir.get((int(veh), str(d), int(s)), '')),\n                'enter_time': str(enter_time_real),\n                'exit_time': str(exit_time_real),\n                'enter_idx': int(enter_out),\n                'exit_idx': int(exit_out),\n                'duration_s': duration_s,\n                'num_points': int(band_df_real.shape[0])\n            })\n\n        if not bands:\n            # No inside points: use best segment near the centerline band by distance to [s_lo,s_hi]\n            # Select the segment (i,i+1) whose [s_i,s_{i+1}] overlaps [s_lo, s_hi] the most; otherwise nearest.\n            best_i = None\n            best_overlap = -1.0\n            best_near = float('inf')\n            for i in range(len(s_list) - 1):\n                a0, a1 = s_list[i], s_list[i + 1]\n                lo = max(min(a0, a1), min(s_lo, s_hi))\n                hi = min(max(a0, a1), max(s_lo, s_hi))\n                overlap = max(0.0, hi - lo)\n                near = min(abs(a0 - s_lo), abs(a0 - s_hi), abs(a1 - s_lo), abs(a1 - s_hi))\n                if overlap > best_overlap or (overlap == best_overlap and near < best_near):\n                    best_overlap = overlap\n                    best_near = near\n                    best_i = i\n            if best_i is None:\n                continue\n            add_interval_and_points(best_i, best_i + 1, True)\n        else:\n            # Select the band that contains the point closest to center (to be consistent with existing behavior)\n            # Find nearest-to-center index\n            cx, cy = lonlat_to_xy(lon_center, lat_center, cos_lat)\n            best_idx = 0\n            best_dd = float('inf')\n            for i, row in seg_df.iterrows():\n                px, py = lonlat_to_xy(float(row['longitude']), float(row['latitude']), cos_lat)\n                dd = (px - cx) * (px - cx) + (py - cy) * (py - cy)\n                if dd < best_dd:\n                    best_dd = dd\n                    best_idx = i\n            chosen_band = None\n            for a, b in bands:\n                if a is not None and b is not None and a <= best_idx <= b:\n                    chosen_band = (a, b)\n                    break\n            selected = [chosen_band] if chosen_band is not None else bands[:1]\n            for a, b in selected:\n                add_interval_and_points(a, b, False)\n\n    if not intervals_real or not points_real_parts:\n        return df.iloc[0:0], []\n    out_points = pd.concat(points_real_parts, ignore_index=True)\n    out_points = out_points[df.columns.tolist()]\n    out_points = out_points.sort_values(['vehicle_id', 'date', 'seg_id', 'collectiontime'])\n    return out_points, intervals_real\n\n\ndef compute_crossover_straight(road_id: str,\n                               directions: List[str],\n                               date: Optional[str],\n                               line_key_lo: str,\n                               line_key_hi: str) -> Tuple[pd.DataFrame, List[Dict[str, Any]]]:\n    \"\"\"\n    Compute crossover segments for straight movements between two parallel stoplines.\n    line_key_lo: base line (e.g., 'west' or 'south'); line_key_hi: opposite line (e.g., 'east' or 'north').\n    Returns (points_df, intervals_list).\n\n    Behavior:\n      1) Prefer bands (continuous inside-band ranges) and pick the one that contains the point\n         closest to the intersection center; if none contains it, fall back to previous ranking.\n      2) If no inside-band points exist (sampling jumps across the band), fall back to selecting\n         the trajectory segment (i, i+1) whose projection contains the center point (t in [0,1]),\n         and use that segment's endpoints as enter/exit times.\n    \"\"\"\n    df = _load_refined_df(road_id, date)\n    if df.empty:\n        return df.iloc[0:0], []\n\n    df, dir_df, valid_triplets = _filter_segments_by_direction(df, road_id, directions, date)\n    if df.empty or dir_df.empty:\n        return df.iloc[0:0], []\n\n    # Stoplines (two parallels)\n    with open(STOPLINE_FILE, 'r', encoding='utf-8') as f:\n        stop_all = json.load(f)\n    seg_lo = _get_stopline_segment(stop_all, road_id, line_key_lo)\n    seg_hi = _get_stopline_segment(stop_all, road_id, line_key_hi)\n    if not (seg_lo and seg_hi):\n        raise ValueError(f'Stoplines not found for {road_id}: {line_key_lo}/{line_key_hi}')\n    (l1_lon, l1_lat), (l2_lon, l2_lat) = seg_lo[0], seg_lo[1]\n    (h1_lon, h1_lat), (h2_lon, h2_lat) = seg_hi[0], seg_hi[1]\n\n    # Projection\n    centers = load_centers()\n    lat_center, lon_center, cos_lat = _ensure_projection_center(road_id, seg_lo, seg_hi, centers)\n\n    ax, ay = lonlat_to_xy(l1_lon, l1_lat, cos_lat)\n    bx, by = lonlat_to_xy(l2_lon, l2_lat, cos_lat)\n    hx, hy = lonlat_to_xy(h1_lon, h1_lat, cos_lat)\n\n    nx, ny = unit_normal(ax, ay, bx, by)\n    if nx == 0.0 and ny == 0.0:\n        return df.iloc[0:0], []\n    d_hi = (hx - ax) * nx + (hy - ay) * ny\n    d_min, d_max = (0.0, d_hi) if d_hi >= 0 else (d_hi, 0.0)\n\n    cx, cy = lonlat_to_xy(lon_center, lat_center, cos_lat)\n\n    def nearest_center_index(seg_df: pd.DataFrame) -> int:\n        xs = seg_df['longitude'].astype(float).values\n        ys = seg_df['latitude'].astype(float).values\n        best_idx = 0\n        best = float('inf')\n        for i, (lon, lat) in enumerate(zip(xs, ys)):\n            px, py = lonlat_to_xy(lon, lat, cos_lat)\n            dd = (px - cx) * (px - cx) + (py - cy) * (py - cy)\n            if dd < best:\n                best = dd\n                best_idx = i\n        return best_idx\n\n    def best_segment_with_center_projection(seg_df: pd.DataFrame) -> Optional[int]:\n        \"\"\"\n        Return index i for which the segment (i, i+1) has the orthogonal projection\n        of the center lying inside the segment (t in [0,1]) and minimizes distance\n        to the center. If none, return None.\n        \"\"\"\n        xs = seg_df['longitude'].astype(float).values\n        ys = seg_df['latitude'].astype(float).values\n        best_i: Optional[int] = None\n        best_dd = float('inf')\n        for i in range(len(xs) - 1):\n            ax_, ay_ = lonlat_to_xy(xs[i], ys[i], cos_lat)\n            bx_, by_ = lonlat_to_xy(xs[i + 1], ys[i + 1], cos_lat)\n            vx, vy = (bx_ - ax_), (by_ - ay_)\n            denom = vx * vx + vy * vy\n            if denom <= 0:\n                continue\n            t = ((cx - ax_) * vx + (cy - ay_) * vy) / denom\n            if t < 0.0 or t > 1.0:\n                continue\n            px = ax_ + t * vx\n            py = ay_ + t * vy\n            dd = (px - cx) * (px - cx) + (py - cy) * (py - cy)\n            if dd < best_dd:\n                best_dd = dd\n                best_i = i\n        return best_i\n\n    def min_dist2_to_center(points_df: pd.DataFrame) -> float:\n        if points_df is None or points_df.empty:\n            return float('inf')\n        xs = points_df['longitude'].astype(float).values\n        ys = points_df['latitude'].astype(float).values\n        best = float('inf')\n        for lon, lat in zip(xs, ys):\n            px, py = lonlat_to_xy(lon, lat, cos_lat)\n            dd = (px - cx) * (px - cx) + (py - cy) * (py - cy)\n            if dd < best:\n                best = dd\n        return best\n\n    df = df.sort_values(['vehicle_id', 'date', 'seg_id', 'collectiontime'])\n    collected_rows: List[pd.DataFrame] = []\n    intervals: List[Dict[str, Any]] = []\n    key_to_dir = {(v, d, s): dd for (v, d, s, dd) in valid_triplets}\n\n    for (veh, d, s), seg_df in df.groupby(['vehicle_id', 'date', 'seg_id']):\n        seg_df = seg_df.reset_index(drop=True)\n        xs = seg_df['longitude'].astype(float).values\n        ys = seg_df['latitude'].astype(float).values\n        band_vals = []\n        for lon, lat in zip(xs, ys):\n            dx, dy = (lon * cos_lat - ax, lat - ay)\n            band_vals.append(dx * nx + dy * ny)\n        inside_flags = [between_band(v, d_min, d_max) for v in band_vals]\n\n        # Index of point closest to center\n        ci = nearest_center_index(seg_df)\n\n        bands = []\n        inside = False\n        enter_idx = None\n        for i in range(1, len(inside_flags)):\n            prev_in = inside_flags[i - 1]\n            cur_in = inside_flags[i]\n            if (not prev_in) and cur_in:\n                enter_idx = i - 1\n                inside = True\n            elif prev_in and (not cur_in) and inside:\n                exit_idx = i\n                bands.append((enter_idx, exit_idx))\n                inside = False\n                enter_idx = None\n\n        if not bands:\n            # New rule: skip segments with no points inside the band\n            continue\n\n        band_infos = []\n        for (a, b) in bands:\n            a = max(0, a)\n            b = min(len(seg_df) - 1, b)\n            band_slice = seg_df.iloc[a:b + 1].copy()\n            score = min_dist2_to_center(band_slice)\n            band_infos.append((score, a, b, band_slice))\n        band_infos.sort(key=lambda t: t[0])\n\n        # Prefer the band that contains the nearest-to-center point, if any\n        chosen_band = None\n        for _, a, b, _ in band_infos:\n            if a is not None and b is not None and a <= ci <= b:\n                chosen_band = (a, b)\n                break\n\n        if chosen_band is not None:\n            selected = [(0.0, chosen_band[0], chosen_band[1], seg_df.iloc[chosen_band[0]:chosen_band[1] + 1].copy())]\n        else:\n            # Fallback to previous top-2 by proximity to center\n            selected = band_infos[:2]\n\n        for (_, a, b, band_df) in selected:\n            collected_rows.append(band_df)\n            # Enter time: use end_time if the entering point is a merged point with non-empty end_time\n            enter_row = seg_df.iloc[a]\n            enter_time = str(enter_row['time_stamp'])\n            if 'end_time' in enter_row and isinstance(enter_row['end_time'], str) and enter_row['end_time'].strip():\n                enter_time = str(enter_row['end_time']).strip()\n            exit_time = str(seg_df.iloc[b]['time_stamp'])\n            try:\n                t0 = pd.to_datetime(enter_time)\n                t1 = pd.to_datetime(exit_time)\n                duration_s = max(0, int((t1 - t0).total_seconds()))\n            except Exception:\n                duration_s = None\n            intervals.append({\n                'road_id': road_id,\n                'vehicle_id': int(veh),\n                'date': str(d),\n                'seg_id': int(s),\n                'direction': str(key_to_dir.get((veh, d, s), '')),\n                'enter_time': enter_time,\n                'exit_time': exit_time,\n                'enter_idx': int(a),\n                'exit_idx': int(b),\n                'duration_s': duration_s,\n                'num_points': int(b - a + 1)\n            })\n\n    if not collected_rows:\n        return df.iloc[0:0], []\n    out_df = pd.concat(collected_rows, axis=0, ignore_index=True)\n    out_df = out_df[df.columns.tolist()]\n    out_df = out_df.sort_values(['vehicle_id', 'date', 'seg_id', 'collectiontime'])\n    return out_df, intervals\n\n\ndef compute_crossover_turn(road_id: str,\n                           directions: List[str],\n                           date: Optional[str],\n                           entry_key: str,\n                           exit_key: str) -> Tuple[pd.DataFrame, List[Dict[str, Any]]]:\n    \"\"\"\n    Compute crossover segments for left-turn movements:\n      - Find the point closest to intersection center (center_idx).\n      - From center_idx, scan backward to find last point before crossing entry stopline.\n      - From center_idx, scan forward to find first point after crossing exit stopline.\n      - Collect the slice [enter_idx, exit_idx].\n    Returns (points_df, intervals_list).\n    \"\"\"\n    df = _load_refined_df(road_id, date)\n    if df.empty:\n        return df.iloc[0:0], []\n    df, dir_df, valid_triplets = _filter_segments_by_direction(df, road_id, directions, date)\n    if df.empty or dir_df.empty:\n        return df.iloc[0:0], []\n\n    with open(STOPLINE_FILE, 'r', encoding='utf-8') as f:\n        stop_all = json.load(f)\n    seg_entry = _get_stopline_segment(stop_all, road_id, entry_key)\n    seg_exit = _get_stopline_segment(stop_all, road_id, exit_key)\n    if not (seg_entry and seg_exit):\n        raise ValueError(f'Stoplines not found for {road_id}: entry={entry_key}, exit={exit_key}')\n\n    centers = load_centers()\n    lat_center, lon_center, cos_lat = _ensure_projection_center(road_id, seg_entry, seg_exit, centers)\n    cx, cy = lonlat_to_xy(lon_center, lat_center, cos_lat)\n\n    # Line params\n    e_ax, e_ay = lonlat_to_xy(seg_entry[0][0], seg_entry[0][1], cos_lat)\n    e_bx, e_by = lonlat_to_xy(seg_entry[1][0], seg_entry[1][1], cos_lat)\n    x_ax, x_ay = lonlat_to_xy(seg_exit[0][0], seg_exit[0][1], cos_lat)\n    x_bx, x_by = lonlat_to_xy(seg_exit[1][0], seg_exit[1][1], cos_lat)\n\n    df = df.sort_values(['vehicle_id', 'date', 'seg_id', 'collectiontime'])\n    collected_rows: List[pd.DataFrame] = []\n    intervals: List[Dict[str, Any]] = []\n    key_to_dir = {(v, d, s): dd for (v, d, s, dd) in valid_triplets}\n\n    def nearest_center_index(seg_df: pd.DataFrame) -> int:\n        xs = seg_df['longitude'].astype(float).values\n        ys = seg_df['latitude'].astype(float).values\n        best_idx = 0\n        best = float('inf')\n        for i, (lon, lat) in enumerate(zip(xs, ys)):\n            px, py = lonlat_to_xy(lon, lat, cos_lat)\n            dd = (px - cx) * (px - cx) + (py - cy) * (py - cy)\n            if dd < best:\n                best = dd\n                best_idx = i\n        return best_idx\n\n    def signed_distances(seg_df: pd.DataFrame, ax: float, ay: float, bx: float, by: float) -> List[float]:\n        xs = seg_df['longitude'].astype(float).values\n        ys = seg_df['latitude'].astype(float).values\n        dd = []\n        for lon, lat in zip(xs, ys):\n            px, py = lonlat_to_xy(lon, lat, cos_lat)\n            dd.append(_signed_distance_to_line(ax, ay, bx, by, px, py))\n        return dd\n\n    EPS = 1e-9\n    def find_last_before_crossing(dists: List[float], start_idx: int) -> Optional[int]:\n        # scan backward; when sign change between i-1 and i, return i-1\n        for i in range(start_idx, 0, -1):\n            a, b = dists[i - 1], dists[i]\n            if (a == 0.0 and b != 0.0) or (b == 0.0 and a != 0.0) or (a * b < 0):\n                return i - 1\n            if abs(a) <= EPS and abs(b) <= EPS:\n                # both near zero -> keep scanning\n                continue\n        return None\n\n    def find_first_after_crossing(dists: List[float], start_idx: int) -> Optional[int]:\n        # scan forward; when sign change between i and i+1, return i+1\n        n = len(dists)\n        for i in range(start_idx, n - 1):\n            a, b = dists[i], dists[i + 1]\n            if (a == 0.0 and b != 0.0) or (b == 0.0 and a != 0.0) or (a * b < 0):\n                return i + 1\n            if abs(a) <= EPS and abs(b) <= EPS:\n                continue\n        return None\n\n    for (veh, d, s), seg_df in df.groupby(['vehicle_id', 'date', 'seg_id']):\n        seg_df = seg_df.reset_index(drop=True)\n        if seg_df.empty or len(seg_df) < 2:\n            continue\n        ci = nearest_center_index(seg_df)\n        entry_d = signed_distances(seg_df, e_ax, e_ay, e_bx, e_by)\n        exit_d = signed_distances(seg_df, x_ax, x_ay, x_bx, x_by)\n        enter_idx = find_last_before_crossing(entry_d, ci)\n        exit_idx = find_first_after_crossing(exit_d, ci)\n        if enter_idx is None or exit_idx is None:\n            continue\n        if not (0 <= enter_idx < exit_idx <= len(seg_df) - 1):\n            continue\n        # New rule: require at least one point inside the intersection area between entry and exit lines\n        has_inside_point = False\n        for k in range(enter_idx, exit_idx + 1):\n            a = entry_d[k]\n            b = exit_d[k]\n            if (abs(a) <= EPS) or (abs(b) <= EPS) or (a * b < 0):\n                has_inside_point = True\n                break\n        if not has_inside_point:\n            continue\n        band_df = seg_df.iloc[enter_idx:exit_idx + 1].copy()\n        collected_rows.append(band_df)\n        enter_row = seg_df.iloc[enter_idx]\n        enter_time = str(enter_row['time_stamp'])\n        if 'end_time' in enter_row and isinstance(enter_row['end_time'], str) and enter_row['end_time'].strip():\n            enter_time = str(enter_row['end_time']).strip()\n        exit_time = str(seg_df.iloc[exit_idx]['time_stamp'])\n        try:\n            t0 = pd.to_datetime(enter_time)\n            t1 = pd.to_datetime(exit_time)\n            duration_s = max(0, int((t1 - t0).total_seconds()))\n        except Exception:\n            duration_s = None\n        intervals.append({\n            'road_id': road_id,\n            'vehicle_id': int(veh),\n            'date': str(d),\n            'seg_id': int(s),\n            'direction': str(key_to_dir.get((veh, d, s), '')),\n            'enter_time': enter_time,\n            'exit_time': exit_time,\n            'enter_idx': int(enter_idx),\n            'exit_idx': int(exit_idx),\n            'duration_s': duration_s,\n            'num_points': int(exit_idx - enter_idx + 1)\n        })\n\n    if not collected_rows:\n        return df.iloc[0:0], []\n    out_df = pd.concat(collected_rows, axis=0, ignore_index=True)\n    out_df = out_df[df.columns.tolist()]\n    out_df = out_df.sort_values(['vehicle_id', 'date', 'seg_id', 'collectiontime'])\n    return out_df, intervals\n\n\ndef _select_best_pair_for_band(band_vals: List[float], d_min: float, d_max: float) -> Optional[int]:\n    \"\"\"\n    For straight movement: select index i (segment i->i+1) whose value range overlaps the band [d_min, d_max]\n    the most; fallback to the one nearest to the band if no overlap.\n    Returns i or None.\n    \"\"\"\n    if not band_vals or len(band_vals) < 2:\n        return None\n    best_i = None\n    best_overlap = -1.0\n    best_near = float('inf')\n    for i in range(len(band_vals) - 1):\n        a0, a1 = band_vals[i], band_vals[i + 1]\n        lo = max(min(a0, a1), min(d_min, d_max))\n        hi = min(max(a0, a1), max(d_min, d_max))\n        overlap = max(0.0, hi - lo)\n        near = min(abs(a0 - d_min), abs(a0 - d_max), abs(a1 - d_min), abs(a1 - d_max))\n        if overlap > best_overlap or (overlap == best_overlap and near < best_near):\n            best_overlap = overlap\n            best_near = near\n            best_i = i\n    return best_i\n\n\ndef compute_crossover_straight_outer(road_id: str,\n                                     directions: List[str],\n                                     date: Optional[str],\n                                     line_key_lo: str,\n                                     line_key_hi: str) -> List[Dict[str, Any]]:\n    \"\"\"\n    For straight movements, process segments with NO inside-band points.\n    Choose the adjacent pair (i,i+1) that best overlaps the band and use:\n      - enter_time: use end_time of point i if available, else time_stamp of point i\n      - exit_time: time_stamp of point i+1\n    Returns list of interval dicts (same schema as cross_over_time.csv).\n    \"\"\"\n    df = _load_refined_df(road_id, date)\n    if df.empty:\n        return []\n    df, dir_df, valid_triplets = _filter_segments_by_direction(df, road_id, directions, date)\n    if df.empty or dir_df.empty:\n        return []\n\n    with open(STOPLINE_FILE, 'r', encoding='utf-8') as f:\n        stop_all = json.load(f)\n    seg_lo = _get_stopline_segment(stop_all, road_id, line_key_lo)\n    seg_hi = _get_stopline_segment(stop_all, road_id, line_key_hi)\n    if not (seg_lo and seg_hi):\n        raise ValueError(f'Stoplines not found for {road_id}: {line_key_lo}/{line_key_hi}')\n    (l1_lon, l1_lat), (l2_lon, l2_lat) = seg_lo[0], seg_lo[1]\n    (h1_lon, h1_lat), (h2_lon, h2_lat) = seg_hi[0], seg_hi[1]\n\n    centers = load_centers()\n    lat_center, lon_center, cos_lat = _ensure_projection_center(road_id, seg_lo, seg_hi, centers)\n\n    ax, ay = lonlat_to_xy(l1_lon, l1_lat, cos_lat)\n    bx, by = lonlat_to_xy(l2_lon, l2_lat, cos_lat)\n    hx, hy = lonlat_to_xy(h1_lon, h1_lat, cos_lat)\n\n    nx, ny = unit_normal(ax, ay, bx, by)\n    if nx == 0.0 and ny == 0.0:\n        return []\n    d_hi = (hx - ax) * nx + (hy - ay) * ny\n    d_min, d_max = (0.0, d_hi) if d_hi >= 0 else (d_hi, 0.0)\n\n    df = df.sort_values(['vehicle_id', 'date', 'seg_id', 'collectiontime'])\n    key_to_dir = {(int(r['vehicle_id']), str(r['date']), int(r['seg_id'])): str(r['direction']) for _, r in dir_df.iterrows()}\n    intervals_outer: List[Dict[str, Any]] = []\n\n    for (veh, d, s), seg_df in df.groupby(['vehicle_id', 'date', 'seg_id']):\n        seg_df = seg_df.reset_index(drop=True)\n        if seg_df.empty or len(seg_df) < 2:\n            continue\n        xs = seg_df['longitude'].astype(float).values\n        ys = seg_df['latitude'].astype(float).values\n        band_vals: List[float] = []\n        for lon, lat in zip(xs, ys):\n            dx, dy = (lon * cos_lat - ax, lat - ay)\n            band_vals.append(dx * nx + dy * ny)\n        inside_flags = [between_band(v, d_min, d_max) for v in band_vals]\n        # Skip segments that already have inside-band points; this function handles only the \"no-inside\" case\n        if any(inside_flags):\n            continue\n        best_i = _select_best_pair_for_band(band_vals, d_min, d_max)\n        if best_i is None:\n            continue\n        i = int(best_i)\n        j = i + 1\n        if not (0 <= i < j <= len(seg_df) - 1):\n            continue\n        row_i = seg_df.iloc[i]\n        row_j = seg_df.iloc[j]\n        # Times\n        enter_time = str(row_i['time_stamp'])\n        try:\n            et = row_i.get('end_time') if 'end_time' in row_i else None\n            if et is not None and str(et).strip() and str(et).strip().lower() not in ('nan', 'nat'):\n                enter_time = str(et).strip()\n        except Exception:\n            pass\n        exit_time = str(row_j['time_stamp'])\n        try:\n            t0 = pd.to_datetime(enter_time)\n            t1 = pd.to_datetime(exit_time)\n            duration_s = max(0, int((t1 - t0).total_seconds()))\n        except Exception:\n            duration_s = None\n        intervals_outer.append({\n            'road_id': road_id,\n            'vehicle_id': int(veh),\n            'date': str(d),\n            'seg_id': int(s),\n            'direction': str(key_to_dir.get((int(veh), str(d), int(s)), '')),\n            'enter_time': enter_time,\n            'exit_time': exit_time,\n            'enter_idx': int(i),\n            'exit_idx': int(j),\n            'duration_s': duration_s,\n            'num_points': 2\n        })\n    return intervals_outer\n\n\ndef compute_crossover_turn_outer(road_id: str,\n                                 directions: List[str],\n                                 date: Optional[str],\n                                 entry_key: str,\n                                 exit_key: str) -> List[Dict[str, Any]]:\n    \"\"\"\n    For left-turn movements, process segments with NO inside-area points.\n    Choose the adjacent pair (i,i+1) that best indicates crossing from entry to exit area:\n      - Prefer pairs whose distance ranges to BOTH lines include zero.\n      - Fallback to the pair minimizing total |distance| to both lines.\n    Use end_time of earlier point for enter_time if available, else its time_stamp; exit_time from later point.\n    \"\"\"\n    df = _load_refined_df(road_id, date)\n    if df.empty:\n        return []\n    df, dir_df, valid_triplets = _filter_segments_by_direction(df, road_id, directions, date)\n    if df.empty or dir_df.empty:\n        return []\n\n    with open(STOPLINE_FILE, 'r', encoding='utf-8') as f:\n        stop_all = json.load(f)\n    seg_entry = _get_stopline_segment(stop_all, road_id, entry_key)\n    seg_exit = _get_stopline_segment(stop_all, road_id, exit_key)\n    if not (seg_entry and seg_exit):\n        raise ValueError(f'Stoplines not found for {road_id}: entry={entry_key}, exit={exit_key}')\n\n    centers = load_centers()\n    lat_center, lon_center, cos_lat = _ensure_projection_center(road_id, seg_entry, seg_exit, centers)\n    cx, cy = lonlat_to_xy(lon_center, lat_center, cos_lat)\n\n    e_ax, e_ay = lonlat_to_xy(seg_entry[0][0], seg_entry[0][1], cos_lat)\n    e_bx, e_by = lonlat_to_xy(seg_entry[1][0], seg_entry[1][1], cos_lat)\n    x_ax, x_ay = lonlat_to_xy(seg_exit[0][0], seg_exit[0][1], cos_lat)\n    x_bx, x_by = lonlat_to_xy(seg_exit[1][0], seg_exit[1][1], cos_lat)\n\n    def signed_distances(seg_df: pd.DataFrame, ax: float, ay: float, bx: float, by: float) -> List[float]:\n        xs = seg_df['longitude'].astype(float).values\n        ys = seg_df['latitude'].astype(float).values\n        dd = []\n        for lon, lat in zip(xs, ys):\n            px, py = lonlat_to_xy(lon, lat, cos_lat)\n            dd.append(_signed_distance_to_line(ax, ay, bx, by, px, py))\n        return dd\n\n    def center_score_for_pair(seg_df: pd.DataFrame, i: int) -> float:\n        # distance^2 from pair midpoint to center\n        try:\n            lon0 = float(seg_df.iloc[i]['longitude']); lat0 = float(seg_df.iloc[i]['latitude'])\n            lon1 = float(seg_df.iloc[i + 1]['longitude']); lat1 = float(seg_df.iloc[i + 1]['latitude'])\n            px, py = lonlat_to_xy((lon0 + lon1) / 2.0, (lat0 + lat1) / 2.0, cos_lat)\n            return (px - cx) * (px - cx) + (py - cy) * (py - cy)\n        except Exception:\n            return float('inf')\n\n    df = df.sort_values(['vehicle_id', 'date', 'seg_id', 'collectiontime'])\n    key_to_dir = {(int(r['vehicle_id']), str(r['date']), int(r['seg_id'])): str(r['direction']) for _, r in dir_df.iterrows()}\n    intervals_outer: List[Dict[str, Any]] = []\n\n    for (veh, d, s), seg_df in df.groupby(['vehicle_id', 'date', 'seg_id']):\n        seg_df = seg_df.reset_index(drop=True)\n        if seg_df.empty or len(seg_df) < 2:\n            continue\n        entry_d = signed_distances(seg_df, e_ax, e_ay, e_bx, e_by)\n        exit_d = signed_distances(seg_df, x_ax, x_ay, x_bx, x_by)\n        # Detect if there are already inside points (then skip here)\n        EPS = 1e-9\n        has_inside = False\n        for k in range(len(seg_df)):\n            a = entry_d[k]; b = exit_d[k]\n            if (abs(a) <= EPS) or (abs(b) <= EPS) or (a * b < 0):\n                has_inside = True\n                break\n        if has_inside:\n            continue\n        # Collect candidate pairs\n        good_pairs: List[Tuple[float, int]] = []  # (center_score, i)\n        fallback_pairs: List[Tuple[float, float, int]] = []  # (dist_sum, center_score, i)\n        for i in range(len(seg_df) - 1):\n            e0, e1 = entry_d[i], entry_d[i + 1]\n            x0, x1 = exit_d[i], exit_d[i + 1]\n            emin, emax = (e0, e1) if e0 <= e1 else (e1, e0)\n            xmin, xmax = (x0, x1) if x0 <= x1 else (x1, x0)\n            e_in = (emin <= 0.0 <= emax)\n            x_in = (xmin <= 0.0 <= xmax)\n            cscore = center_score_for_pair(seg_df, i)\n            if e_in and x_in:\n                good_pairs.append((cscore, i))\n            else:\n                dist_sum = min(abs(e0), abs(e1)) + min(abs(x0), abs(x1))\n                fallback_pairs.append((dist_sum, cscore, i))\n        chosen_i: Optional[int] = None\n        if good_pairs:\n            good_pairs.sort(key=lambda t: t[0])  # nearest to center\n            chosen_i = good_pairs[0][1]\n        elif fallback_pairs:\n            fallback_pairs.sort(key=lambda t: (t[0], t[1]))\n            chosen_i = fallback_pairs[0][2]\n        else:\n            continue\n        i = int(chosen_i)\n        j = i + 1\n        row_i = seg_df.iloc[i]\n        row_j = seg_df.iloc[j]\n        enter_time = str(row_i['time_stamp'])\n        try:\n            et = row_i.get('end_time') if 'end_time' in row_i else None\n            if et is not None and str(et).strip() and str(et).strip().lower() not in ('nan', 'nat'):\n                enter_time = str(et).strip()\n        except Exception:\n            pass\n        exit_time = str(row_j['time_stamp'])\n        try:\n            t0 = pd.to_datetime(enter_time)\n            t1 = pd.to_datetime(exit_time)\n            duration_s = max(0, int((t1 - t0).total_seconds()))\n        except Exception:\n            duration_s = None\n        intervals_outer.append({\n            'road_id': road_id,\n            'vehicle_id': int(veh),\n            'date': str(d),\n            'seg_id': int(s),\n            'direction': str(key_to_dir.get((int(veh), str(d), int(s)), '')),\n            'enter_time': enter_time,\n            'exit_time': exit_time,\n            'enter_idx': int(i),\n            'exit_idx': int(j),\n            'duration_s': duration_s,\n            'num_points': 2\n        })\n    return intervals_outer\n\n\ndef build_wait_df(road_id: str, directions: List[str], date: str | None, points_df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    From the selected crossover points, output time ranges from time_stamp to end_time\n    for all qualifying points within directions, as wait intervals.\n    \"\"\"\n    if points_df is None or points_df.empty:\n        return points_df.iloc[0:0]\n    # Require both time_stamp and end_time to exist and be non-empty\n    if 'time_stamp' not in points_df.columns or 'end_time' not in points_df.columns:\n        return points_df.iloc[0:0]\n    wdf = points_df.copy()\n    has_start = wdf['time_stamp'].notna() & wdf['time_stamp'].astype(str).str.strip().ne('')\n    has_end = wdf['end_time'].notna() & wdf['end_time'].astype(str).str.strip().ne('')\n    wdf = wdf[has_start & has_end].copy()\n    if wdf.empty:\n        return wdf\n    # Attach direction via direction.csv mapping\n    try:\n        dir_df = pd.read_csv(DIRECTION_FILE)\n        mask = (dir_df['road_id'] == road_id)\n        if directions:\n            up_dirs = [d.upper() for d in directions]\n            mask &= dir_df['direction'].astype(str).str.upper().isin(up_dirs)\n        if date:\n            mask &= (dir_df['date'] == date)\n        dir_df = dir_df[mask].copy()\n        key_to_dir = {\n            (int(r['vehicle_id']), str(r['date']), int(r['seg_id'])): str(r['direction'])\n            for _, r in dir_df.iterrows()\n        }\n        wdf['direction'] = wdf.apply(\n            lambda r: key_to_dir.get((int(r['vehicle_id']), str(r['date']), int(r['seg_id'])) , ''),\n            axis=1\n        )\n    except Exception:\n        # If direction.csv is unavailable for any reason, still output without direction\n        wdf['direction'] = ''\n    # Add road_id column and select/reorder desired columns\n    wdf['road_id'] = road_id\n    desired_cols = ['road_id', 'vehicle_id', 'date', 'seg_id', 'direction', 'time_stamp', 'end_time']\n    existing_cols = [c for c in desired_cols if c in wdf.columns]\n    return wdf[existing_cols].reset_index(drop=True)\n\n\n# -------------------- Per-second occupancy (A1/A2/B1/B2) --------------------\nDIR4 = ('A1', 'A2', 'B1', 'B2')\n\n\ndef _to_dir4(direction: Any) -> Optional[str]:\n    try:\n        d = str(direction)\n    except Exception:\n        return None\n    for k in DIR4:\n        if d.startswith(k):\n            return k\n    return None\n\n\ndef build_per_second_occupancy(df: pd.DataFrame,\n                               start_col: str,\n                               end_col: str,\n                               direction_col: str) -> pd.DataFrame:\n    \"\"\"\n    Build per-second occupancy counts per (road_id, date) and direction A1/A2/B1/B2.\n    Interval is [start, end) i.e., end exclusive.\n    Returns columns: road_id, date, time, A1, A2, B1, B2\n    \"\"\"\n    if df is None or df.empty:\n        return pd.DataFrame(columns=['road_id', 'date', 'time', *DIR4])\n    work = df.copy()\n    # Map to 4-direction groups\n    work['dir4'] = work[direction_col].map(_to_dir4)\n    work = work.dropna(subset=['dir4']).astype({'dir4': str})\n    # Build absolute timestamps\n    work['start'] = pd.to_datetime(work['date'].astype(str) + ' ' + work[start_col].astype(str), errors='coerce')\n    work['end'] = pd.to_datetime(work['date'].astype(str) + ' ' + work[end_col].astype(str), errors='coerce')\n    # Filter valid, non-zero intervals\n    work = work[(~work['start'].isna()) & (~work['end'].isna()) & (work['start'] < work['end'])].copy()\n    if work.empty:\n        return pd.DataFrame(columns=['road_id', 'date', 'time', *DIR4])\n\n    out_frames: List[pd.DataFrame] = []\n    for (road_id, date_val), g in work.groupby(['road_id', 'date']):\n        # Collect event deltas per direction\n        dir_events: Dict[str, Dict[pd.Timestamp, int]] = {d: {} for d in DIR4}\n        for _, r in g.iterrows():\n            d = r['dir4']\n            s = r['start']\n            e = r['end']\n            dir_events[d][s] = dir_events[d].get(s, 0) + 1\n            dir_events[d][e] = dir_events[d].get(e, 0) - 1\n        # Determine group time span\n        all_keys = []\n        for d in DIR4:\n            all_keys.extend(list(dir_events[d].keys()))\n        if not all_keys:\n            continue\n        t0 = min(all_keys).floor('s')\n        t1 = max(all_keys).ceil('s')\n        if t0 >= t1:\n            continue\n        # Build 1-second index; end exclusive\n        idx = pd.date_range(t0, t1 - pd.Timedelta(seconds=1), freq='s')\n        data = {}\n        for d in DIR4:\n            ev = dir_events[d]\n            if not ev:\n                series = pd.Series(0, index=idx, dtype='int64')\n            else:\n                evs = pd.Series(ev).sort_index()\n                series = evs.cumsum()\n                # Align to idx: forward fill current occupancy and fill gaps with 0\n                series = series.reindex(idx, method='ffill').fillna(0).astype('int64')\n            data[d] = series\n        df_group = pd.DataFrame(data, index=idx).reset_index().rename(columns={'index': 'dt'})\n        df_group['road_id'] = road_id\n        df_group['date'] = date_val\n        df_group['time'] = df_group['dt'].dt.strftime('%H:%M:%S')\n        out_frames.append(df_group[['road_id', 'date', 'time', *DIR4]])\n    if not out_frames:\n        return pd.DataFrame(columns=['road_id', 'date', 'time', *DIR4])\n    out = pd.concat(out_frames, ignore_index=True)\n    # Ensure integer dtype\n    for d in DIR4:\n        out[d] = out[d].astype('int64')\n    return out.sort_values(['road_id', 'date', 'time']).reset_index(drop=True)\n\n\ndef compute_and_write_per_second_counts() -> None:\n    \"\"\"\n    Read data/cross_over_time_try.csv and data/wait.csv,\n    compute per-second occupancy counts for A1/A2/B1/B2, and write:\n      - data/per_second_flow.csv\n      - data/per_second_wait.csv\n    \"\"\"\n    flow_in = os.path.join(DATA_DIR, '/home/mw/project/cross_over_time_try.csv')\n    wait_in = os.path.join(DATA_DIR, '/home/mw/project/wait.csv')\n    flow_out = os.path.join(DATA_DIR, '/home/mw/project/per_second_flow.csv')\n    wait_out = os.path.join(DATA_DIR, '/home/mw/project/per_second_wait.csv')\n\n    # Flow: enter_time -> exit_time\n    try:\n        if os.path.exists(flow_in):\n            fdf = pd.read_csv(flow_in)\n            need_cols = {'road_id', 'date', 'direction', 'enter_time', 'exit_time'}\n            if need_cols.issubset(set(fdf.columns)):\n                flow_ps = build_per_second_occupancy(fdf, 'enter_time', 'exit_time', 'direction')\n                if flow_ps is not None and not flow_ps.empty:\n                    flow_ps.to_csv(flow_out, index=False)\n                    print(f'Wrote {len(flow_ps)} per-second rows to {flow_out}')\n                else:\n                    pd.DataFrame(columns=['road_id', 'date', 'time', *DIR4]).to_csv(flow_out, index=False)\n                    print(f'No per-second flow rows; wrote empty CSV to {flow_out}')\n            else:\n                print(f'[WARN] Missing columns in {flow_in}; expected {need_cols}')\n        else:\n            print(f'[WARN] Flow input not found: {flow_in}')\n    except Exception as e:\n        print(f'[WARN] Failed computing per-second flow: {e}')\n\n    # Wait: time_stamp -> end_time\n    try:\n        if os.path.exists(wait_in):\n            wdf = pd.read_csv(wait_in)\n            need_cols = {'road_id', 'date', 'direction', 'time_stamp', 'end_time'}\n            if need_cols.issubset(set(wdf.columns)):\n                wait_ps = build_per_second_occupancy(wdf, 'time_stamp', 'end_time', 'direction')\n                if wait_ps is not None and not wait_ps.empty:\n                    wait_ps.to_csv(wait_out, index=False)\n                    print(f'Wrote {len(wait_ps)} per-second rows to {wait_out}')\n                else:\n                    pd.DataFrame(columns=['road_id', 'date', 'time', *DIR4]).to_csv(wait_out, index=False)\n                    print(f'No per-second wait rows; wrote empty CSV to {wait_out}')\n            else:\n                print(f'[WARN] Missing columns in {wait_in}; expected {need_cols}')\n        else:\n            print(f'[WARN] Wait input not found: {wait_in}')\n    except Exception as e:\n        print(f'[WARN] Failed computing per-second wait: {e}')\n\n\ndef main():\n    # Hardcoded initial configuration (edit here as needed)\n    road_ids = ['A0003', 'A0008']\n    # Direction groups\n    dirs_a1 = ['A1-1', 'A1-2']  # EW straight\n    dirs_b1 = ['B1-1', 'B1-2']  # NS straight\n    dirs_a2 = ['A2-1', 'A2-2']  # EW left-turn\n    dirs_b2 = ['B2-1', 'B2-2']  # NS left-turn\n    date = None  # or 'YYYY-MM-DD'\n    output_points_unified = os.path.join(DATA_DIR, '/home/mw/project/cross_over.csv')\n    output_intervals_unified = os.path.join(DATA_DIR, '/home/mw/project/cross_over_time.csv')\n    output_wait_unified = os.path.join(DATA_DIR, '/home/mw/project/wait.csv')\n    # A1-specific outputs\n    output_points_a1 = os.path.join(DATA_DIR, '/home/mw/project/cross_overA.csv')\n    output_intervals_a1_real = os.path.join(DATA_DIR, '/home/mw/project/corss_timeA_real.csv')\n\n    print(f'Generating crossover for roads {road_ids}, date={date or \"ALL\"}')\n    print(f' - A1 (straight EW) = {dirs_a1}')\n    print(f' - B1 (straight NS) = {dirs_b1}')\n    print(f' - A2 (left-turn EW) = {dirs_a2}')\n    print(f' - B2 (left-turn NS) = {dirs_b2}')\n\n    intervals_all: List[Dict[str, Any]] = []\n    points_parts: List[pd.DataFrame] = []\n    wait_parts: List[pd.DataFrame] = []\n    a1_points_real_parts: List[pd.DataFrame] = []\n    a1_intervals_real_parts: List[Dict[str, Any]] = []\n    intervals_with_outer_extra: List[Dict[str, Any]] = []\n\n    for road_id in road_ids:\n        print(f'Processing road {road_id}...')\n        # Compute straight bands\n        pts_a1, intervals_a1 = compute_crossover_straight(road_id, dirs_a1, date, 'west', 'east')\n        pts_b1, intervals_b1 = compute_crossover_straight(road_id, dirs_b1, date, 'south', 'north')\n        # Compute left-turns per mapping\n        pts_a2_1, intervals_a2_1 = compute_crossover_turn(road_id, ['A2-1'], date, 'north', 'east')\n        pts_a2_2, intervals_a2_2 = compute_crossover_turn(road_id, ['A2-2'], date, 'south', 'west')\n        pts_b2_1, intervals_b2_1 = compute_crossover_turn(road_id, ['B2-1'], date, 'west', 'north')\n        pts_b2_2, intervals_b2_2 = compute_crossover_turn(road_id, ['B2-2'], date, 'east', 'south')\n\n        # Accumulate intervals\n        for part in [intervals_a1, intervals_b1, intervals_a2_1, intervals_a2_2, intervals_b2_1, intervals_b2_2]:\n            if part:\n                intervals_all.extend(part)\n\n        # Extra: generate outer-fallback intervals for segments with no inside points\n        try:\n            outer_a1 = compute_crossover_straight_outer(road_id, dirs_a1, date, 'west', 'east')\n            outer_b1 = compute_crossover_straight_outer(road_id, dirs_b1, date, 'south', 'north')\n            outer_a2_1 = compute_crossover_turn_outer(road_id, ['A2-1'], date, 'north', 'east')\n            outer_a2_2 = compute_crossover_turn_outer(road_id, ['A2-2'], date, 'south', 'west')\n            outer_b2_1 = compute_crossover_turn_outer(road_id, ['B2-1'], date, 'west', 'north')\n            outer_b2_2 = compute_crossover_turn_outer(road_id, ['B2-2'], date, 'east', 'south')\n            for part in [outer_a1, outer_b1, outer_a2_1, outer_a2_2, outer_b2_1, outer_b2_2]:\n                if part:\n                    intervals_with_outer_extra.extend(part)\n        except Exception as e:\n            print(f'[WARN] Failed to compute outer intervals for {road_id}: {e}')\n\n        # A1 real entry/exit times and synthesized points (lane_divider-based)\n        try:\n            a1_points_real, a1_intervals_real = compute_a1_real_outputs(road_id, dirs_a1, date)\n            if a1_points_real is not None and not a1_points_real.empty:\n                if 'road_id' not in a1_points_real.columns:\n                    a1_points_real['road_id'] = road_id\n                a1_points_real_parts.append(a1_points_real)\n            if a1_intervals_real:\n                a1_intervals_real_parts.extend(a1_intervals_real)\n        except Exception as e:\n            print(f'[WARN] Failed to compute A1 real outputs for {road_id}: {e}')\n\n        # Accumulate points per road\n        pts_concat_list = [df for df in [pts_a1, pts_b1, pts_a2_1, pts_a2_2, pts_b2_1, pts_b2_2] if df is not None and not df.empty]\n        if pts_concat_list:\n            pts_all = pd.concat(pts_concat_list, ignore_index=True)\n            # Ensure road_id column exists\n            if 'road_id' not in pts_all.columns:\n                pts_all['road_id'] = road_id\n            # Attach direction column by mapping (vehicle_id, date, seg_id) -> direction from direction.csv\n            try:\n                dir_map = pd.read_csv(DIRECTION_FILE)\n                dir_map = dir_map[dir_map['road_id'] == road_id].copy()\n                if date:\n                    dir_map = dir_map[dir_map['date'] == date]\n                dir_map = dir_map[['vehicle_id', 'date', 'seg_id', 'direction']].drop_duplicates()\n                pts_all = pts_all.merge(dir_map, on=['vehicle_id', 'date', 'seg_id'], how='left')\n            except Exception as e:\n                print(f'[WARN] Failed to attach direction to points for {road_id}: {e}')\n                if 'direction' not in pts_all.columns:\n                    pts_all['direction'] = ''\n            points_parts.append(pts_all)\n\n            # Wait intervals for this road (per group)\n            for dirs, pts in [\n                (dirs_a1, pts_a1),\n                (dirs_b1, pts_b1),\n                (dirs_a2, pd.concat([p for p in [pts_a2_1, pts_a2_2] if p is not None and not p.empty], ignore_index=True) if any(p is not None and not p.empty for p in [pts_a2_1, pts_a2_2]) else pd.DataFrame()),\n                (dirs_b2, pd.concat([p for p in [pts_b2_1, pts_b2_2] if p is not None and not p.empty], ignore_index=True) if any(p is not None and not p.empty for p in [pts_b2_1, pts_b2_2]) else pd.DataFrame()),\n            ]:\n                if pts is not None and not pts.empty:\n                    w = build_wait_df(road_id, dirs, date, pts)\n                    if w is not None and not w.empty:\n                        # Ensure road_id exists\n                        if 'road_id' not in w.columns:\n                            w['road_id'] = road_id\n                        wait_parts.append(w)\n\n    # Write unified intervals\n    if intervals_all:\n        df_intervals_all = pd.DataFrame(intervals_all)\n        df_intervals_all.to_csv(output_intervals_unified, index=False)\n        print(f'Wrote {len(df_intervals_all)} intervals to {output_intervals_unified}')\n    else:\n        print('/home/mw/project/No intervals to write to cross_over_time.csv')\n\n    # Write unified points\n    if points_parts:\n        pts_all = pd.concat(points_parts, ignore_index=True)\n        if 'road_id' not in pts_all.columns:\n            # Fallback set if somehow missing\n            pts_all['road_id'] = road_ids[0]\n        pts_all.to_csv(output_points_unified, index=False)\n        print(f'Wrote {len(pts_all)} points to {output_points_unified}')\n    else:\n        print('/home/mw/project/No points to write to cross_over.csv')\n\n    # Write unified wait.csv\n    if wait_parts:\n        wait_all = pd.concat(wait_parts, ignore_index=True)\n        if 'road_id' not in wait_all.columns:\n            wait_all['road_id'] = road_ids[0]\n        wait_all.to_csv(output_wait_unified, index=False)\n        print(f'Wrote {len(wait_all)} wait intervals to {output_wait_unified}')\n    else:\n        print('No wait intervals found (no rows with non-empty end_time).')\n\n    # Write cross_over_time_with_outer.csv (union of normal intervals and extra outer ones)\n    output_intervals_with_outer = os.path.join(DATA_DIR, '/home/mw/project/cross_over_time_with_outer.csv')\n    intervals_all_with_outer = list(intervals_all)\n    if intervals_with_outer_extra:\n        intervals_all_with_outer.extend(intervals_with_outer_extra)\n    if intervals_all_with_outer:\n        df_with_outer = pd.DataFrame(intervals_all_with_outer)\n        df_with_outer.to_csv(output_intervals_with_outer, index=False)\n        print(f'Wrote {len(df_with_outer)} intervals to {output_intervals_with_outer}')\n    else:\n        print('/home/mw/project/No intervals to write to cross_over_time_with_outer.csv')\n\n    # Write cross_over_time_try.csv (ONLY outer-adjacent intervals)\n    output_intervals_try = os.path.join(DATA_DIR, '/home/mw/project/cross_over_time_try.csv')\n    if intervals_with_outer_extra:\n        df_try = pd.DataFrame(intervals_with_outer_extra)\n        df_try.to_csv(output_intervals_try, index=False)\n        print(f'Wrote {len(df_try)} intervals to {output_intervals_try}')\n    else:\n        print('/home/mw/project/No intervals to write to cross_over_time_try.csv')\n\n    # Write A1-specific outputs\n    if a1_intervals_real_parts:\n        df_a1_real = pd.DataFrame(a1_intervals_real_parts)\n        df_a1_real.to_csv(output_intervals_a1_real, index=False)\n        print(f'Wrote {len(df_a1_real)} intervals to {output_intervals_a1_real}')\n    else:\n        print('No A1 real intervals to write.')\n    if a1_points_real_parts:\n        df_a1_pts = pd.concat(a1_points_real_parts, ignore_index=True)\n        if 'road_id' not in df_a1_pts.columns:\n            df_a1_pts['road_id'] = road_ids[0]\n        df_a1_pts.to_csv(output_points_a1, index=False)\n        print(f'Wrote {len(df_a1_pts)} points to {output_points_a1}')\n    else:\n        print('No A1 real points to write.')\n    # Compute per-second flow/wait series based on cross_over_time_try.csv and wait.csv\n    compute_and_write_per_second_counts()\n    return 0\n\n\nif __name__ == '__main__':\n    raise SystemExit(main())\n\n\n"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}