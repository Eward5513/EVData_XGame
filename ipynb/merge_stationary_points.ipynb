{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Auto-generated from `merge_stationary_points.py`\n\nGenerated on 2025-11-09T22:01:34.\n\nThis notebook was created programmatically to mirror the original Python script.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nimport sys\nproject_root = str(Path.cwd().parent.resolve())\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nMerge consecutive low-speed (stationary) trajectory points into representative points\nand add an end_time column to indicate the last timestamp of merged clusters.\n\nInputs:\n  - /home/tzhang174/EVData_XGame/A0003_split.csv\n  - /home/tzhang174/EVData_XGame/A0008_split.csv\n\nOutputs:\n  - /home/tzhang174/EVData_XGame/A0003_merged.csv\n  - /home/tzhang174/EVData_XGame/A0008_merged.csv\n\nRules:\n  - Only points with speed < 3 (km/h) are eligible for merging.\n  - Merge consecutive points when each adjacent pair is within a distance threshold.\n  - Threshold depends on sampling interval (median Δcollectiontime in seconds):\n      * If ~1s (0.8s–1.2s), threshold = 3 m\n      * Else threshold = 5 m\n  - Any point with speed ≥ 3 is never merged.\n  - For merged runs (length ≥ 2):\n      * Output one row located at the average latitude/longitude of the run\n      * time_stamp = first point's time_stamp; end_time = last point's time_stamp\n      * collectiontime = first point's collectiontime\n      * Other fields: keep from the first row, except numeric speed/acceleratorpedal averaged\n  - For non-merged points: copy as-is with end_time empty\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom typing import List\n\nimport numpy as np\nimport pandas as pd\nfrom trajectory_utils import pair_distance_m\nfrom config import BASE_DIR\n\n\nINPUT_FILES = [\n    os.path.join(BASE_DIR, \"data\", \"/home/mw/project/A0003_split.csv\"),\n    os.path.join(BASE_DIR, \"data\", \"/home/mw/project/A0008_split.csv\"),\n]\n\n\ndef determine_distance_threshold_secs(times_ms: np.ndarray) -> float:\n    \"\"\"\n    Determine the spatial threshold (meters) based on the median sampling interval (seconds).\n    If the median Δt is ~1s (0.8..1.2), return 3m; otherwise return 5m.\n    \"\"\"\n    if times_ms is None or len(times_ms) < 2:\n        return 5.0\n    diffs = np.diff(times_ms.astype(np.float64)) / 1000.0  # seconds\n    # Exclude non-positive diffs to avoid duplicated timestamps\n    diffs = diffs[diffs > 0]\n    if len(diffs) == 0:\n        return 5.0\n    med = float(np.median(diffs))\n    if 0.8 <= med <= 1.2:\n        return 3.0\n    return 5.0\n\n\ndef merge_group(df_group: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Merge consecutive stationary points within a single (road_id, vehicle_id, date, seg_id) group.\n    Returns a new dataframe with an added 'end_time' column.\n    \"\"\"\n    if df_group.empty:\n        return df_group\n\n    # Ensure proper ordering\n    g = df_group.sort_values('collectiontime').reset_index(drop=True)\n\n    # Determine distance threshold based on sampling interval\n    times = g['collectiontime'].to_numpy(dtype=np.int64)\n    dist_thresh_m = determine_distance_threshold_secs(times)\n\n    # Pull needed arrays\n    lats = g['latitude'].to_numpy(dtype=float)\n    lons = g['longitude'].to_numpy(dtype=float)\n    # Speed in km/h (as-is); NaN treated as large to disable merge\n    sp = pd.to_numeric(g['speed'], errors='coerce').to_numpy()\n    sp = np.where(np.isnan(sp), np.inf, sp)\n\n    out_rows: List[pd.Series] = []\n    n = len(g)\n    i = 0\n    while i < n:\n        # Attempt to start a stationary run at i\n        if sp[i] < 3.0:\n            j = i + 1\n            while j < n:\n                if not (sp[j] < 3.0):\n                    break\n                # Check distance constraint between consecutive points\n                d_m = pair_distance_m(lats[j - 1], lons[j - 1], lats[j], lons[j])\n                if d_m > dist_thresh_m:\n                    break\n                j += 1\n\n            run_len = j - i\n            if run_len >= 2:\n                sub = g.iloc[i:j].copy()\n                # Build output row primarily from the first row\n                row = sub.iloc[0].copy()\n                # Average coordinates for the merged representative point\n                row['latitude'] = float(sub['latitude'].mean())\n                row['longitude'] = float(sub['longitude'].mean())\n                # Keep collectiontime/time_stamp from the first; set end_time to last time_stamp\n                if 'time_stamp' in sub.columns:\n                    row['end_time'] = str(sub.iloc[-1]['time_stamp'])\n                else:\n                    row['end_time'] = ''\n                # Average numeric metrics where appropriate\n                if 'speed' in sub.columns:\n                    row['speed'] = float(pd.to_numeric(sub['speed'], errors='coerce').mean())\n                if 'acceleratorpedal' in sub.columns:\n                    row['acceleratorpedal'] = float(pd.to_numeric(sub['acceleratorpedal'], errors='coerce').mean())\n                # Keep brakestatus/gearnum/havebrake/havedriver from the first (if present)\n                out_rows.append(row)\n                i = j\n                continue\n        # Not merged: copy as-is with empty end_time\n        row = g.iloc[i].copy()\n        row['end_time'] = ''\n        out_rows.append(row)\n        i += 1\n\n    out = pd.DataFrame(out_rows)\n    return out\n\n\ndef process_file(input_path: str, output_path: str) -> None:\n    print(f\"Reading {input_path} ...\")\n    if not os.path.exists(input_path):\n        raise FileNotFoundError(input_path)\n    df = pd.read_csv(input_path)\n    if df.empty:\n        print(f\"Input is empty; writing empty output: {output_path}\")\n        df_out = df.copy()\n        if 'end_time' not in df_out.columns:\n            df_out['end_time'] = ''\n        # Ensure output directory exists even in empty-input path\n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n        df_out.to_csv(output_path, index=False)\n        return\n\n    required_cols = ['vehicle_id', 'date', 'seg_id', 'collectiontime', 'latitude', 'longitude', 'speed']\n    missing = [c for c in required_cols if c not in df.columns]\n    if missing:\n        raise ValueError(f\"Missing required columns in {input_path}: {missing}\")\n\n    # Process per (road_id, vehicle_id, date, seg_id) if road_id exists; else per (vehicle_id, date, seg_id)\n    group_cols = ['vehicle_id', 'date', 'seg_id']\n    if 'road_id' in df.columns:\n        group_cols = ['road_id'] + group_cols\n\n    out_parts: List[pd.DataFrame] = []\n    for _, sub in df.groupby(group_cols, sort=False):\n        out_parts.append(merge_group(sub))\n    merged = pd.concat(out_parts, ignore_index=True)\n\n    # Reorder columns: keep original order and append 'end_time' at the end\n    cols = list(df.columns)\n    if 'end_time' not in cols:\n        cols.append('end_time')\n    # Retain only columns present in merged (in case some optional columns are absent)\n    final_cols = [c for c in cols if c in merged.columns]\n    merged = merged[final_cols]\n\n    print(f\"Writing {output_path} ...\")\n    # Ensure output directory exists\n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n    merged.to_csv(output_path, index=False)\n    print(f\"Wrote {len(merged)} rows to {output_path}\")\ndef main():\n    for in_path in INPUT_FILES:\n        base = os.path.basename(in_path)\n        name_no_ext = base.rsplit('.', 1)[0]\n        out_path = os.path.join(BASE_DIR, \"data\", f\"{name_no_ext.replace('_split', '')}_merged.csv\")\n        process_file(in_path, out_path)\n\n# Module is imported by main.py; no standalone execution\n\n\n"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}