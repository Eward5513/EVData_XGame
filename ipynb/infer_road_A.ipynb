{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Auto-generated from `infer_road_A.py`\n\nGenerated on 2025-11-09T22:01:34.\n\nThis notebook was created programmatically to mirror the original Python script.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nimport sys\nproject_root = str(Path.cwd().parent.resolve())\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "\n# -*- coding: utf-8 -*-\n\"\"\"\nFixed 3-vs-2 straight lanes with robust geographic-north labeling.\n\n- Data dir (fixed): /home/tzhang174/EVData_XGame/data\n- Files: direction.csv, A0003_refined.csv, A0008_refined.csv\n- Filter: only A1-1 / A1-2\n- Divider: PCA-1D -> along-path binning (bin_size_m=17) -> per-bin two-peak on t -> midpoint -> interpolate + smooth\n- Lanes: north side = 3 centers at +{1.75, 5.25, 8.75} m, south side = 2 centers at -{1.75, 5.25} m\n- Robust \"north\" test: build a +half (1.75 m) offset of divider, convert to lon/lat, check median(lat_offset - lat_divider);\n  if negative, invert the sign so that \"north\" is the side with higher latitude.\n- Output JSON: /home/tzhang174/EVData_XGame/data/intersection.json\n\"\"\"\n\nimport os, csv, json, math\nfrom typing import Any, Dict, List, Tuple\nimport numpy as np\n\n# ---------------- Configuration ----------------\nDATA_DIR      = \"/home/tzhang174/EVData_XGame/data\"\nINPUT_FILES   = [(\"/home/mw/project/A0003_refined.csv\", \"A0003\"), (\"/home/mw/project/A0008_refined.csv\", \"A0008\")]\nOUTPUT_JSON   = \"/home/mw/project/intersection.json\"\n\nBIN_SIZE_M        = 17.0\nMIN_PTS_PER_BIN   = 25\nNBINS_T           = 64\nMIN_LANE_SEP_M    = 3.2\nSIGMA_BINS        = 1.5\nSMOOTH_WIN        = 7\nLANE_WIDTH        = 3.5\nHALF              = LANE_WIDTH / 2.0  # 1.75 m\n\n# ---------------- Geometry helpers ----------------\ndef lonlat_to_local_xy(lon, lat, lon0=None, lat0=None):\n    lon = np.asarray(lon, float); lat = np.asarray(lat, float)\n    if lon0 is None: lon0 = float(np.nanmean(lon))\n    if lat0 is None: lat0 = float(np.nanmean(lat))\n    R = 6371000.0\n    x = R*np.cos(np.deg2rad(lat0))*np.deg2rad(lon - lon0)\n    y = R*np.deg2rad(lat - lat0)\n    return x, y, lon0, lat0\n\ndef local_xy_to_lonlat(x, y, lon0, lat0):\n    R = 6371000.0\n    lon = lon0 + np.rad2deg(x/(R*np.cos(np.deg2rad(lat0))))\n    lat = lat0 + np.rad2deg(y/R)\n    return lon, lat\n\ndef pca_first_axis(X: np.ndarray):\n    mu = X.mean(axis=0)\n    Y  = X - mu\n    C  = (Y.T @ Y) / max(len(X)-1, 1)\n    w, V = np.linalg.eigh(C)\n    u = V[:, np.argmax(w)]; u /= np.linalg.norm(u)\n    v = np.array([-u[1], u[0]])\n    return u, v, mu\n\n# ------------- Per-bin two-peak detection -------------\ndef _gauss_smooth_1d(y: np.ndarray, sigma_bins=1.5, radius=4):\n    if len(y) == 0: return y\n    r = int(max(1, np.ceil(radius*sigma_bins)))\n    xs = np.arange(-r, r+1)\n    ker = np.exp(-0.5*(xs/sigma_bins)**2); ker /= ker.sum()\n    pad = (len(ker)-1)//2\n    yp  = np.pad(y, (pad,pad), mode='edge')\n    return np.convolve(yp, ker, mode='valid')\n\ndef _two_peaks_in_bin(tvals: np.ndarray, nbins=64, min_sep=3.2, sigma_bins=1.5):\n    \"\"\"\n    Return (t_low, t_up); if only one peak found, returns (t_single, None);\n    else returns None.\n    \"\"\"\n    if len(tvals) < 5:\n        return None\n    tmin, tmax = np.quantile(tvals, 0.02), np.quantile(tvals, 0.98)\n    if not np.isfinite(tmin) or not np.isfinite(tmax):\n        return None\n    if tmax <= tmin: tmax = tmin + 1e-3\n    H, edges = np.histogram(tvals, bins=nbins, range=(tmin, tmax))\n    Hs = _gauss_smooth_1d(H, sigma_bins=sigma_bins)\n\n    peaks = []\n    for i in range(1, len(Hs)-1):\n        if Hs[i] >= Hs[i-1] and Hs[i] >= Hs[i+1] and Hs[i] > 0:\n            t_center = 0.5*(edges[i] + edges[i+1])\n            peaks.append((Hs[i], t_center))\n    if not peaks:\n        return None\n    peaks.sort(reverse=True, key=lambda z: z[0])\n\n    top = []\n    for h, tc in peaks:\n        if not top or all(abs(tc - tc2) >= min_sep for _, tc2 in top):\n            top.append((h, tc))\n        if len(top) == 2:\n            break\n\n    if len(top) == 1:\n        return (top[0][1], None)\n    t1 = min(top[0][1], top[1][1]); t2 = max(top[0][1], top[1][1])\n    return (t1, t2)\n\n# ------------- Divider from (s,t) -------------\ndef _lane_divider_xy_from_st(s: np.ndarray, t: np.ndarray,\n                             u: np.ndarray, v: np.ndarray, mu: np.ndarray,\n                             bin_size_m=BIN_SIZE_M, min_pts_per_bin=MIN_PTS_PER_BIN, nbins_t=NBINS_T,\n                             min_lane_sep_m=MIN_LANE_SEP_M, sigma_bins=SIGMA_BINS, smooth_win=SMOOTH_WIN):\n    if s.size == 0: return np.array([]), np.array([])\n    smin, smax = float(np.min(s)), float(np.max(s))\n    if not np.isfinite(smin) or not np.isfinite(smax) or smax - smin < 1e-9:\n        return np.array([]), np.array([])\n    edges = np.arange(smin, smax + bin_size_m, bin_size_m)\n    idx   = np.digitize(s, edges) - 1\n\n    T_div_bins = np.full(len(edges)-1, np.nan)\n\n    for b in range(len(edges)-1):\n        m = (idx == b)\n        if np.sum(m) < min_pts_per_bin:\n            continue\n        tp = _two_peaks_in_bin(t[m], nbins=nbins_t, min_sep=min_lane_sep_m, sigma_bins=sigma_bins)\n        if tp is None:\n            continue\n        t1, t2 = tp\n        if t2 is None:\n            t_div = t1\n        else:\n            t_div = 0.5*(t1 + t2)\n        T_div_bins[b] = float(t_div)\n\n    if np.all(np.isnan(T_div_bins)):\n        return np.array([]), np.array([])\n\n    idx_bins = np.arange(len(T_div_bins))\n    good = ~np.isnan(T_div_bins)\n    if np.sum(good) >= 2:\n        T_div_bins = np.interp(idx_bins, idx_bins[good], T_div_bins[good])\n    elif np.sum(good) == 1:\n        T_div_bins[:] = T_div_bins[good][0]\n\n    S_centers = 0.5*(edges[:-1] + edges[1:])\n    T_arr = T_div_bins.copy()\n    if smooth_win and smooth_win > 1:\n        if smooth_win % 2 == 0: smooth_win += 1\n        pad = smooth_win//2\n        ker = np.ones(smooth_win)/smooth_win\n        Tp  = np.pad(T_arr, (pad,pad), mode='edge')\n        T_arr = np.convolve(Tp, ker, mode='valid')\n\n    C = mu + S_centers[:,None]*u + T_arr[:,None]*v\n    return C[:,0], C[:,1]\n\n# ------------- Normals and offsets -------------\ndef _compute_normals(cx: np.ndarray, cy: np.ndarray):\n    n = len(cx)\n    if n < 2:\n        return np.array([]), np.array([])\n    tx = np.zeros(n); ty = np.zeros(n)\n    dx = np.diff(cx); dy = np.diff(cy)\n    tx[0], ty[0] = dx[0], dy[0]\n    tx[-1], ty[-1] = dx[-1], dy[-1]\n    if n > 2:\n        tx[1:-1] = (cx[2:] - cx[:-2]) * 0.5\n        ty[1:-1] = (cy[2:] - cy[:-2]) * 0.5\n    L = np.hypot(tx, ty); L[L==0]=1.0\n    tx/=L; ty/=L\n    nx, ny = -ty, tx\n    NL = np.hypot(nx, ny); NL[NL==0]=1.0\n    nx/=NL; ny/=NL\n    return nx, ny\n\ndef _offset_polyline(cx: np.ndarray, cy: np.ndarray, d: float):\n    nx, ny = _compute_normals(cx, cy)\n    if nx.size == 0:\n        return np.array([]), np.array([])\n    return cx + d*nx, cy + d*ny\n\n# ------------- IO helpers -------------\ndef load_directions(path: str) -> set:\n    allowed = set()\n    with open(path, \"r\", newline=\"\", encoding=\"utf-8\") as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            d = row.get(\"direction\",\"\").strip()\n            if d in {\"A1-1\",\"A1-2\"}:\n                key = (\n                    row.get(\"vehicle_id\",\"\").strip(),\n                    row.get(\"date\",\"\").strip(),\n                    row.get(\"seg_id\",\"\").strip(),\n                    row.get(\"road_id\",\"\").strip(),\n                )\n                allowed.add(key)\n    return allowed\n\ndef load_points(path: str, allowed: set, expect_road: str):\n    lons, lats = [], []\n    with open(path, \"r\", newline=\"\", encoding=\"utf-8\") as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            if row.get(\"road_id\",\"\").strip() != expect_road:\n                continue\n            key = (\n                row.get(\"vehicle_id\",\"\").strip(),\n                row.get(\"date\",\"\").strip(),\n                row.get(\"seg_id\",\"\").strip(),\n                row.get(\"road_id\",\"\").strip(),\n            )\n            if key not in allowed:\n                continue\n            try:\n                lon = float(row.get(\"longitude\",\"\"))\n                lat = float(row.get(\"latitude\",\"\"))\n            except ValueError:\n                continue\n            if math.isfinite(lon) and math.isfinite(lat):\n                lons.append(lon); lats.append(lat)\n    return np.array(lons, float), np.array(lats, float)\n\n# ------------- Main per-road pipeline -------------\ndef process_one(points_csv: str, road_id: str, allowed: set):\n    lons, lats = load_points(points_csv, allowed, road_id)\n    if lons.size < 10:\n        return {\n            \"lane_divider\": [],\n            \"north\": {\"lanes\": {\"north_lane1\": [], \"north_lane2\": [], \"north_lane3\": []}},\n            \"south\": {\"lanes\": {\"south_lane1\": [], \"south_lane2\": []}}\n        }\n\n    x, y, lon0, lat0 = lonlat_to_local_xy(lons, lats)\n    X  = np.column_stack([x, y])\n    u, v, mu = pca_first_axis(X)\n    Y  = X - mu\n    s  = Y @ u\n    t  = Y @ v\n\n    # Divider in local XY\n    cx, cy = _lane_divider_xy_from_st(s, t, u, v, mu)\n    if cx.size < 2:\n        return {\n            \"lane_divider\": [],\n            \"north\": {\"lanes\": {\"north_lane1\": [], \"north_lane2\": [], \"north_lane3\": []}},\n            \"south\": {\"lanes\": {\"south_lane1\": [], \"south_lane2\": []}}\n        }\n\n    # --- Robust geographic-north test using latitudes ---\n    # Build a +half offset (mathematical + side), compare latitude vs divider\n    ox_test, oy_test = _offset_polyline(cx, cy, HALF)\n    test_lon, test_lat = local_xy_to_lonlat(ox_test, oy_test, lon0, lat0)\n    div_lon,  div_lat  = local_xy_to_lonlat(cx, cy, lon0, lat0)\n    # If median(test_lat - div_lat) < 0, then mathematical '+' points to geographic south;\n    # we should invert signs so that '+' corresponds to true north.\n    import numpy as _np\n    sign = +1.0\n    if _np.median(test_lat - div_lat) < 0.0:\n        sign = -1.0\n\n    # Offsets: fixed counts (north=3, south=2) with corrected sign so that 'north' is geographic north\n    north_offsets = [ sign*(HALF + k*LANE_WIDTH) for k in range(3) ]   # +1.75,+5.25,+8.75 toward geographic north\n    south_offsets = [-sign*(HALF + k*LANE_WIDTH) for k in range(2) ]   # -1.75,-5.25 toward geographic south\n\n    # Divider to lon/lat (already computed as div_lon/div_lat)\n    out = {\n        \"lane_divider\": [[float(a), float(b)] for a,b in zip(div_lon.tolist(), div_lat.tolist())],\n        \"north\": {\"lanes\": {}},\n        \"south\": {\"lanes\": {}}\n    }\n\n    # Build offset lanes\n    for i, d in enumerate(north_offsets, start=1):\n        ox, oy = _offset_polyline(cx, cy, d)\n        lon, lat = local_xy_to_lonlat(ox, oy, lon0, lat0)\n        out[\"north\"][\"lanes\"][f\"north_lane{i}\"] = [[float(a), float(b)] for a,b in zip(lon.tolist(), lat.tolist())]\n    for i, d in enumerate(south_offsets, start=1):\n        ox, oy = _offset_polyline(cx, cy, d)\n        lon, lat = local_xy_to_lonlat(ox, oy, lon0, lat0)\n        out[\"south\"][\"lanes\"][f\"south_lane{i}\"] = [[float(a), float(b)] for a,b in zip(lon.tolist(), lat.tolist())]\n\n    return out\n\ndef main():\n    direction_csv = \"/home/mw/project/direction.csv\"\n    allowed = load_directions(direction_csv)\n\n    result = {}\n    for fname, road in INPUT_FILES:\n        path = os.path.join(DATA_DIR, fname)\n        if not os.path.exists(path):\n            result[road] = {\n                \"lane_divider\": [],\n                \"north\": {\"lanes\": {\"north_lane1\": [], \"north_lane2\": [], \"north_lane3\": []}},\n                \"south\": {\"lanes\": {\"south_lane1\": [], \"south_lane2\": []}}\n            }\n            continue\n        result[road] = process_one(path, road, allowed)\n\n    with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n        json.dump(result, f, ensure_ascii=False, indent=2)\n    print(f\"Wrote {OUTPUT_JSON}\")\n\nif __name__ == \"__main__\":\n    main()\n"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}