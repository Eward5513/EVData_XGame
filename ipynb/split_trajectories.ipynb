{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Auto-generated from `split_trajectories.py`\n\nGenerated on 2025-11-09T22:01:34.\n\nThis notebook was created programmatically to mirror the original Python script.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nimport sys\nproject_root = str(Path.cwd().parent.resolve())\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nSplit trajectories in A0003.csv and A0008.csv by adaptive time-gap rule.\n\nOutput files:\n- A0003_split.csv\n- A0008_split.csv\n\nSchema: same as input, but insert seg_id immediately after vehicle_id.\nseg_id starts at 0 per (vehicle_id, date) trajectory; if no split occurs, all rows have seg_id=0.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport math\nimport os\nfrom config import BASE_DIR, CENTERS\n\n# Intersection centers are passed per road; no global default center\n\n# Manual overrides: hardcoded segmentation per (road_id, vehicle_id, date)\n# Define segments using 1-based inclusive positions within the group's time-ordered rows.\n# Example: ('A0003', 543, '2024-06-20'): {'segments': [(1, 3), (4, None)]}\n# means: first 3 points = seg 0, remaining points = seg 1.\nMANUAL_OVERRIDES: dict[tuple[str, int, str], dict] = {\n    # Add your overrides here:\n    ('A0003', 543, '2024-06-20'): {'segments': [(1, 3), (4, None)]},\n    ('A0003', 296, '2024-06-19'): {'segments': [(1, 25), (26, None)]},\n    ('A0008', 132, '2024-06-17'): {'segments': [(1, 2)]},\n    ('A0008', 622, '2024-06-20'): {'segments': [(3, 4)]},\n    ('A0008', 348, '2024-06-19'): {'segments': [(1, 3)]},\n    ('A0003', 287, '2024-06-19'): {'segments': [(3, 20),(55,66),(67,None)]},\n    ('A0003', 1157, '2024-06-21'): {'segments': [(1, 6),(7,None)]},\n    ('A0008', 1665, '2024-06-17'): {'segments': [(1, 10),(11,14),(15,None)]},\n    ('A0008', 18, '2024-06-19'): {'segments': [(1, 12),(13,23),(24,None)]},\n    ('A0008', 1999, '2024-06-18'): {'segments': [(1, 6),(7,None)]},\n    ('A0008', 1303, '2024-06-21'): {'segments': [(1, 14),(15,None)]},\n    ('A0008', 1775, '2024-06-19'): {'segments': [(1, 3),(3,None)]},\n    ('A0003', 1581, '2024-06-17'): {'segments': [(1, 2),(2,None)]},\n    ('A0003', 2297, '2024-06-19'): {'segments': [(1, 2),(2,None)]},\n    ('A0003', 217, '2024-06-19'): {'segments': [(1, 10),(79,None)]},\n    ('A0003', 1614, '2024-06-17'): {'segments': [(20,None)]},\n    ('A0003', 812, '2024-06-18'): {'segments': [(11,None)]},\n    ('A0003', 1117, '2024-06-21'): {'segments': [(68,None)]},\n}\n\n# Manual exclusions: remove entire segments after splitting/overrides.\n# Key: (road_id, vehicle_id, date, seg_id)\n# Example: {('A0008', 1775, '2024-06-19', -1)}  # seg_id=-1 means remove ALL segments for that (road_id, vehicle_id, date)\nMANUAL_EXCLUSIONS: set[tuple[str, int, str, int]] = {\n    ('A0003', 27, '2024-06-19', -1),\n    ('A0003', 663, '2024-06-20', -1),\n    ('A0003', 276, '2024-06-19', -1),\n    ('A0003', 1443, '2024-06-17', 1),\n    ('A0003', 496, '2024-06-20', 1),\n    ('A0003', 1602, '2024-06-17', -1),\n\n}\n\n# Center-based splitting hysteresis thresholds (meters)\n# near: considered \"near center\" when distance <= NEAR_RADIUS_M\n# far: considered \"far from center\" when distance >= FAR_RADIUS_M\n# Using hysteresis avoids flapping near the boundary\nNEAR_RADIUS_M = 100.0\nFAR_RADIUS_M = 150.0\nDR_NOISE_EPS_M = 0.5  # minimal radial change to consider trend change (meters)\n\n\n# Exclusion radius for preprocessing (meters)\nEXCLUDE_OUTSIDE_RADIUS_M = 200.0\n# If a segment has no points within the exclusion radius, keep it when the\n# angular change of start vs end around the center exceeds this threshold (deg)\nANGULAR_CHANGE_DEG_THRESHOLD = 60.0\n\n\ndef exclude_segments_outside_radius(\n    df: pd.DataFrame,\n    center_lat: float,\n    center_lon: float,\n    radius_m: float = EXCLUDE_OUTSIDE_RADIUS_M,\n) -> tuple[pd.DataFrame, pd.DataFrame, dict]:\n    \"\"\"\n    Remove segments (vehicle_id, date, seg_id) whose ALL points lie beyond radius_m from the center,\n    EXCEPT keep segments whose start vs end polar angle around the center changes by more than\n    ANGULAR_CHANGE_DEG_THRESHOLD degrees.\n\n    Returns (kept_df, excluded_df, stats_dict).\n    \"\"\"\n    if df.empty:\n        return df, df.iloc[0:0], {\"excluded_segments\": 0, \"excluded_rows\": 0}\n\n    out = df.copy()\n    # Ensure seg_id exists and is integer\n    if 'seg_id' not in out.columns:\n        raise ValueError(\"exclude_segments_outside_radius requires seg_id column\")\n\n    # Compute per-row distance to center (meters)\n    lats = out['latitude'].to_numpy()\n    lons = out['longitude'].to_numpy()\n    dy = (lats - center_lat) * 111000.0\n    dx = (lons - center_lon) * 111000.0 * np.cos(np.radians(lats))\n    dist = np.sqrt(dx * dx + dy * dy)\n    near = dist <= float(radius_m)\n\n    # For each (vehicle_id, date, seg_id), keep if ANY near==True; else evaluate angular change rule\n    grp_keys = ['vehicle_id', 'date', 'seg_id']\n    # Make sure seg_id is int for stable grouping\n    out['seg_id'] = out['seg_id'].astype('int64')\n    any_near = (\n        pd.Series(near, index=out.index)\n        .groupby([out['vehicle_id'], out['date'], out['seg_id']])\n        .transform('any')\n    )\n\n    # Start with keep mask based on near; we'll add angle-based keep for groups with no near points\n    keep_mask = any_near.copy()\n\n    # Helper: compute normalized polar angle (degrees) of vector center->(lat,lon)\n    def compute_angle_deg(lat_val: float, lon_val: float) -> float:\n        dy_m = (float(lat_val) - float(center_lat)) * 111000.0\n        dx_m = (float(lon_val) - float(center_lon)) * 111000.0 * math.cos(math.radians(float(lat_val)))\n        ang_deg = math.degrees(math.atan2(dy_m, dx_m))\n        # Normalize to [0,360)\n        if ang_deg < 0:\n            ang_deg += 360.0\n        return ang_deg\n\n    # Helper: minimal absolute angular difference (degrees) accounting for wrap-around\n    def ang_diff_deg(a: float, b: float) -> float:\n        d = abs(((a - b + 180.0) % 360.0) - 180.0)\n        return d\n\n    # Evaluate angle rule per group only for those with no near points\n    for (vid, date, sid), idx in out.groupby(grp_keys).groups.items():\n        # Check group near status using label-based indexing\n        any_near_group = bool(any_near.loc[idx].any()) if len(idx) > 0 else False\n        if any_near_group:\n            continue  # already kept\n\n        sub = out.loc[idx]\n        if sub.empty:\n            continue\n        # Order chronologically\n        if 'collectiontime' in sub.columns:\n            sub_ord = sub.sort_values('collectiontime')\n        else:\n            sub_ord = sub\n        # Get start and end\n        start_row = sub_ord.iloc[0]\n        end_row = sub_ord.iloc[-1]\n        try:\n            a0 = compute_angle_deg(float(start_row['latitude']), float(start_row['longitude']))\n            a1 = compute_angle_deg(float(end_row['latitude']), float(end_row['longitude']))\n            delta = ang_diff_deg(a1, a0)\n            if delta > float(ANGULAR_CHANGE_DEG_THRESHOLD):\n                # Keep entire group by angle rule\n                keep_mask.loc[idx] = True\n        except Exception:\n            # If angle computation fails, do not change keep_mask (remain excluded)\n            pass\n\n    kept = out[keep_mask].copy()\n    excluded = out[~keep_mask].copy()\n    excluded_rows = int(len(excluded))\n    excluded_segments = 0\n    if excluded_rows > 0:\n        excluded['excluded_reason'] = 'outside_200m_all_points'\n        # Count unique segments excluded\n        excluded_segments = excluded.drop_duplicates(subset=grp_keys).shape[0]\n\n    stats = {\"excluded_segments\": excluded_segments, \"excluded_rows\": excluded_rows}\n    return kept, excluded, stats\n\n\n\n\ndef apply_manual_overrides_inline(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Apply hardcoded manual segmentation after automatic logic.\n    MANUAL_OVERRIDES keys: (road_id, vehicle_id, date)\n    Value supports either:\n      - {'segments': [(start1, end1), (start2, end2), ...]} with 1-based inclusive indices; end=None means to the last point.\n      - {'cuts': [k1, k2, ...]} with 1-based positions to split AFTER (equivalent to segments [(1,k1), (k1+1,k2), (k2+1,None)]).\n\n    If provided segments/cuts do NOT cover all points within the group, the uncovered\n    points are treated as \"not needed\" and will be removed from the output. Only the\n    specified ranges are kept and re-labeled with seg_id starting from 0 in listed order.\n    \"\"\"\n    if not MANUAL_OVERRIDES:\n        return df\n\n    out = df.copy()\n    # Normalize key column types to ensure mask matches\n    if 'road_id' in out.columns:\n        out['road_id'] = out['road_id'].astype(str)\n    if 'vehicle_id' in out.columns:\n        out['vehicle_id'] = out['vehicle_id'].astype('int64')\n    if 'date' in out.columns:\n        out['date'] = out['date'].astype(str)\n    # Ensure required columns\n    required_cols = ['road_id', 'vehicle_id', 'date', 'collectiontime', 'seg_id']\n    for c in required_cols:\n        if c not in out.columns:\n            raise ValueError(f\"Dataframe missing required column: {c}\")\n\n    # Process each override\n    for (road_id, vehicle_id, date), spec in MANUAL_OVERRIDES.items():\n        mask = (out['road_id'] == str(road_id)) & (out['vehicle_id'] == int(vehicle_id)) & (out['date'] == str(date))\n        idx = out[mask].index\n        if len(idx) == 0:\n            continue\n        # Order rows chronologically within the group\n        sub = out.loc[idx].sort_values('collectiontime')\n        ordered_idx = sub.index.to_list()\n        n = len(ordered_idx)\n        if n == 0:\n            continue\n\n        # Build segments from spec\n        segments: list[tuple[int, int]] = []  # 0-based inclusive ranges over ordered positions\n        if 'segments' in spec and isinstance(spec['segments'], (list, tuple)):\n            for rng in spec['segments']:\n                if not isinstance(rng, (list, tuple)) or len(rng) != 2:\n                    continue\n                s1, e1 = rng[0], rng[1]\n                if not isinstance(s1, int):\n                    continue\n                start0 = max(0, s1 - 1)\n                end0 = n - 1 if (e1 is None) else max(0, int(e1) - 1)\n                if start0 > end0 or start0 >= n:\n                    continue\n                end0 = min(end0, n - 1)\n                segments.append((start0, end0))\n        elif 'cuts' in spec and isinstance(spec['cuts'], (list, tuple)):\n            cuts = sorted(int(k) for k in spec['cuts'] if isinstance(k, (int, np.integer)))\n            prev = 0\n            for cpos in cuts:\n                end0 = min(max(0, cpos - 1), n - 1)\n                if prev <= end0:\n                    segments.append((prev, end0))\n                prev = end0 + 1\n            if prev <= n - 1:\n                segments.append((prev, n - 1))\n        else:\n            # If spec malformed, skip\n            continue\n\n        if not segments:\n            continue\n\n        # Build replacement rows allowing overlapping positions to be duplicated across segments\n        replacement_rows: list[pd.Series] = []\n        cur_seg = 0\n        for (a, b) in segments:\n            for pos in range(a, b + 1):\n                if 0 <= pos < n:\n                    src_idx = ordered_idx[pos]\n                    row = out.loc[src_idx].copy()\n                    row['seg_id'] = cur_seg\n                    replacement_rows.append(row)\n            cur_seg += 1\n\n        # Replace the group's rows with the reconstructed rows (drop uncovered points and allow duplicates)\n        out = out.drop(index=ordered_idx)\n        if replacement_rows:\n            out = pd.concat([out, pd.DataFrame(replacement_rows)], ignore_index=True)\n\n    return out\n\ndef apply_manual_exclusions_inline(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Remove rows for segments listed in MANUAL_EXCLUSIONS.\n    Keys: (road_id, vehicle_id, date, seg_id).\n    Occurs after automatic splitting and manual overrides, before radius exclusion.\n    \"\"\"\n    if not MANUAL_EXCLUSIONS:\n        return df\n    out = df.copy()\n    required_cols = ['road_id', 'vehicle_id', 'date', 'seg_id']\n    for c in required_cols:\n        if c not in out.columns:\n            raise ValueError(f\"Dataframe missing required column for manual exclusions: {c}\")\n    out['road_id'] = out['road_id'].astype(str)\n    out['vehicle_id'] = out['vehicle_id'].astype('int64')\n    out['date'] = out['date'].astype(str)\n    out['seg_id'] = out['seg_id'].astype('int64')\n\n    drop_idx_all: list[int] = []\n    for (road_id, vehicle_id, date, seg_id) in MANUAL_EXCLUSIONS:\n        base_mask = (\n            (out['road_id'] == str(road_id)) &\n            (out['vehicle_id'] == int(vehicle_id)) &\n            (out['date'] == str(date))\n        )\n        if int(seg_id) == -1:\n            mask = base_mask  # remove all segments for this (road_id, vehicle_id, date)\n        else:\n            mask = base_mask & (out['seg_id'] == int(seg_id))\n        drop_idx_all.extend(out[mask].index.tolist())\n    if drop_idx_all:\n        out = out.drop(index=drop_idx_all)\n    return out\ndef adaptive_split_segment_indices(\n    df: pd.DataFrame,\n    center_lat: float,\n    center_lon: float,\n    max_gap_seconds: float = 180.0,\n    enable_center_splitting: bool = True,\n    near_radius_m: float = NEAR_RADIUS_M,\n    far_radius_m: float = FAR_RADIUS_M,\n) -> tuple[pd.Series, int]:\n    \"\"\"\n    Compute seg_id per (vehicle_id, date) group using adaptive time-gap splitting.\n    - Start seg_id=0; for each point i, if time gap to previous point > 2x median of previous gaps\n      within current seg, or > max_gap_seconds, then start a new seg (seg_id += 1) at i.\n    - Requires df sorted by collectiontime within each group.\n    Returns (seg_id Series, extra_center_splits) where extra_center_splits counts splits caused by center rule.\n    \"\"\"\n    # We'll collect confirmed split indices first, then build seg_id at the end\n    confirmed_split_local_indices: list[int] = []\n\n    # Initialize time-gap baseline history\n    prev_diffs: list[float] = []\n\n    times = df['collectiontime'].to_numpy()  # expected in ms\n\n    # Precompute distance to center for hysteresis-based splitting\n    lats = df['latitude'].to_numpy()\n    lons = df['longitude'].to_numpy()\n    # Use per-point local scale for longitude\n    avg_lats_rad = np.radians(lats)\n    dy_m = (lats - center_lat) * 111000.0\n    dx_m = (lons - center_lon) * 111000.0 * np.cos(avg_lats_rad)\n    dist_to_center = np.sqrt(dx_m * dx_m + dy_m * dy_m)\n\n    # Helper: classify near/far using hysteresis windows (for readability)\n\n    # Center state machine with hysteresis\n    def classify_near_far(distance_m: float, prev_state: str | None) -> str:\n        if prev_state == 'near':\n            return 'far' if distance_m >= far_radius_m else 'near'\n        if prev_state == 'far':\n            return 'near' if distance_m <= near_radius_m else 'far'\n        # unknown -> decide based on hysteresis window\n        if distance_m <= near_radius_m:\n            return 'near'\n        if distance_m >= far_radius_m:\n            return 'far'\n        return 'far'\n\n    # New pre-splitting state\n    pre_candidate_idx: int | None = None  # first re-approach index (tentative split start)\n    # Track radial trend: 'away' or 'approach'\n    prev_trend: str | None = None\n\n    # Count of splits confirmed by center pre-splitting\n    extra_center_splits = 0\n\n    n = len(df)\n    for i in range(1, n):\n        cur_diff = (times[i] - times[i - 1]) / 1000.0  # seconds\n\n        # 1) Time-gap splitting (immediate)\n        time_gap_split = False\n        if len(prev_diffs) >= 3:\n            baseline = float(np.median(prev_diffs))\n            if baseline > 0 and float(cur_diff) > 2.0 * baseline:\n                time_gap_split = True\n        if float(cur_diff) > float(max_gap_seconds):\n            time_gap_split = True\n\n        if time_gap_split:\n            confirmed_split_local_indices.append(i)\n            prev_diffs = []\n            # Reset pre-splitting state across time-based boundary\n            pre_candidate_idx = None\n            prev_trend = None\n\n        # 2) Center pre-splitting (tentative confirmation model)\n        if enable_center_splitting:\n            r_prev = float(dist_to_center[i - 1])\n            r_cur = float(dist_to_center[i])\n            dr = r_cur - r_prev\n            cur_trend: str | None = None\n            if dr > DR_NOISE_EPS_M:\n                cur_trend = 'away'\n            elif dr < -DR_NOISE_EPS_M:\n                cur_trend = 'approach'\n\n            # Start a tentative split when we are far and switch from away -> approach\n            if pre_candidate_idx is None:\n                if cur_trend == 'approach' and prev_trend == 'away' and r_cur >= float(far_radius_m) and r_prev >= float(far_radius_m):\n                    pre_candidate_idx = i  # first point re-approaching the center while far\n            else:\n                # If we reach near zone, confirm the split at the candidate index\n                if r_cur <= float(near_radius_m):\n                    confirmed_split_local_indices.append(pre_candidate_idx)\n                    extra_center_splits += 1\n                    pre_candidate_idx = None\n                    # After confirmation, reset trend to avoid immediate re-trigger\n                    prev_trend = None\n                else:\n                    # If another away->approach occurs while still far, move candidate to the new index (invalidate previous)\n                    if cur_trend == 'approach' and prev_trend == 'away' and r_cur >= float(far_radius_m) and r_prev >= float(far_radius_m):\n                        pre_candidate_idx = i\n\n            # Update previous trend when determinable\n            if cur_trend is not None:\n                prev_trend = cur_trend\n\n        prev_diffs.append(float(cur_diff))\n\n    # Build seg_id series from confirmed split indices\n    confirmed_split_local_indices = sorted(set(confirmed_split_local_indices))\n    seg_ids_local = np.zeros(n, dtype=np.int64)\n    current_seg = 0\n    cursor = 0\n    for split_idx in confirmed_split_local_indices:\n        # rows [cursor, split_idx) belong to current_seg\n        # rows [split_idx, ...) will have new segment\n        if split_idx > cursor:\n            seg_ids_local[split_idx:] += 1\n            current_seg += 1\n            cursor = split_idx\n\n    # Map back to original df indices\n    seg_ids = pd.Series(seg_ids_local, index=df.index, dtype='int64')\n\n    return seg_ids, extra_center_splits\n\n\ndef process_file(\n    input_path: str,\n    output_path: str,\n    center_lat: float,\n    center_lon: float,\n    max_gap_seconds: float = 180.0,\n) -> None:\n    print(f\"Reading {input_path} ...\")\n    df = pd.read_csv(input_path)\n\n    # Validate required columns\n    required_cols = ['vehicle_id', 'collectiontime', 'date']\n    for col in required_cols:\n        if col not in df.columns:\n            raise ValueError(f\"Missing required column: {col}\")\n\n    # Sort by vehicle_id, date, collectiontime to ensure correct ordering\n    df = df.sort_values(['vehicle_id', 'date', 'collectiontime']).reset_index(drop=True)\n\n    # Compute seg_id per (vehicle_id, date) and collect center split metrics\n    seg_ids_all = []\n    affected_trajectories = 0\n    center_splits_total = 0\n    for (vehicle_id, date), group_idx in df.groupby(['vehicle_id', 'date']).groups.items():\n        group_df = df.loc[group_idx]\n        seg_ids_group, extra_center_splits = adaptive_split_segment_indices(\n            group_df,\n            max_gap_seconds=max_gap_seconds,\n            enable_center_splitting=True,\n            near_radius_m=NEAR_RADIUS_M,\n            far_radius_m=FAR_RADIUS_M,\n            center_lat=center_lat,\n            center_lon=center_lon,\n        )\n        seg_ids_all.append(seg_ids_group)\n        if extra_center_splits > 0:\n            affected_trajectories += 1\n            center_splits_total += extra_center_splits\n\n    seg_ids_concat = pd.concat(seg_ids_all).sort_index()\n\n    # Insert seg_id after vehicle_id column\n    cols = list(df.columns)\n    try:\n        vid_pos = cols.index('vehicle_id')\n    except ValueError:\n        vid_pos = 0\n    df.insert(vid_pos + 1, 'seg_id', seg_ids_concat.astype('int64').to_numpy())\n\n    # Apply inline hardcoded overrides\n    df = apply_manual_overrides_inline(df)\n\n    # Apply manual exclusions inline after splitting/overrides\n    df = apply_manual_exclusions_inline(df)\n\n    # Exclude segments whose all points are outside the center radius\n    kept_df, excluded_df, ex_stats = exclude_segments_outside_radius(\n        df, center_lat=center_lat, center_lon=center_lon, radius_m=EXCLUDE_OUTSIDE_RADIUS_M\n    )\n\n    # Write kept (split) file\n    print(f\"Writing {output_path} ...\")\n    # Ensure output directory exists\n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n    kept_df.to_csv(output_path, index=False)\n    print(f\"Wrote {len(kept_df)} rows to {output_path}\")\n\n    # Write excluded file (parallel to split file name)\n    excluded_path = output_path.replace('/home/mw/project/_split.csv', '/home/mw/project/_excluded.csv')\n    if len(excluded_df) > 0:\n        print(f\"Writing excluded rows to {excluded_path} ...\")\n        excluded_df.to_csv(excluded_path, index=False)\n        print(\n            f\"Excluded segments={ex_stats['excluded_segments']}, rows={ex_stats['excluded_rows']} (radius={EXCLUDE_OUTSIDE_RADIUS_M}m)\"\n        )\n    else:\n        # If no excluded rows, and an older excluded file exists, we do not touch it\n        print(\"No segments excluded by radius rule.\")\n    # Report center-based splitting metrics\n    print(\n        f\"Center-based splitting: affected trajectories = {affected_trajectories}, \"\n        f\"extra splits due to center = {center_splits_total}\"\n    )\n\n\ndef main():\n    data_dir = os.path.join(BASE_DIR, 'data')\n    os.makedirs(data_dir, exist_ok=True)\n    # Per-road intersection centers (lat, lon)\n    A0003_CENTER = CENTERS['A0003']\n    A0008_CENTER = CENTERS['A0008']\n\n    process_file(\n        f'/home/mw/project/A0003.csv',\n        f'/home/mw/project/A0003_split.csv',\n        center_lat=A0003_CENTER[0],\n        center_lon=A0003_CENTER[1],\n    )\n    process_file(\n        f'/home/mw/project/A0008.csv',\n        f'/home/mw/project/A0008_split.csv',\n        center_lat=A0008_CENTER[0],\n        center_lon=A0008_CENTER[1],\n    )\n\n\n## Module is imported by main.py; no standalone execution\n\n\n"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}