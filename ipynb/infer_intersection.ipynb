{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Auto-generated from `infer_intersection.py`\n\nGenerated on 2025-11-09T22:01:34.\n\nThis notebook was created programmatically to mirror the original Python script.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nimport sys\nproject_root = str(Path.cwd().parent.resolve())\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport json\nimport math\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Tuple\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nfrom config import BASE_DIR, CENTERS\nrng = np.random.default_rng(42)\n\n# ---------- Configuration ----------\n# Input CSVs to process (produced by split_trajectories)\nINPUT_FILES = [\n    '/home/mw/project/A0003_split.csv',\n    '/home/mw/project/A0008_split.csv',\n]\nK = 4                        # Number of approach direction clusters\nV_STOP = 0.5                 # Stationary speed threshold (m/s)\nV_GO = 1.5                   # Start-moving speed threshold (m/s)\nLOOKAHEAD_S = 5.0            # Lookahead window for detecting start (s)\nRANSAC_THRESH = 1.5          # RANSAC inlier distance threshold (m)\nLATERAL_BAND = 2.0           # Lateral band width for stop-line estimation (m)\nSTOP_QUANTILE = 0.15         # Quantile for conservative stop-line estimate\nWRITE_GEOJSON = False        # If True, also write a GeoJSON per CSV\n\nDATA_DIR = os.path.join(BASE_DIR, 'data')\nDIRECTION_FILE = '/home/mw/project/direction.csv'\nAXIS_POLY_BIN_M = 50.0       # Bin size (meters) to build piecewise axis/lane polyline\nAXIS_POLY_MIN_POINTS = 5     # Min points per bin to keep a vertex\n\n# Direction-grouped labels per inbound side (W,E,S,N)\nLANE_GROUPS = {\n    'W': {\n        'straight': ['A1-1', 'A1-2'],\n        'left': ['B2-1', 'A3-2'],\n        'right': ['A2-2', 'B3-2'],\n        'stop_labels': ['A1-1', 'B2-1', 'B3-2']\n    },\n    'E': {\n        'straight': ['A1-1', 'A1-2'],\n        'left': ['B2-2', 'A3-1'],\n        'right': ['A2-1', 'B3-1'],\n        'stop_labels': ['A1-2', 'B2-2', 'B3-1']\n    },\n    'S': {\n        'straight': ['B1-1', 'B1-2'],\n        'left': ['A2-2', 'B3-2'],\n        'right': ['B2-2', 'A3-1'],\n        'stop_labels': ['B1-1', 'A2-2', 'A3-1']\n    },\n    'N': {\n        'straight': ['B1-1', 'B1-2'],\n        'left': ['A2-1', 'B3-1'],\n        'right': ['B2-1', 'A3-2'],\n        'stop_labels': ['B1-2', 'A2-1', 'A3-2']\n    }\n}\n\n# ---------- Utilities ----------\n\ndef lonlat_to_xy(lon, lat, lon0, lat0):\n    \"\"\"\n    Approximate local tangent-plane projection (meters) centered at (lon0, lat0).\n    \"\"\"\n    # Earth radius (approximate)\n    R = 6378137.0\n    lat0_rad = np.deg2rad(lat0)\n    mx = (np.deg2rad(lon - lon0) * R * np.cos(lat0_rad))\n    my = (np.deg2rad(lat - lat0) * R)\n    return mx, my\n\ndef xy_to_lonlat(x, y, lon0, lat0):\n    R = 6378137.0\n    lat0_rad = np.deg2rad(lat0)\n    lon = lon0 + np.rad2deg(x / (R * np.cos(lat0_rad)))\n    lat = lat0 + np.rad2deg(y / R)\n    return lon, lat\n\ndef angle_wrap_deg(a):\n    \"\"\"Wrap angle into [-180, 180).\"\"\"\n    a = (a + 180.0) % 360.0 - 180.0\n    return a\n\ndef heading_from_xy(dx, dy):\n    \"\"\"Heading with east=0°, counter-clockwise positive: atan2(dy, dx).\"\"\"\n    return (np.rad2deg(np.arctan2(dy, dx)) + 360.0) % 360.0\n\ndef robust_quantile(values, q, max_iters=2):\n    \"\"\"Quantile after IQR-based outlier clipping (robust to extremes).\"\"\"\n    v = np.asarray(values).copy()\n    if len(v) == 0:\n        return np.nan\n    for _ in range(max_iters):\n        q1, q3 = np.quantile(v, [0.25, 0.75])\n        iqr = q3 - q1\n        lo, hi = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n        v = v[(v >= lo) & (v <= hi)]\n        if len(v) == 0:\n            break\n    if len(v) == 0:\n        return np.nan\n    return float(np.quantile(v, q))\n\n# ---------- Line representation and fitting ----------\n\n@dataclass\nclass Line:\n    n: np.ndarray   # 法向单位向量 shape (2,)\n    rho: float      # 截距, n^T x = rho\n    t: np.ndarray   # 切向单位向量 (与 n 垂直)\n    angle_deg: float  # 切向角度（以东为0逆时针）\n\ndef pca_tls_direction(points: np.ndarray, weights: np.ndarray=None) -> np.ndarray:\n    \"\"\"\n    TLS principal direction (tangent) from 2D points (N,2).\n    Returns a unit vector t.\n    \"\"\"\n    if weights is None:\n        w = np.ones(len(points))\n    else:\n        w = weights\n    w = w / (w.sum() + 1e-12)\n    mu = (points * w[:, None]).sum(axis=0)\n    X = points - mu\n    C = (X * w[:, None]).T @ X\n    # 主特征向量对应最大特征值\n    vals, vecs = np.linalg.eigh(C)\n    t = vecs[:, np.argmax(vals)]\n    t = t / (np.linalg.norm(t) + 1e-12)\n    return t\n\ndef line_from_points_tls(points: np.ndarray, weights: np.ndarray=None) -> Line:\n    \"\"\"\n    TLS-fit line in normal form: n^T x = rho.\n    \"\"\"\n    t = pca_tls_direction(points, weights)\n    n = np.array([-t[1], t[0]])\n    # Use weighted median of normal projections for rho (robust)\n    if weights is None:\n        weights = np.ones(len(points))\n    proj = points @ n\n    rho = robust_quantile(np.repeat(proj, repeats=np.maximum(1, weights.astype(int))), 0.5)\n    if np.isnan(rho):\n        rho = float(np.median(proj))\n    angle_deg = (np.rad2deg(np.arctan2(t[1], t[0])) + 360.0) % 360.0\n    return Line(n=n, rho=rho, t=t, angle_deg=angle_deg)\n\ndef ransac_line(points: np.ndarray, thresh=1.5, iters=300, min_inliers=6) -> Tuple[Line, np.ndarray]:\n    \"\"\"\n    Fit a line with RANSAC, then refine with TLS.\n    Returns a Line and a boolean inlier mask.\n    \"\"\"\n    N = len(points)\n    if N < 2:\n        raise ValueError(\"Not enough points for RANSAC\")\n    best_inliers = None\n    best_count = -1\n    idx = np.arange(N)\n    for _ in range(iters):\n        i, j = rng.choice(idx, size=2, replace=False)\n        p1, p2 = points[i], points[j]\n        v = p2 - p1\n        if np.linalg.norm(v) < 1e-3:\n            continue\n        t = v / np.linalg.norm(v)\n        n = np.array([-t[1], t[0]])\n        rho = float(n @ p1)\n        d = np.abs(points @ n - rho)\n        inliers = d <= thresh\n        count = inliers.sum()\n        if count > best_count:\n            best_count = count\n            best_inliers = inliers\n    if best_inliers is None or best_count < max(min_inliers, 2):\n        # Degenerate case: use TLS on all points\n        line = line_from_points_tls(points)\n        inliers = np.ones(N, dtype=bool)\n        return line, inliers\n    # TLS refinement\n    line = line_from_points_tls(points[best_inliers])\n    return line, best_inliers\n\ndef lsq_intersection_center(lines: List[Line], weights: List[float]=None) -> np.ndarray:\n    \"\"\"\n    Least-squares intersection point of lines n_j^T x = rho_j.\n    \"\"\"\n    if weights is None:\n        weights = [1.0] * len(lines)\n    A = np.zeros((2,2))\n    b = np.zeros(2)\n    for L, w in zip(lines, weights):\n        n = L.n.reshape(2,1)\n        A += w * (n @ n.T)\n        b += w * (L.rho * L.n)\n    c = np.linalg.solve(A, b)\n    return c  # shape (2,)\n\n# ---------- Main pipeline ----------\n\ndef compute_heading_per_track(df: pd.DataFrame, lon0: float, lat0: float) -> pd.DataFrame:\n    \"\"\"\n    For each vehicle_id, sort by time and compute heading between consecutive points (degrees).\n    If 'collectiontime' (milliseconds) exists, prefer it; otherwise parse from 'date' + 'time_stamp'.\n    \"\"\"\n    if 'collectiontime' in df.columns and df['collectiontime'].notna().any():\n        df['_t'] = pd.to_numeric(df['collectiontime'], errors='coerce')\n    else:\n        # Attempt to parse from 'date' and 'time_stamp'\n        df['_t'] = pd.to_datetime(df['date'].astype(str) + ' ' + df['time_stamp'].astype(str), errors='coerce').astype('int64')//10**6\n    # Sort by vehicle and time\n    df = df.sort_values(['vehicle_id','_t']).copy()\n    # Compute heading\n    x, y = lonlat_to_xy(df['longitude'].values, df['latitude'].values, lon0, lat0)\n    df['_x'] = x\n    df['_y'] = y\n    df['_x_prev'] = df.groupby('vehicle_id')['_x'].shift(1)\n    df['_y_prev'] = df.groupby('vehicle_id')['_y'].shift(1)\n    dx = df['_x'] - df['_x_prev']\n    dy = df['_y'] - df['_y_prev']\n    hd = heading_from_xy(dx.fillna(0).values, dy.fillna(0).values)\n    df['heading_est'] = hd\n    return df\n\ndef extract_last_stop_points(df: pd.DataFrame,\n                             v_stop=0.5, v_go=1.5, lookahead_s=5.0) -> pd.DataFrame:\n    \"\"\"\n    Extract the last stationary point before starting:\n    speed < v_stop and, within lookahead_s, a future speed > v_go.\n    \"\"\"\n    # If speed is likely in km/h, attempt conversion based on distribution\n    sp = pd.to_numeric(df['speed'], errors='coerce').fillna(0).values\n    # Heuristic: if 95th percentile > 80, assume km/h and convert to m/s\n    if np.nanpercentile(sp, 95) > 80:\n        sp = sp / 3.6\n    df['_speed_ms'] = sp\n\n    # Use millisecond timestamps\n    tms = pd.to_numeric(df['_t'], errors='coerce').fillna(0).values\n    df['_t_ms'] = tms\n\n    # Scan each vehicle independently\n    out_rows = []\n    for vid, g in df.groupby('vehicle_id', sort=False):\n        g = g.sort_values('_t_ms')\n        arr_t = g['_t_ms'].values\n        arr_v = g['_speed_ms'].values\n        arr_x = g['_x'].values\n        arr_y = g['_y'].values\n        arr_hd = g['heading_est'].values\n\n        N = len(g)\n        i = 0\n        while i < N:\n            if arr_v[i] < v_stop:\n                # Look ahead within lookahead_s to see if speed exceeds v_go\n                j = i\n                moved = False\n                while j < N and (arr_t[j] - arr_t[i]) <= lookahead_s * 1000.0:\n                    if arr_v[j] > v_go:\n                        moved = True\n                        break\n                    j += 1\n                if moved:\n                    # Last stationary point before start: within [i, j),\n                    # choose the slowest and nearest to j\n                    k = np.argmax((arr_v[i:j] < v_stop).astype(int) * np.arange(j - i)) + i\n                    out_rows.append({\n                        'vehicle_id': vid,\n                        '_t_ms': arr_t[k],\n                        '_x': arr_x[k], '_y': arr_y[k],\n                        'heading': arr_hd[k]\n                    })\n                    # Jump to after j and continue\n                    i = j + 1\n                    continue\n            i += 1\n    return pd.DataFrame(out_rows)\n\ndef cluster_directions(points_df: pd.DataFrame, K=4) -> np.ndarray:\n    \"\"\"\n    Cluster headings into K approach directions.\n    If headings are missing, you could instead use polar angles to a provisional center.\n    \"\"\"\n    hd = points_df['heading'].values % 360.0\n    # Embed onto the unit circle\n    X = np.c_[np.cos(np.deg2rad(hd)), np.sin(np.deg2rad(hd))]\n    km = KMeans(n_clusters=K, n_init=10, random_state=42)\n    labels = km.fit_predict(X)\n    return labels  # 0..K-1\n\ndef load_direction_df(path: str = DIRECTION_FILE) -> pd.DataFrame:\n    try:\n        return pd.read_csv(path)\n    except Exception as exc:\n        print(f\"[Error] Failed to read direction file '{path}': {exc}\")\n        return pd.DataFrame()\n\ndef _triplet_key(vid, date, seg) -> Tuple[int, str, int]:\n    \"\"\"Normalize (vehicle_id, date, seg_id) to int, str, int tuple.\"\"\"\n    def _to_int(x):\n        try:\n            return int(x)\n        except Exception:\n            try:\n                return int(float(x))\n            except Exception:\n                return -1\n    return (_to_int(vid), str(date), _to_int(seg))\n\ndef build_triplet_set_for_labels(dir_df: pd.DataFrame, road_id: str, labels: List[str]) -> set:\n    \"\"\"Return set of (vehicle_id, date, seg_id) triplets for given road_id and label list.\"\"\"\n    if dir_df is None or len(dir_df) == 0:\n        return set()\n    sub = dir_df[(dir_df['road_id'] == road_id) & (dir_df['direction'].astype(str).isin(labels))]\n    out = set()\n    for _, r in sub.iterrows():\n        out.add(_triplet_key(r['vehicle_id'], r['date'], r['seg_id']))\n    return out\n\ndef filter_df_by_triplets(df: pd.DataFrame, triplets: set) -> pd.DataFrame:\n    if not triplets:\n        return df.iloc[0:0].copy()\n    def _keep(row):\n        return _triplet_key(row['vehicle_id'], row['date'], row['seg_id']) in triplets\n    return df[df.apply(_keep, axis=1)].copy()\n\ndef collect_points_for_labels(df_raw: pd.DataFrame, dir_df: pd.DataFrame, road_id: str, labels: List[str]) -> np.ndarray:\n    trip = build_triplet_set_for_labels(dir_df, road_id, labels)\n    dff = filter_df_by_triplets(df_raw, trip)\n    return dff[['_x', '_y']].to_numpy()\n\ndef collect_stop_points_for_labels(df_raw: pd.DataFrame, dir_df: pd.DataFrame, road_id: str, labels: List[str]) -> pd.DataFrame:\n    trip = build_triplet_set_for_labels(dir_df, road_id, labels)\n    dff = filter_df_by_triplets(df_raw, trip)\n    return extract_last_stop_points(dff, v_stop=V_STOP, v_go=V_GO, lookahead_s=LOOKAHEAD_S)\n\ndef fit_two_lanes_from_points(P: np.ndarray, base_line: Line) -> List[Line]:\n    \"\"\"Split by lateral offset into two clusters (K=2) and fit TLS line per cluster.\n    Returns list of 1 or 2 Line objects depending on viability.\n    \"\"\"\n    if P is None or len(P) < 2:\n        return []\n    # Lateral offsets to base line\n    d = (P @ base_line.n - base_line.rho).reshape(-1, 1)\n    try:\n        km = KMeans(n_clusters=2, n_init=10, random_state=42)\n        lab = km.fit_predict(d)\n    except Exception:\n        # Degenerate: return a single lane from all points\n        return [line_from_points_tls(P)]\n    lanes: List[Line] = []\n    for k in (0, 1):\n        Q = P[lab == k]\n        if len(Q) >= 2:\n            lanes.append(line_from_points_tls(Q))\n    if len(lanes) == 0:\n        lanes = [line_from_points_tls(P)]\n    return lanes\n\ndef polyline_along_s(P: np.ndarray, center_xy: np.ndarray, t_dir: np.ndarray,\n                     lon0: float, lat0: float,\n                     bin_m: float = AXIS_POLY_BIN_M, min_pts: int = AXIS_POLY_MIN_POINTS) -> Optional[dict]:\n    \"\"\"Build a piecewise polyline by binning points along s = (p-center)·t_dir.\"\"\"\n    if P is None or len(P) == 0:\n        return None\n    s_vals = (P - center_xy.reshape(1, 2)) @ t_dir\n    if not (np.isfinite(s_vals).all()):\n        return None\n    s_min = float(np.min(s_vals))\n    s_max = float(np.max(s_vals))\n    if not (np.isfinite(s_min) and np.isfinite(s_max)) or s_max <= s_min + 1.0:\n        return None\n    num_bins = max(1, int(np.ceil((s_max - s_min) / bin_m)))\n    xs = np.linspace(s_min, s_max, num_bins + 1)\n    coords = []\n    for i in range(num_bins):\n        a = xs[i]\n        b = xs[i + 1]\n        mask = (s_vals >= a) & (s_vals <= b)\n        if np.count_nonzero(mask) >= 1:\n            p_mean = P[mask].mean(axis=0)\n            lon_i, lat_i = xy_to_lonlat(p_mean[0], p_mean[1], lon0, lat0)\n            coords.append([float(lon_i), float(lat_i)])\n    if len(coords) >= 2:\n        return {'coordinates': coords}\n    return None\n\n# Curves to build from specified label pairs\nCURVE_PAIRS = [\n    ((\"A2-1\", \"B3-1\"), \"E_right\"),\n    ((\"B3-2\", \"A2-2\"), \"W_right\"),\n    ((\"A3-2\", \"B2-1\"), \"W_left\"),\n    ((\"B2-2\", \"A3-1\"), \"E_left\"),\n]\n\ndef build_curve_poly(df_raw: pd.DataFrame, dir_df: pd.DataFrame, road_id: str,\n                     label_pair: Tuple[str, str], center_xy: np.ndarray,\n                     lon0: float, lat0: float) -> Optional[dict]:\n    P = collect_points_for_labels(df_raw, dir_df, road_id, list(label_pair))\n    if P is None or len(P) < 2:\n        return None\n    t_dir = pca_tls_direction(P)\n    return polyline_along_s(P, center_xy, t_dir, lon0, lat0)\n\ndef fit_axis_per_cluster(points_df: pd.DataFrame, labels: np.ndarray,\n                         ransac_thresh=1.5) -> Dict[int, Dict]:\n    \"\"\"\n    For each cluster, fit a line with RANSAC + TLS.\n    Returns: {label: {'line': Line, 'inliers_mask': mask, 'points': (N,2)}}.\n    \"\"\"\n    result = {}\n    for lab in np.unique(labels):\n        g = points_df[labels == lab]\n        P = g[['_x','_y']].values\n        if len(P) < 4:\n            continue\n        line, inliers = ransac_line(P, thresh=ransac_thresh, iters=400, min_inliers= max(6, len(P)//3))\n        result[int(lab)] = {'line': line, 'inliers_mask': inliers, 'points': P}\n    return result\n\ndef stopline_along_axis(points_df: pd.DataFrame, line: Line, center_xy: np.ndarray,\n                        lateral_band=2.0, use_quantile=0.15) -> float:\n    \"\"\"\n    Compute the stop-line longitudinal coordinate s_stop (meters) along the given axis.\n    \"\"\"\n    P = points_df[['_x','_y']].values\n    # Keep only points within a lateral band around the axis\n    lat_dev = np.abs(P @ line.n - line.rho)\n    keep = lat_dev <= lateral_band\n    if not np.any(keep):\n        return float('nan')\n    T = line.t\n    s = (P[keep] - center_xy.reshape(1,2)) @ T\n    if np.isnan(use_quantile):\n        s_stop = float(np.median(s))\n    else:\n        s_stop = robust_quantile(s, use_quantile)\n    return s_stop\n\ndef main():\n    for csv_path in INPUT_FILES:\n        base = os.path.basename(csv_path)\n        name_no_ext = base.rsplit('.', 1)[0]\n        road_id = name_no_ext.split('_')[0] if '_' in name_no_ext else name_no_ext\n        df = pd.read_csv(csv_path)\n        # Coarse origin for local projection; prefer configured centers, otherwise use medians\n        c_hint = CENTERS.get(road_id)\n        center_lat_hint = float(c_hint[0]) if c_hint is not None else None\n        center_lon_hint = float(c_hint[1]) if c_hint is not None else None\n        lat0 = center_lat_hint if center_lat_hint is not None else float(np.median(df['latitude']))\n        lon0 = center_lon_hint if center_lon_hint is not None else float(np.median(df['longitude']))\n\n        # 1) Compute headings and local coordinates\n        df = compute_heading_per_track(df, lon0, lat0)\n\n        # 2) Load direction labels for this road\n        dir_df_all = load_direction_df(DIRECTION_FILE)\n        if dir_df_all.empty:\n            raise RuntimeError(\"direction.csv not available for direction-based grouping\")\n        dir_df = dir_df_all[dir_df_all['road_id'] == road_id].copy()\n\n        # 3) Fit global EW and NS axes from combined straight labels to estimate center\n        # Updated: NS from A1, EW from B1\n        P_NS = collect_points_for_labels(df, dir_df, road_id, ['A1-1', 'A1-2'])\n        P_EW = collect_points_for_labels(df, dir_df, road_id, ['B1-1', 'B1-2'])\n        if len(P_NS) < 2 or len(P_EW) < 2:\n            # Fallback to configured center if insufficient to estimate center\n            center_lat = center_lat_hint if center_lat_hint is not None else float(np.median(df['latitude']))\n            center_lon = center_lon_hint if center_lon_hint is not None else float(np.median(df['longitude']))\n            cx, cy = lonlat_to_xy(np.array([center_lon]), np.array([center_lat]), lon0, lat0)\n            center_xy = np.array([float(cx[0]), float(cy[0])])\n            # Still compute EW/NS if possible (may be missing)\n            line_NS, inliers_NS = (line_from_points_tls(P_NS), np.ones(len(P_NS), dtype=bool)) if len(P_NS) >= 2 else (None, None)\n            line_EW, inliers_EW = (line_from_points_tls(P_EW), np.ones(len(P_EW), dtype=bool)) if len(P_EW) >= 2 else (None, None)\n        else:\n            line_NS, inliers_NS = ransac_line(P_NS, thresh=RANSAC_THRESH, iters=400, min_inliers=max(6, len(P_NS)//3))\n            line_EW, inliers_EW = ransac_line(P_EW, thresh=RANSAC_THRESH, iters=400, min_inliers=max(6, len(P_EW)//3))\n            center_xy = lsq_intersection_center([line_NS, line_EW], weights=[float(inliers_NS.sum()), float(inliers_EW.sum())])\n            center_lon, center_lat = xy_to_lonlat(center_xy[0], center_xy[1], lon0, lat0)\n\n        # 4) Per-side straight base axes and two-lane split\n        side_results = {}\n        # Determine side assignment by sign of s = (p-center)·t along axis orientation\n        # For EW, use t.x sign to map s>=0 to East if t.x>=0, else to West\n        # For NS, use t.y sign to map s>=0 to North if t.y>=0, else to South\n        # Build helper to clone a Line object\n        def _clone_line(L: Line) -> Line:\n            return Line(n=L.n.copy(), rho=float(L.rho), t=L.t.copy(), angle_deg=float(L.angle_deg))\n\n        # Precompute signs and s-values for combined point sets\n        if P_EW is not None and len(P_EW) >= 2 and line_EW is not None:\n            s_EW = (P_EW - center_xy.reshape(1, 2)) @ line_EW.t\n            signE = 1.0 if line_EW.t[0] >= 0.0 else -1.0\n        else:\n            s_EW = None\n            signE = 1.0\n        if P_NS is not None and len(P_NS) >= 2 and line_NS is not None:\n            s_NS = (P_NS - center_xy.reshape(1, 2)) @ line_NS.t\n            signN = 1.0 if line_NS.t[1] >= 0.0 else -1.0\n        else:\n            s_NS = None\n            signN = 1.0\n\n        for side in ['W', 'E']:\n            if line_EW is None or s_EW is None:\n                side_results[side] = {\n                    'base_axis': None,\n                    'inliers_mask': None,\n                    'points': np.zeros((0, 2)),\n                    'lanes': []\n                }\n                continue\n            if side == 'E':\n                mask = (signE * s_EW) >= 0.0\n            else:  # 'W'\n                mask = (signE * s_EW) < 0.0\n            P_side = P_EW[mask]\n            base_axis = _clone_line(line_EW)\n            lanes = fit_two_lanes_from_points(P_side, base_axis) if len(P_side) >= 2 else []\n            side_results[side] = {\n                'base_axis': base_axis,\n                'inliers_mask': np.ones(len(P_side), dtype=bool),\n                'points': P_side,\n                'lanes': lanes\n            }\n\n        for side in ['S', 'N']:\n            if line_NS is None or s_NS is None:\n                side_results[side] = {\n                    'base_axis': None,\n                    'inliers_mask': None,\n                    'points': np.zeros((0, 2)),\n                    'lanes': []\n                }\n                continue\n            if side == 'N':\n                mask = (signN * s_NS) >= 0.0\n            else:  # 'S'\n                mask = (signN * s_NS) < 0.0\n            P_side = P_NS[mask]\n            base_axis = _clone_line(line_NS)\n            lanes = fit_two_lanes_from_points(P_side, base_axis) if len(P_side) >= 2 else []\n            side_results[side] = {\n                'base_axis': base_axis,\n                'inliers_mask': np.ones(len(P_side), dtype=bool),\n                'points': P_side,\n                'lanes': lanes\n            }\n\n        # 5) Orient all axis tangents outward per side (if available)\n        for side, res in side_results.items():\n            if res['base_axis'] is None or len(res['points']) == 0:\n                continue\n            line = res['base_axis']\n            mean_vec = res['points'].mean(axis=0) - center_xy\n            if (mean_vec @ line.t) < 0:\n                line.t = -line.t\n                line.n = -line.n\n                line.rho = -line.rho\n                line.angle_deg = (line.angle_deg + 180.0) % 360.0\n            # Orient lanes similarly\n            for ln in res['lanes']:\n                if (mean_vec @ ln.t) < 0:\n                    ln.t = -ln.t\n                    ln.n = -ln.n\n                    ln.rho = -ln.rho\n                    ln.angle_deg = (ln.angle_deg + 180.0) % 360.0\n\n        # 6) Stopline per side (use union of stop labels)\n        stoplines = {}\n        for side in ['W', 'E', 'S', 'N']:\n            base_axis = side_results[side]['base_axis']\n            if base_axis is None:\n                stoplines[side] = {'s_stop_m_from_center': None, 'method': f'quantile_{STOP_QUANTILE}', 'labels': LANE_GROUPS[side]['stop_labels']}\n                continue\n            pts_stop = collect_stop_points_for_labels(df, dir_df, road_id, LANE_GROUPS[side]['stop_labels'])\n            s_stop = stopline_along_axis(pts_stop, base_axis, center_xy, lateral_band=LATERAL_BAND, use_quantile=STOP_QUANTILE)\n            stoplines[side] = {\n                's_stop_m_from_center': float(s_stop) if s_stop is not None and np.isfinite(s_stop) else None,\n                'method': f'quantile_{STOP_QUANTILE}' if not np.isnan(STOP_QUANTILE) else 'median',\n                'labels': LANE_GROUPS[side]['stop_labels']\n            }\n\n        # 7) (Removed) Side-based turn polylines; we only keep four specified curves below\n        turn_lanes = {s: {'left': None, 'right': None} for s in ['W', 'E', 'S', 'N']}\n\n        # Build specified curves forming the road network\n        curves = []\n        for (labels_pair, name) in CURVE_PAIRS:\n            poly = build_curve_poly(df, dir_df, road_id, labels_pair, center_xy, lon0, lat0)\n            curves.append({'name': name, 'labels': list(labels_pair), 'polyline': poly})\n\n        # 8) Compose output JSON\n        out = {\n            'center_point': {\n                'x_m': float(center_xy[0]),\n                'y_m': float(center_xy[1]),\n                'lon': center_lon,\n                'lat': center_lat\n            },\n            'lanes_straight': {},\n            'lanes_turn': {},\n            'stoplines': stoplines,\n            'approaches': []\n        }\n\n        # Road network summary: axes and curves\n        out['road_network'] = {\n            'axes': {\n                'NS': {\n                    'angle_deg': float(line_NS.angle_deg) if 'line_NS' in locals() and line_NS is not None else None,\n                    'n': [float(line_NS.n[0]), float(line_NS.n[1])] if 'line_NS' in locals() and line_NS is not None else None,\n                    't': [float(line_NS.t[0]), float(line_NS.t[1])] if 'line_NS' in locals() and line_NS is not None else None,\n                    'rho_m': float(line_NS.rho) if 'line_NS' in locals() and line_NS is not None else None,\n                },\n                'EW': {\n                    'angle_deg': float(line_EW.angle_deg) if 'line_EW' in locals() and line_EW is not None else None,\n                    'n': [float(line_EW.n[0]), float(line_EW.n[1])] if 'line_EW' in locals() and line_EW is not None else None,\n                    't': [float(line_EW.t[0]), float(line_EW.t[1])] if 'line_EW' in locals() and line_EW is not None else None,\n                    'rho_m': float(line_EW.rho) if 'line_EW' in locals() and line_EW is not None else None,\n                },\n            },\n            'curves': [c for c in curves if c['polyline'] is not None]\n        }\n\n        for side, res in side_results.items():\n            # Straight lanes (suppressed: only keep base axes in output)\n            lanes_serialized = []\n            base_axis = res['base_axis']\n            base_ser = None\n            if base_axis is not None:\n                base_ser = {\n                    'angle_deg': float(base_axis.angle_deg),\n                    'n': [float(base_axis.n[0]), float(base_axis.n[1])],\n                    't': [float(base_axis.t[0]), float(base_axis.t[1])],\n                    'rho_m': float(base_axis.rho)\n                }\n            out['lanes_straight'][side] = {\n                'base_axis': base_ser,\n                'lanes': lanes_serialized,\n                'samples': int(len(res['points'])),\n            }\n            # Turn lanes\n            out['lanes_turn'][side] = turn_lanes[side]\n\n        # Also export four base approaches for backward compatibility\n        for side, res in side_results.items():\n            base_axis = res['base_axis']\n            if base_axis is None:\n                continue\n            out['approaches'].append({\n                'cluster_label': side,\n                'label_hint': side,\n                'axis': {\n                    'angle_deg': float(base_axis.angle_deg),\n                    'n': [float(base_axis.n[0]), float(base_axis.n[1])],\n                    't': [float(base_axis.t[0]), float(base_axis.t[1])],\n                    'rho_m': float(base_axis.rho)\n                },\n                'stopline': stoplines[side],\n                'axis_polyline': None,\n                'samples': int(len(res['points'])),\n                'inliers': int(res['inliers_mask'].sum()) if res['inliers_mask'] is not None else int(len(res['points']))\n            })\n\n        # Determine intersection id from file name\n        inter_id = road_id\n\n        # Write results JSON under BASE_DIR/data named by intersection id\n        out_json_path = f\"/home/mw/project/{inter_id}_intersection.json\"\n        with open(out_json_path, 'w', encoding='utf-8') as f:\n            json.dump(out, f, ensure_ascii=False, indent=2)\n\n        # Optionally write GeoJSON named by intersection id\n        if WRITE_GEOJSON:\n            out_geojson_path = os.path.join(DATA_DIR, f\"{inter_id}_intersection.geojson\")\n            features = []\n            # Center point\n            features.append({\n                \"type\": \"Feature\",\n                \"properties\": {\"type\": \"center\"},\n                \"geometry\": {\"type\": \"Point\", \"coordinates\": [center_lon, center_lat]}\n            })\n            # Visualize axes (only two global axes) and stoplines\n            L_vis = 120.0\n            # Draw NS axis\n            if 'line_NS' in locals() and line_NS is not None:\n                t = line_NS.t\n                n = line_NS.n\n                rho = line_NS.rho\n                alpha = rho - n @ center_xy\n                p0 = center_xy + alpha * n\n                p1 = p0 - t * (L_vis/2)\n                p2 = p0 + t * (L_vis/2)\n                lon1, lat1 = xy_to_lonlat(p1[0], p1[1], lon0, lat0)\n                lon2, lat2 = xy_to_lonlat(p2[0], p2[1], lon0, lat0)\n                features.append({\n                    \"type\": \"Feature\",\n                    \"properties\": {\"type\": \"axis\", \"name\": \"NS\", \"angle_deg\": float(line_NS.angle_deg)},\n                    \"geometry\": {\"type\": \"LineString\", \"coordinates\": [[lon1, lat1], [lon2, lat2]]}\n                })\n            # Draw EW axis\n            if 'line_EW' in locals() and line_EW is not None:\n                t = line_EW.t\n                n = line_EW.n\n                rho = line_EW.rho\n                alpha = rho - n @ center_xy\n                p0 = center_xy + alpha * n\n                p1 = p0 - t * (L_vis/2)\n                p2 = p0 + t * (L_vis/2)\n                lon1, lat1 = xy_to_lonlat(p1[0], p1[1], lon0, lat0)\n                lon2, lat2 = xy_to_lonlat(p2[0], p2[1], lon0, lat0)\n                features.append({\n                    \"type\": \"Feature\",\n                    \"properties\": {\"type\": \"axis\", \"name\": \"EW\", \"angle_deg\": float(line_EW.angle_deg)},\n                    \"geometry\": {\"type\": \"LineString\", \"coordinates\": [[lon1, lat1], [lon2, lat2]]}\n                })\n            # Stoplines per side (unchanged)\n            for side, res in side_results.items():\n                base_axis = res['base_axis']\n                if base_axis is None:\n                    continue\n                t = base_axis.t\n                n = base_axis.n\n                s_stop = stoplines[side]['s_stop_m_from_center']\n                if s_stop is not None:\n                    p_stop_center = center_xy + t * s_stop\n                    Ls = 20.0\n                    q1 = p_stop_center - n * (Ls/2)\n                    q2 = p_stop_center + n * (Ls/2)\n                    lon3, lat3 = xy_to_lonlat(q1[0], q1[1], lon0, lat0)\n                    lon4, lat4 = xy_to_lonlat(q2[0], q2[1], lon0, lat0)\n                    features.append({\n                        \"type\": \"Feature\",\n                        \"properties\": {\"type\": \"stopline\", \"side\": side},\n                        \"geometry\": {\"type\": \"LineString\", \"coordinates\": [[lon3, lat3], [lon4, lat4]]}\n                    })\n            # (Removed) turn_lanes visualizations; only draw specified curves below\n            # Specified curves forming the road network\n            for c in curves:\n                if c['polyline'] is not None:\n                    features.append({\n                        \"type\": \"Feature\",\n                        \"properties\": {\"type\": \"curve\", \"name\": c['name'], \"labels\": c['labels']},\n                        \"geometry\": {\"type\": \"LineString\", \"coordinates\": c['polyline']['coordinates']}\n                    })\n            with open(out_geojson_path, 'w', encoding='utf-8') as f:\n                json.dump({\"type\": \"FeatureCollection\", \"features\": features}, f, ensure_ascii=False, indent=2)\n\n        # Console summary\n        print(f\"\\n=== Intersection Inference Results ({inter_id}) ===\")\n        print(f\"Center (local m): x={center_xy[0]:.2f}, y={center_xy[1]:.2f}\")\n        print(f\"Center (lon,lat): ({center_lon:.6f}, {center_lat:.6f})\")\n        for side, res in side_results.items():\n            base_axis = res['base_axis']\n            if base_axis is None:\n                print(f\"\\n[{side}]  no straight base axis\")\n                continue\n            print(f\"\\n[{side}]  straight_samples={len(res['points'])}  lanes={len(res['lanes'])}\")\n            print(f\"  Base axis angle = {base_axis.angle_deg:.2f} deg (0=E,90=N)\")\n            print(f\"  Base axis eqn   : n^T x = rho,  n={[float(base_axis.n[0]), float(base_axis.n[1])]}, rho={base_axis.rho:.2f} m\")\n            sstop = stoplines[side]['s_stop_m_from_center']\n            print(f\"  Stop-line s(from center) = {None if sstop is None else f'{sstop:.2f} m'}  ({stoplines[side]['method']})\")\n\n        if WRITE_GEOJSON:\n            print(f\"\\nWrote {out_json_path} and {out_geojson_path}.\")\n        else:\n            print(f\"\\nWrote {out_json_path}.\")\n\n# Module is imported and executed via main.py\n"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}