{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Auto-generated from `infer_stopline_w_bak.py`\n\nGenerated on 2025-11-09T22:01:34.\n\nThis notebook was created programmatically to mirror the original Python script.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nimport sys\nproject_root = str(Path.cwd().parent.resolve())\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# -*- coding: utf-8 -*-\n\"\"\"\nWEST stop-line detection (Q90 strategy):\n- Same data flow as v2 (strict dwell + two-pass refinement),\n  but final s_stop = Q=0.90 percentile of per-vehicle \"last dwell s\"\n  computed on the refined (line-front-only) evidence.\n- This ensures ~90% 的“每车最后一次驻停”都在 s_stop 之前/到达处。\n\nOutputs:\n  /home/tzhang174/EVData_XGame/data/west_stopline.json\n  /home/tzhang174/EVData_XGame/data/west_stopline_analyse.json\n  (same filenames; this script overwrites with Q90 strategy results)\n\"\"\"\nimport os, csv, json, math, datetime\nimport numpy as np\n\nDATA_DIR = \"/home/tzhang174/EVData_XGame/data\"\nDIR_CSV  = \"/home/mw/project/direction.csv\"\nFILES    = [(\"/home/mw/project/A0003_refined.csv\",\"A0003\"), (\"/home/mw/project/A0008_refined.csv\",\"A0008\")]\nCL_JSON  = \"/home/mw/project/intersection_A.json\"\n\nOUT_GEOM    = \"/home/mw/project/west_stopline.json\"\nOUT_ANALYSE = \"/home/mw/project/west_stopline_analyse.json\"\n\nCENTER_BY_ROAD = {\n    \"A0003\": (123.15253329, 32.34513595),\n    \"A0008\": (123.18126882, 32.32708227),\n}\nVALID_DIRS = {\"A1-1\",\"B2-1\",\"B3-2\"}\n\n# Params (same as v2)\nSEARCH_BACK_M   = 40.0\nSTOP_HALF_M     = 10.0\nLOW_SPEED_KMH   = 8.0\nMIN_STOP_SEC    = 2.5\nREFINE_BUFFER_M = 1.5\nQ_ALPHA         = 0.10   # 90th percentile\n\n# ---------- IO helpers ----------\ndef _read_csv_rows(path, encodings=(\"utf-8\",\"gb18030\",\"latin-1\")):\n    last=None\n    for enc in encodings:\n        try:\n            with open(path,\"r\",newline=\"\",encoding=enc) as f:\n                return list(csv.DictReader(f))\n        except Exception as e:\n            last=e\n    raise last\n\ndef _norm(s): return (s or \"\").strip()\n\ndef _parse_epoch_ts(row):\n    def _num(s):\n        try: return float(str(s).strip())\n        except: return None\n    coll = row.get('collectiontime') or row.get('collection_time') or row.get('collecttime')\n    if coll is not None and str(coll).strip()!='':\n        v = _num(coll)\n        if v is not None:\n            if v > 1e10: return v/1000.0\n            if v > 1e6:  return v\n    date_s=(row.get('date') or '').strip()\n    time_s=(row.get('time_stamp') or row.get('timestamp') or '').strip()\n    if date_s and time_s:\n        try:\n            import datetime\n            return datetime.datetime.strptime(date_s+' '+time_s, '%Y-%m-%d %H:%M:%S').timestamp()\n        except: pass\n    v = _num(row.get('time_stamp'))\n    return v if v is not None else 0.0\n\ndef _parse_end_ts(row):\n    def _num(s):\n        try: return float(str(s).strip())\n        except: return None\n    end_raw = row.get('end_time')\n    if end_raw is None or str(end_raw).strip()=='' : return None\n    v = _num(end_raw)\n    if v is not None:\n        if v > 1e10: return v/1000.0\n        if v > 1e6:  return v\n    date_s=(row.get('date') or '').strip()\n    end_s =str(end_raw).strip()\n    if date_s and len(end_s)>=5:\n        import datetime\n        try: return datetime.datetime.strptime(date_s+' '+end_s, '%Y-%m-%d %H:%M:%S').timestamp()\n        except: return None\n    return None\n\ndef lonlat_to_local_xy(lon, lat, lon0=None, lat0=None):\n    import numpy as np\n    lon = np.asarray(lon,float); lat=np.asarray(lat,float)\n    if lon0 is None: lon0=float(np.nanmean(lon))\n    if lat0 is None: lat0=float(np.nanmean(lat))\n    R=6371000.0\n    x=R*np.cos(np.deg2rad(lat0))*np.deg2rad(lon-lon0)\n    y=R*np.deg2rad(lat-lat0)\n    return x,y,lon0,lat0\n\ndef local_xy_to_lonlat(x,y,lon0,lat0):\n    import numpy as np\n    R=6371000.0\n    lon=lon0+np.rad2deg(x/(R*np.cos(np.deg2rad(lat0))))\n    lat=lat0+np.rad2deg(y/R)\n    return lon,lat\n\n# ---------- Polyline ----------\nimport numpy as np, json\ndef load_centerline(path, road):\n    with open(path,\"r\",encoding=\"utf-8\") as f:\n        obj=json.load(f)\n    entry=obj.get(road,{})\n    cand=entry.get(\"lane_divider\",[])\n    CL=[]\n    for p in cand:\n        if isinstance(p,dict) and \"lon\" in p: CL.append([float(p[\"lon\"]),float(p[\"lat\"])])\n        else: CL.append([float(p[0]),float(p[1])])\n    if len(CL)<2: raise ValueError(\"lane_divider too short\")\n    return np.array(CL,float)\n\ndef polyline_metrics_xy(lonlat):\n    lon=lonlat[:,0]; lat=lonlat[:,1]\n    x,y,lon0,lat0=lonlat_to_local_xy(lon,lat)\n    P=np.column_stack([x,y])\n    segs=P[1:]-P[:-1]\n    seg_len=np.linalg.norm(segs,axis=1)\n    s_vertices=np.concatenate([[0.0],np.cumsum(seg_len)])\n    return P,segs,seg_len,s_vertices,lon0,lat0\n\ndef project_point_to_polyline_xy(px,py,P,segs,seg_len,s_vertices):\n    best=(None,None,None,None,float(\"inf\"))\n    for i,(v,w,L) in enumerate(zip(P[:-1],segs,seg_len)):\n        if L<=1e-6:\n            qx,qy=v[0],v[1]; s_here=s_vertices[i]\n            d2=(px-qx)**2+(py-qy)**2\n            if d2<best[-1]: best=(s_here,qx,qy,i,0.0,d2)\n            continue\n        t=((px-v[0])*w[0]+(py-v[1])*w[1])/(L*L)\n        t=max(0.0,min(1.0,t))\n        qx,qy=v[0]+t*w[0], v[1]+t*w[1]\n        s_here=s_vertices[i]+t*L\n        d2=(px-qx)**2+(py-qy)**2\n        if d2<best[-1]: best=(s_here,qx,qy,i,t,d2)\n    return best[:5]\n\ndef normal_at_s(i,segs):\n    w=segs[i]; L=float(np.hypot(w[0],w[1])) or 1.0\n    nx,ny=-w[1]/L, w[0]/L\n    return nx,ny,L\n\n# ---------- Data loading ----------\ndef load_directions_keys(path):\n    rows=_read_csv_rows(path)\n    allow={}\n    for r in rows:\n        d=_norm(r.get(\"direction\"))\n        if d not in VALID_DIRS: continue\n        k=(_norm(r.get(\"vehicle_id\")), _norm(r.get(\"date\")),\n           _norm(r.get(\"seg_id\")), _norm(r.get(\"road_id\")))\n        allow[k]=d\n    return allow\n\ndef load_points_for_road(csv_path, road, allow_map):\n    rows=_read_csv_rows(csv_path)\n    by_vid_dir={}; all_lonlat=[]\n    for r in rows:\n        if _norm(r.get(\"road_id\"))!=road: continue\n        k=(_norm(r.get(\"vehicle_id\")), _norm(r.get(\"date\")),\n           _norm(r.get(\"seg_id\")), _norm(r.get(\"road_id\")))\n        d=allow_map.get(k)\n        if d is None: continue\n        try:\n            lon=float(_norm(r.get(\"longitude\"))); lat=float(_norm(r.get(\"latitude\")))\n            spd_kmh=float(_norm(r.get(\"speed\")) or 0.0)\n        except: continue\n        ts_start=_parse_epoch_ts(r) or 0.0\n        ts_end  =_parse_end_ts(r)\n        by_vid_dir.setdefault((k[0],d), []).append((ts_start, ts_end, lon, lat, spd_kmh))\n        all_lonlat.append((lon,lat))\n    for key in by_vid_dir: by_vid_dir[key].sort(key=lambda x: x[0])\n    import numpy as np\n    return by_vid_dir, (np.array(all_lonlat) if all_lonlat else np.zeros((0,2))), rows\n\n# ---------- Dwell ----------\ndef is_dwell(ts_start, ts_end, spd_kmh):\n    if ts_end is None: return False\n    dur=max(0.0, ts_end-ts_start)\n    return (dur>=MIN_STOP_SEC) and (spd_kmh<=LOW_SPEED_KMH)\n\ndef per_vehicle_rightmost_stop(seq,P,segs,seg_len,s_vertices,lon0,lat0,s_lo,s_hi,s_max=None):\n    rightmost=None\n    for ts_start, ts_end, lon, lat, spd_kmh in seq:\n        if not is_dwell(ts_start, ts_end, spd_kmh): continue\n        x,y,_,_=lonlat_to_local_xy(np.array([lon]),np.array([lat]),lon0,lat0)\n        s_proj,*_=project_point_to_polyline_xy(x[0],y[0],P,segs,seg_len,s_vertices)\n        if s_proj is None: continue\n        if s_proj<s_lo or s_proj>s_hi: continue\n        if (s_max is not None) and (s_proj> s_max): continue\n        if (rightmost is None) or (s_proj>rightmost): rightmost=s_proj\n    return rightmost\n\n# ---------- Road pipeline ----------\ndef compute_for_road(road, csv_path, allow_map, centerline_lonlat, center_lonlat):\n    P,segs,seg_len,s_vertices,lon0,lat0 = polyline_metrics_xy(centerline_lonlat)\n    by_vid_dir, all_lonlat, _ = load_points_for_road(csv_path, road, allow_map)\n    if len(by_vid_dir)==0:\n        return ({\"s_stop_m\":None,\"stopline_segment\":[]},{\"error\":\"no data\"})\n\n    # Orientation\n    Xall,Yall,_,_=lonlat_to_local_xy(all_lonlat[:,0],all_lonlat[:,1],lon0,lat0)\n    s_all=[]\n    for (x,y) in zip(Xall,Yall):\n        s_proj,*_=project_point_to_polyline_xy(x,y,P,segs,seg_len,s_vertices)\n        s_all.append(s_proj if s_proj is not None else np.nan)\n    s_all=np.array(s_all,float)\n    if np.nanstd(s_all)<1e-9 or np.sum(~np.isnan(s_all))<3: east_sign=+1.0\n    else:\n        c=np.corrcoef(s_all[~np.isnan(s_all)], all_lonlat[~np.isnan(s_all),0])[0,1]\n        east_sign=+1.0 if c>=0 else -1.0\n\n    # s0 from intersection center\n    cx,cy,_,_=lonlat_to_local_xy(np.array([center_lonlat[0]]),np.array([center_lonlat[1]]),lon0,lat0)\n    s0,*_=project_point_to_polyline_xy(cx[0],cy[0],P,segs,seg_len,s_vertices)\n\n    # WEST window\n    if east_sign>0: s_lo,s_hi = s0-SEARCH_BACK_M, s0\n    else:           s_lo,s_hi = s0, s0+SEARCH_BACK_M\n\n    def gather_all_dwells(s_max=None):\n        per_class_stop_s={\"A1-1\":[],\"B2-1\":[],\"B3-2\":[]}\n        all_stop_s=[]\n        for (vid,d),seq in by_vid_dir.items():\n            rs=per_vehicle_rightmost_stop(seq,P,segs,seg_len,s_vertices,lon0,lat0,s_lo,s_hi,s_max=s_max)\n            if (rs is not None) and (d in per_class_stop_s):\n                per_class_stop_s[d].append(float(rs))\n                all_stop_s.append(float(rs))\n        s_all_low=[]; post_line_slow=0\n        for (vid,d),seq in by_vid_dir.items():\n            for ts_start,ts_end,lon,lat,spd_kmh in seq:\n                if not is_dwell(ts_start,ts_end,spd_kmh): continue\n                x,y,_,_=lonlat_to_local_xy(np.array([lon]),np.array([lat]),lon0,lat0)\n                s_proj,*_=project_point_to_polyline_xy(x[0],y[0],P,segs,seg_len,s_vertices)\n                if s_proj is None: continue\n                if s_proj<s_lo or s_proj>s_hi: continue\n                if (s_max is not None) and (s_proj> s_max):\n                    post_line_slow += 1\n                    continue\n                s_all_low.append(float(s_proj))\n        # histogram (diagnostic only)\n        if len(s_all_low)==0:\n            s_peak=float(s_hi); edges=[]; counts=[]\n        else:\n            s_all_low=np.array(s_all_low,float)\n            nb=max(10,int((s_hi-s_lo)/2.0))\n            counts,edges=np.histogram(s_all_low, bins=nb, range=(s_lo,s_hi))\n            k=int(np.argmax(counts)); s_peak=float(0.5*(edges[k]+edges[k+1]))\n        return per_class_stop_s, all_stop_s, s_all_low, (edges,counts), s_peak, post_line_slow\n\n    # Pass1\n    per1, all1, s_low1, (edges1,counts1), peak1, post1 = gather_all_dwells(s_max=None)\n    if len(all1)==0:\n        s_stop0=peak1\n    else:\n        s_stop0=float(np.quantile(np.array(all1,float), 0.50))  # coarse = median (only for s_max)\n    # Pass2 (refined)\n    s_max_refine = s_stop0 + REFINE_BUFFER_M\n    per2, all2, s_low2, (edges2,counts2), peak2, post2 = gather_all_dwells(s_max=s_max_refine)\n\n    # ---- Q90 strategy ----\n    if len(all2)==0:\n        s_stop = float(s_max_refine)  # fallback: practically near coarse\n        qvals = {}\n    else:\n        arr = np.array(all2, float)\n        q50 = float(np.quantile(arr, 0.50))\n        q80 = float(np.quantile(arr, 0.80))\n        q90 = float(np.quantile(arr, Q_ALPHA))\n        q95 = float(np.quantile(arr, 0.95))\n        s_stop = q90  # core: 90% before this line\n        qvals = {\"q50\":q50,\"q80\":q80,\"q90\":q90,\"q95\":q95}\n    # 20 m segment at s_stop\n    s_vertices=np.concatenate([[0.0], np.cumsum(seg_len)])\n    si=int(np.searchsorted(s_vertices, s_stop)-1); si=max(0,min(len(segs)-1,si))\n    nx,ny,Lseg=normal_at_s(si,segs)\n    s_base=s_vertices[si]\n    t=(s_stop - s_base)/(Lseg if Lseg>1e-6 else 1.0)\n    vx,vy=P[si]; wx,wy=segs[si]\n    px,py=vx+t*wx, vy+t*wy\n    ax,ay=px-STOP_HALF_M*nx, py-STOP_HALF_M*ny\n    bx,by=px+STOP_HALF_M*nx, py+STOP_HALF_M*ny\n    seg_lon,seg_lat=local_xy_to_lonlat(np.array([ax,bx]), np.array([ay,by]), lon0, lat0)\n\n    geom = {\n        \"s_stop_m\": float(s_stop),\n        \"stopline_segment\": [[float(seg_lon[0]), float(seg_lat[0])],\n                             [float(seg_lon[1]), float(seg_lat[1])]]\n    }\n    analyse = {\n        \"params\": {\n            \"search_back_m\": SEARCH_BACK_M,\n            \"stop_segment_half_m\": STOP_HALF_M,\n            \"low_speed_kmh\": LOW_SPEED_KMH,\n            \"min_stop_sec\": MIN_STOP_SEC,\n            \"refine_buffer_m\": REFINE_BUFFER_M,\n            \"q_alpha\": Q_ALPHA\n        },\n        \"east_sign\": 1 if east_sign>0 else -1,\n        \"s0_center_m\": float(s0),\n        \"window\": {\"s_lo\": float(s_lo), \"s_hi\": float(s_hi)},\n        \"pass1\": {\n            \"hist_edges\": edges1.tolist() if len(edges1)>0 else [],\n            \"hist_counts\": [int(x) for x in (counts1.tolist() if len(edges1)>0 else [])],\n            \"s_peak_right\": float(peak1),\n            \"s_stop0\": float(s_stop0),\n            \"per_class_stop_s\": {k: [float(x) for x in v] for k,v in per1.items()},\n            \"postline_slowroll_count\": int(post1)\n        },\n        \"pass2_refined\": {\n            \"hist_edges\": edges2.tolist() if len(edges2)>0 else [],\n            \"hist_counts\": [int(x) for x in (counts2.tolist() if len(edges2)>0 else [])],\n            \"s_peak_right\": float(peak2),\n            \"quantiles\": qvals,\n            \"s_stop\": float(s_stop),\n            \"per_class_stop_s\": {k: [float(x) for x in v] for k,v in per2.items()},\n            \"postline_slowroll_count\": int(post2)\n        }\n    }\n    return geom, analyse\n\ndef main():\n    allow_map = load_directions_keys(DIR_CSV)\n    out_geom={}; out_ana={}\n    for fname, road in FILES:\n        csv_path=os.path.join(DATA_DIR, fname)\n        if not os.path.exists(csv_path):\n            out_geom[road]={\"error\":\"file not found\"}; out_ana[road]={\"error\":\"file not found\"}; continue\n        try: CL=load_centerline(CL_JSON, road)\n        except Exception as e:\n            out_geom[road]={\"error\":f\"centerline error: {e}\"}; out_ana[road]={\"error\":f\"centerline error: {e}\"}; continue\n        center=CENTER_BY_ROAD.get(road)\n        if center is None:\n            out_geom[road]={\"error\":\"missing intersection center\"}; out_ana[road]={\"error\":\"missing intersection center\"}; continue\n        geom, ana = compute_for_road(road, csv_path, allow_map, CL, center)\n        out_geom[road]=geom; out_ana[road]=ana\n    with open(OUT_GEOM,\"w\",encoding=\"utf-8\") as f: json.dump(out_geom,f,ensure_ascii=False,indent=2)\n    with open(OUT_ANALYSE,\"w\",encoding=\"utf-8\") as f: json.dump(out_ana,f,ensure_ascii=False,indent=2)\n    print(\"Wrote\", OUT_GEOM); print(\"Wrote\", OUT_ANALYSE)\n\nif __name__ == \"__main__\":\n    main()\n"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}